{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱 신경망 (Convolutional Neural Network, CNN)\n",
    "\n",
    "합성곱 신경망(CNN)은 **이미지** 처리와 패턴 인식에 주로 사용되는 신경망 구조입니다. CNN은 입력 데이터에 필터(커널)를 적용하여 특징을 추출하고, 풀링 연산을 통해 중요한 정보를 유지하면서 공간 크기를 줄입니다. 이러한 과정을 반복하여 고수준의 특징을 추출하고 분류 및 인식 작업을 수행합니다. CNN은 이미지 분류, 객체 검출, 분할 등 다양한 컴퓨터 비전 태스크에 효과적으로 적용됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "이번 실습에서는 CNN을 사용하여 CIFAR-10 데이터셋을 학습하고, 테스트 데이터에 대한 예측을 수행합니다. CNN 모델을 구축하고 훈련하는 과정을 진행한 후, 모델의 정확도를 평가합니다.\n",
    "\n",
    "실습에서는 데이터 전처리, 모델 구축, 모델 컴파일, 훈련, 평가 등의 과정을 진행합니다. CNN을 사용하여 이미지 데이터의 특징을 추출하고 분류하는 과정을 경험해보세요.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[텐서플로우 설치]__\n",
    "- 텐서플로우가 설치되지 않았다면 아래 명령어를 실행하여 설치해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T06:27:11.189604Z",
     "start_time": "2024-08-14T06:27:10.261102Z"
    }
   },
   "source": [
    "#!pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org -U tensorflow\n",
    "!pip install tensorflow"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (2.17.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (24.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (4.25.4)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (69.5.1)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (4.11.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.65.4)\r\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (2.17.0)\r\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.26.4)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\r\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필요한 라이브러리 임포트 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__사내 PC 실습 안내__ \n",
    "- 본 실습자료는 외부 인터넷 환경에서 자료를 다운로드하는 과정이 담겨 있습니다.\n",
    "- 사내 PC에서 실습하실 경우 SSL 인증 오류가 발생할 수 있습니다.\n",
    "- SSL 인증을 생략하여 오류를 방지하는 아래 코드를 실행한 후, 실습을 진행 해 주시면 됩니다.\n",
    "- 따라서, 내용은 영상 속 강의자료와 다를 수 있습니다.\n",
    "\n",
    "```python\n",
    "import ssl\n",
    "# https 인증 시, 기본 인증 컨텍스트를, 인증 생략 컨텍스트로 변경\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T06:28:26.573086Z",
     "start_time": "2024-08-14T06:28:23.825624Z"
    }
   },
   "source": [
    "import ssl\n",
    "# https 인증 시, 기본 인증 컨텍스트를, 인증 생략 컨텍스트로 변경\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information:\n",
    "TensorFlow를 사용하여 CIFAR-10 데이터셋을 로드하고, CNN(Convolutional Neural Network) 모델을 구성하여 이미지 분류 작업을 수행합니다. 주요 라이브러리와 모듈들은 다음과 같이 사용됩니다:\n",
    "\n",
    "- `numpy as np`: 수치 계산을 위한 다차원 배열 처리 라이브러리입니다.\n",
    "- `tensorflow as tf`: 오픈 소스 기계 학습 프레임워크인 TensorFlow를 사용하기 위한 라이브러리입니다.\n",
    "- `tensorflow.keras.datasets.cifar10`: CIFAR-10 데이터셋을 로드하기 위한 모듈입니다. CIFAR-10은 10개의 클래스로 이루어진 컬러 이미지 데이터셋입니다.\n",
    "- `tensorflow.keras.models.Sequential`: 순차적인 모델을 생성하기 위한 클래스입니다. 모델은 레이어를 선형으로 쌓아 구성할 수 있습니다.\n",
    "- `tensorflow.keras.layers.Conv2D`: 합성곱 레이어입니다. 이미지 데이터의 특징을 추출하는 데 사용됩니다.\n",
    "- `tensorflow.keras.layers.MaxPooling2D`: 최대 풀링 레이어입니다. 이미지의 공간 해상도를 줄이는 데 사용됩니다.\n",
    "- `tensorflow.keras.layers.Flatten`: 입력 데이터를 1차원으로 평탄화시키는 레이어입니다. 다차원 배열의 데이터를 1차원으로 변환하여 신경망의 입력으로 사용할 수 있습니다.\n",
    "- `tensorflow.keras.layers.Dense`: 완전 연결 레이어입니다. 입력과 출력을 모두 연결하여 가중치를 학습합니다.\n",
    "- `sklearn.preprocessing.MinMaxScaler`: 데이터를 정규화하기 위한 클래스입니다. 입력 데이터를 특정 범위로 스케일링하여 모델의 학습을 돕는 데 사용됩니다.\n",
    "- `sklearn.model_selection.train_test_split`: 데이터셋을 훈련 및 테스트 세트로 나누기 위한 함수입니다.\n",
    "- `matplotlib.pyplot as plt`: 데이터 시각화를 위한 라이브러리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터셋 생성\n",
    "#####  CIFAR-10 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T06:30:58.728524Z",
     "start_time": "2024-08-14T06:30:30.990232Z"
    }
   },
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001B[1m170498071/170498071\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 0us/step\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같은 데이터 전처리 과정을 수행합니다.\n",
    "\n",
    "- `x_train = x_train / 255.0`: 훈련 데이터를 0과 1 사이의 범위로 정규화합니다. 정규화는 데이터의 범위를 일정하게 조정하여 모델의 학습을 돕는 역할을 합니다. CIFAR-10 데이터셋은 각 픽셀 값이 0에서 255 사이의 정수로 표현되는 이미지로 구성되어 있습니다. 따라서 이 값을 255로 나누면 모든 픽셀 값이 0에서 1 사이의 실수로 변환됩니다. 이는 모델이 데이터를 더 잘 처리하고 일반화할 수 있도록 돕는 역할을 합니다.\n",
    "- `x_test = x_test / 255.0`: 테스트 데이터도 동일하게 0과 1 사이의 범위로 정규화합니다.\n",
    "\n",
    "정규화를 수행하는 이유는 모델이 입력 데이터의 스케일 차이에 영향을 받지 않고 일관된 방식으로 학습할 수 있도록 하기 위함입니다. 또한, 정규화를 통해 모델의 수렴 속도를 향상시키고, 과적합을 방지하는 일반화 효과를 얻을 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T07:56:13.321817Z",
     "start_time": "2024-08-14T07:56:12.955984Z"
    }
   },
   "source": [
    "# 데이터 전처리\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델(CNN) 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential 모델을 사용하여 이미지 분류를 위한 CNN(Convolutional Neural Network) 모델을 구성하는 과정입니다.\n",
    "\n",
    "- `model = Sequential()`: Sequential 모델을 생성합니다. Sequential 모델은 레이어를 선형으로 쌓아 구성할 수 있는 가장 간단한 형태의 모델입니다.\n",
    "\n",
    "- `model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))`: 32개의 필터를 사용하여 3x3 크기의 컨볼루션(Convolution) 레이어를 추가합니다. 활성화 함수로는 ReLU(Rectified Linear Unit)를 사용합니다. 입력 이미지의 크기는 (32, 32, 3)입니다.\n",
    "\n",
    "- `model.add(MaxPooling2D((2, 2)))`: 2x2 크기의 맥스 풀링(Max Pooling) 레이어를 추가합니다. 맥스 풀링은 입력 영역에서 가장 큰 값을 선택하여 다운샘플링하는 과정입니다. 이를 통해 공간적인 특징을 추출하고 계산량을 줄입니다.\n",
    "\n",
    "- `model.add(Conv2D(64, (3, 3), activation='relu'))`: 64개의 필터를 사용하여 3x3 크기의 컨볼루션 레이어를 추가합니다. 활성화 함수로는 ReLU를 사용합니다.\n",
    "\n",
    "- `model.add(MaxPooling2D((2, 2)))`: 2x2 크기의 맥스 풀링 레이어를 추가합니다.\n",
    "\n",
    "- `model.add(Conv2D(64, (3, 3), activation='relu'))`: 64개의 필터를 사용하여 3x3 크기의 컨볼루션 레이어를 추가합니다. 활성화 함수로는 ReLU를 사용합니다.\n",
    "\n",
    "- `model.add(Flatten())`: 다차원의 입력을 1차원으로 평탄화시키는 레이어를 추가합니다. 이는 컨볼루션 레이어의 출력을 전결합층(Fully Connected Layer)에 전달하기 위해 필요합니다.\n",
    "\n",
    "- `model.add(Dense(64, activation='relu'))`: 64개의 뉴런으로 구성된 전결합층을 추가합니다. 활성화 함수로는 ReLU를 사용합니다.\n",
    "\n",
    "- `model.add(Dense(10))`: 10개의 뉴런으로 구성된 출력층을 추가합니다. 이는 CIFAR-10 데이터셋의 10개의 클래스에 대한 확률 값을 출력하기 위한 것입니다.\n",
    "\n",
    "위 모델은 컨볼루션 레이어와 맥스 풀링 레이어를 번갈아가며 쌓아 이미지의 특징을 추출하고, 이를 전결합층을 통해 분류하는 과정을 수행합니다. 활성화 함수로는 ReLU를 사용하여 비선형성을 도입하고, 출력층에서는 활성화 함수를 지정하지 않았습니다. 이는 다중 클래스 분류 문제에서는 일반적으로 softmax 활성화 함수가 사용되기 때문입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T07:56:22.788696Z",
     "start_time": "2024-08-14T07:56:22.740575Z"
    }
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aice/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컴파일은 학습 프로세스를 설정하는 단계입니다.\n",
    "\n",
    "- `model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])`: 모델 컴파일을 수행합니다. 여기서 사용된 인자들을 설명하면 다음과 같습니다:\n",
    "    - `optimizer='adam'`: 최적화 알고리즘으로 Adam 옵티마이저를 사용합니다. Adam은 경사 하강법의 변종으로, 학습 속도를 자동으로 조절하여 빠르고 안정적인 학습을 도와줍니다.\n",
    "    - `loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)`: 손실 함수로 Sparse Categorical Crossentropy를 사용합니다. 이 함수는 다중 클래스 분류 문제에 적합하며, 실제 클래스 레이블이 정수 형태로 주어진 경우 사용됩니다. `from_logits=True`는 모델의 출력을 확률 값으로 해석하지 않고, 그대로 사용한다는 의미입니다.\n",
    "    - `metrics=['accuracy']`: 모델의 평가 지표로 정확도(Accuracy)를 사용합니다. 이는 분류 문제에서 가장 일반적으로 사용되는 지표로, 모델의 예측 결과가 실제 레이블과 얼마나 일치하는지를 측정합니다.\n",
    "\n",
    "위 코드는 모델을 컴파일하여 학습 프로세스를 설정하는 단계를 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T07:56:31.778159Z",
     "start_time": "2024-08-14T07:56:31.769040Z"
    }
   },
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델을 학습시킵니다. 여기서 사용된 인자들을 설명하면 다음과 같습니다:\n",
    "    - `x_train`과 `y_train`: 훈련 데이터셋의 입력과 레이블입니다.\n",
    "    - `epochs=10`: 전체 훈련 데이터셋에 대해 반복 학습할 에포크(Epoch) 수를 지정합니다. 에포크는 훈련 데이터셋을 한 번 전체로 통과하는 것을 의미합니다.\n",
    "    - `validation_data=(x_test, y_test)`: 검증 데이터셋의 입력과 레이블입니다. 모델 학습 중에 검증 데이터셋을 사용하여 모델의 성능을 평가합니다. 검증 데이터셋을 사용하여 모델이 과적합되지 않도록 제어할 수 있습니다.\n",
    "\n",
    "위 코드는 주어진 훈련 데이터셋을 사용하여 모델을 학습시키는 단계를 수행합니다. 학습은 주어진 에포크 수만큼 반복되며, 각 에포크마다 훈련 데이터셋을 사용하여 모델의 가중치를 업데이트합니다. 또한, 검증 데이터셋을 사용하여 모델의 성능을 평가하고 모니터링합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T07:59:13.004993Z",
     "start_time": "2024-08-14T07:56:35.574388Z"
    }
   },
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 8ms/step - accuracy: 0.3446 - loss: 1.7597 - val_accuracy: 0.5387 - val_loss: 1.2701\n",
      "Epoch 2/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 9ms/step - accuracy: 0.5638 - loss: 1.2139 - val_accuracy: 0.6117 - val_loss: 1.1047\n",
      "Epoch 3/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 10ms/step - accuracy: 0.6373 - loss: 1.0253 - val_accuracy: 0.6353 - val_loss: 1.0427\n",
      "Epoch 4/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 9ms/step - accuracy: 0.6802 - loss: 0.9179 - val_accuracy: 0.6802 - val_loss: 0.9262\n",
      "Epoch 5/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 10ms/step - accuracy: 0.7101 - loss: 0.8345 - val_accuracy: 0.6829 - val_loss: 0.9103\n",
      "Epoch 6/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 10ms/step - accuracy: 0.7315 - loss: 0.7696 - val_accuracy: 0.7046 - val_loss: 0.8637\n",
      "Epoch 7/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 11ms/step - accuracy: 0.7478 - loss: 0.7179 - val_accuracy: 0.6952 - val_loss: 0.8838\n",
      "Epoch 8/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 11ms/step - accuracy: 0.7617 - loss: 0.6728 - val_accuracy: 0.7111 - val_loss: 0.8533\n",
      "Epoch 9/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 11ms/step - accuracy: 0.7796 - loss: 0.6314 - val_accuracy: 0.7213 - val_loss: 0.8401\n",
      "Epoch 10/10\n",
      "\u001B[1m1563/1563\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 10ms/step - accuracy: 0.7918 - loss: 0.5900 - val_accuracy: 0.7145 - val_loss: 0.8557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17cabea90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 모델 평가\n",
    "##### 테스트 데이터(X_test, y_test)를 사용하여 모델의 손실과 정확도를 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`verbose`는 모델 학습 중에 출력되는 정보의 양을 조절하는 인자입니다.\n",
    "\n",
    "- `verbose=2`: 학습 과정에서 에포크마다 한 줄씩 출력됩니다. 각 에포크마다 진행 상황과 손실 값(loss) 및 정확도(accuracy)가 표시됩니다.\n",
    "\n",
    "verbose 값에 따라 출력되는 정보의 양이 다르며, 일반적으로 다음과 같이 설정할 수 있습니다:\n",
    "- `verbose=0`: 출력이 없습니다.\n",
    "- `verbose=1`: 진행 막대(progress bar)와 함께 간단한 정보를 출력합니다.\n",
    "- `verbose=2`: 각 에포크마다 상세한 정보를 출력합니다.\n",
    "\n",
    "`verbose` 인자는 모델 학습 중에 출력되는 정보의 양을 조절하여 사용자에게 적절한 학습 과정 모니터링을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T08:01:44.278638Z",
     "start_time": "2024-08-14T08:01:43.071235Z"
    }
   },
   "source": [
    "loss, accuracy = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 4ms/step - accuracy: 0.7145 - loss: 0.8557\n",
      "Test Loss: 0.8557\n",
      "Test Accuracy: 0.7145\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 예측 수행\n",
    "##### CIFAR-10 이미지를 사용하여 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-14T08:09:15.174782Z",
     "start_time": "2024-08-14T08:09:15.060854Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 테스트 데이터셋에서 이미지 하나 선택\n",
    "image_index = 1\n",
    "test_image = x_test[image_index]\n",
    "true_label = y_test[image_index][0]  # 정수 스칼라로 변환\n",
    "\n",
    "# 이미지 정규화 해제\n",
    "test_image = test_image * 255\n",
    "\n",
    "# 이미지 예측\n",
    "predictions = model.predict(np.expand_dims(test_image, axis=0))\n",
    "predicted_label = np.argmax(predictions[0])  # 정수 스칼라로 변환\n",
    "\n",
    "# 클래스 레이블 매핑\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# 이미지 시각화 및 예측 결과 출력\n",
    "plt.figure(figsize=(3, 3))  # 그림의 크기 조정\n",
    "plt.imshow(test_image.astype(int))\n",
    "plt.axis('off')\n",
    "plt.title(f\"True Label: {class_names[true_label]}, Predicted Label: {class_names[predicted_label]}\")\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 완료: CNN(Convolutional Neural Network, CNN) Summary\n",
    "\n",
    "1. CNN 모델을 사용하여 CIFAR-10 데이터셋을 학습하고 평가하는 실습을 완료했습니다. CNN은 이미지 처리와 패턴 인식에 효과적으로 사용되는 신경망 구조입니다.\n",
    "\n",
    "2. 실습을 통해 CNN 모델의 구성과 파라미터 조정, 이미지 전처리의 중요성 등을 경험하였습니다. 학습된 모델은 테스트 데이터에 대해 정확도를 평가할 수 있었습니다.\n",
    "\n",
    "3. CNN을 이용한 이미지 분류와 패턴 인식은 다양한 컴퓨터 비전 문제에 적용할 수 있으며, 더 많은 실습과 응용을 통해 CNN 모델의 성능을 개선하고 다양한 이미지 데이터에 적용해 보시기 바랍니다. 감사합니다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
