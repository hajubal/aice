{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f7625f",
   "metadata": {},
   "source": [
    "# 안녕하세요, 여러분 ^^ \n",
    "\n",
    "# 디지코 디그리 AI 모델링 과정 \n",
    "# 🎈\"도전 머신러닝\" 시간에 오신 여러분을 환영합니다!\n",
    "\n",
    "## 오늘은 <font color=\"#01918a\">'타이타닉 생존자 예측'</font> 문제를 해결해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325d774e",
   "metadata": {},
   "source": [
    "<img src = \"https://images.unsplash.com/photo-1654170816607-f355d5cd5619?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2664&q=80\" width=100% align=\"center\"/>\n",
    "\n",
    "<div align=\"right\">사진: <a href=\"https://unsplash.com/ko/%EC%82%AC%EC%A7%84/TQAWPDbuwrc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>의<a href=\"https://unsplash.com/@ep_petrus?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Edwin Petrus</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1edbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15623d6c",
   "metadata": {},
   "source": [
    "## 1. 데이터 수집 및 분석\n",
    "### 1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec46e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip 이용해서 필요 라이브러리 설치(앞선 실습에서 미 설치 시 실행)\n",
    "\n",
    "# 사내 컴퓨터 사용 시\n",
    "#!pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org -U graphviz\n",
    "\n",
    "# import os\n",
    "# os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\"./bin\")\n",
    "\n",
    "# 사외 컴퓨터 사용 시\n",
    "#!pip install pandas-profiling seaborn graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f0f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리 불러오기\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3af1ec2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1aae7",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 (1)\n",
    "불필요한 컬럼을 삭제하거나 기존 데이터로 부터 새로운 컬럼을 생성합니다.\n",
    "데이터의 결측치를 확인하고 처리합니다\n",
    "- 데이터 가공하기\n",
    "- 결측치 제거하기\n",
    "- 불필요한 컬럼 삭제하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2634c7ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f15f20",
   "metadata": {},
   "source": [
    "## 3. 데이터 전처리 (2)\n",
    "범주형 변수를 수치형 데이터로 변환하고, 다양한 특성들의 스케일을 조정하여 데이터를 모델링에 적합한 형태로 전처리하는 과정입니다.\n",
    "\n",
    "- 범주형 데이터 인코딩\n",
    "- 특성 스케일링/정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1e6ce7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0476ae",
   "metadata": {},
   "source": [
    "## 4. 머신러닝 모델링\n",
    "데이터를 수집하고 전처리하여 특성을 선택하고 엔지니어링한 후, \n",
    "학습 데이터와 검증용 데이터를 분리하고 적절한 머신러닝 모델을 선택하여 학습시킨 다음,\n",
    "모델의 성능을 평가하고 성능을 향상시키는 작업을 수행하는 단계입니다.\n",
    "\n",
    "- Train(학습용), Test(검증용) 데이터 셋 분할\n",
    "- 머신러닝 모델 구현하기\n",
    "- 머신러닝 모델 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a160f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0ff53",
   "metadata": {},
   "source": [
    "## 5. 머신러닝 모델 활용하기\n",
    "머신러닝 모델 활용은 저장된 모델을 로드하고, 새로운 입력 데이터(Test 데이터)를 제공하여 예측 또는 추론을 수행하면 됩니다. <br>이 과정을 통해 모델을 활용하여 실제 문제에 대한 예측을 수행할 수 있습니다.\n",
    "- 머신러닝 모델 로드(불러오기)\n",
    "- Test 데이터 준비하기\n",
    "- 머신러닝 모델 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de96267",
   "metadata": {},
   "source": [
    "### 1) 머신러닝 모델 로드(불러오기)\n",
    "저장된 모델 파일을 로드합니다. <br>\n",
    "scikit-learn은 joblib 라이브러리를 활용하여 모델을 저장하고 로드할 수 있는 dump와 load 함수를 제공합니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93249de3",
   "metadata": {},
   "source": [
    "#### ① 저장한 모델 불러오기\n",
    "joblib의 load 함수를 사용하여 저장된 모델을 로드할 수 있습니다.\n",
    "> - loaded_model = joblib.load('model_file.pkl')<br>\n",
    "> load 함수를 사용하여 저장된 파일의 경로와 이름을 전달하면 모델이 로드됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bbb4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import joblib\n",
    "\n",
    "#model 저장\n",
    "my_model = joblib.load('./model_사번_이름.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07533819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb95984",
   "metadata": {},
   "source": [
    "### 2) Test 데이터 준비하기\n",
    "모델을 활용하기 위해 Test 데이터를 준비해야합니다. Test 데이터는 모델이 예측을 수행할 때 필요한 특성들을 포함해야 합니다. <br> \n",
    "데이터를 모델이 요구하는 형식에 맞게 가공하고 스케일링 등의 전처리 작업을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5223ae",
   "metadata": {},
   "source": [
    "#### ① Test 데이터 불러오기\n",
    "- **pandas 라이브러리의 read_csv 함수를 사용하면 파일을 불러오고 변수에 저장할 수 있습니다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./data/train_preprocessing_2.csv\")\n",
    "df_test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c4fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e735f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c25a47",
   "metadata": {},
   "source": [
    "#### ② Test 데이터 전처리하기\n",
    "- **Title 변수 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5982be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Title'] = df_test['Name'].str.extract(' ([a-zA-Z]+)\\.')\n",
    "\n",
    "# 대표 호칭 이외는 Others로 변경\n",
    "df_test.loc[df_test['Title'].isin(['Mr', 'Miss', 'Mrs'])==False, ['Title']] = 'Others'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e5b58",
   "metadata": {},
   "source": [
    "- **결측치 처리하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341a49e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b112c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputer 라이브러리 불러오기\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "# KNNImputer를 사용하여 'Age' 결측치를 예측하여 대체\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_test['Age'] = imputer.fit_transform(df_test[['Age']])\n",
    "df_test['Age'] = df_test['Age'].astype(int)\n",
    "\n",
    "# SimpleImputer를 사용하여 'Embarked' 최빈값으로 대체\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_test['Embarked'] = imputer.fit_transform(df_test[['Embarked']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bd390b",
   "metadata": {},
   "source": [
    "- **불필요한 컬럼 삭제하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e516eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "df_test.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebee43b0",
   "metadata": {},
   "source": [
    "- **데이터 인코딩하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20eeb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dummies를 활용하여 범주형 데이터 가변수화 진행\n",
    "# 범주형 컬럼 리스트\n",
    "dummy_vars = ['Title', 'Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns=dummy_vars, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672432cc",
   "metadata": {},
   "source": [
    "- **데이터 스케일링하기**<br>\n",
    "테스트 데이터는 학습 데이터와 동일한 스케일링 범위로 조정되어야 합니다. 그러나 테스트 데이터를 스케일링할 때마다 최소값과 최대값을 새로 계산하면 학습 데이터와 다른 스케일링 범위가 적용될 수 있습니다.<br>\n",
    "학습 데이터에는 모델이 이미 노출되어 있으므로, 학습 데이터의 스케일링 범위를 사용하는 것이 테스트 데이터의 정보 유출을 방지하고 일관성을 유지하는 데 도움이 됩니다.\n",
    "<br><br>\n",
    "학습 데이터에는 fit_transform()을 사용하여 최소값과 최대값을 계산하고 데이터를 스케일링합니다.<br> \n",
    "그 후, 테스트 데이터에는 transform()을 사용하여 학습 데이터에서 계산된 최소값과 최대값을 사용하여 동일한 스케일링을 적용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d9e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "# 스케일러 생성하기\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 학습용 데이터 스케일러 불러오기\n",
    "scaler = joblib.load(\"./scaler.pkl\")\n",
    "\n",
    "# 데이터 스케일링하기\n",
    "df_test = scaler.transform(df_test)\n",
    "\n",
    "#데이터 프레임\n",
    "df_test = pd.DataFrame(df_test, columns=scaler.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284313d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9454e87f",
   "metadata": {},
   "source": [
    "### 3) 머신러닝 모델 예측하기\n",
    "준비된 데이터를 사용하여 모델에 입력하여 예측을 수행하거나 추론 결과를 얻습니다. <br> \n",
    "모델에 입력 데이터를 전달하고, 모델은 해당 데이터에 대한 예측값을 반환합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429a79b",
   "metadata": {},
   "source": [
    "#### ① 불러온 모델로 Test 데이터 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ebdf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 모델로 예측하기\n",
    "predict = my_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b32147",
   "metadata": {},
   "source": [
    "#### ② 정답 데이터와 비교하기\n",
    "모델이 예측한 결과를 정답 데이터('actual.csv')를 불러와서 f1_score를 확인해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = pd.read_csv(\"./data/actual.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2b0d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8de0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(actual['Survived'], predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6787f",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
