{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:38:15.257062Z",
     "start_time": "2023-03-10T10:38:15.243169Z"
    }
   },
   "source": [
    "# SECTION 02. 머신러닝 모델링 및 하이퍼 파라미터 튜닝 실습하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "## 1. [회귀] 항공권 가격 예측 모델링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터 불러오기"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:06:42.335927Z",
     "start_time": "2024-08-22T02:06:42.333114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:06:43.930066Z",
     "start_time": "2024-08-22T02:06:43.750721Z"
    }
   },
   "source": [
    "# 판다스 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "cdf = pd.read_csv(\"./dataset/Clean_Dataset.csv\")\n",
    "\n",
    "# 학습시간 단축을 위해 5000건만 추출하기\n",
    "cdf = cdf[:5000]\n",
    "\n",
    "# 데이터 확인하기\n",
    "cdf.head(1) "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0   airline   flight source_city departure_time stops  \\\n",
       "0           0  SpiceJet  SG-8709       Delhi        Evening  zero   \n",
       "\n",
       "  arrival_time destination_city    class  duration  days_left  price  \n",
       "0        Night           Mumbai  Economy      2.17          1   5953  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) Unnamed 삭제 및 데이터 기초 통계 정보 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-08-22T02:06:58.447560Z",
     "start_time": "2024-08-22T02:06:58.440538Z"
    }
   },
   "source": [
    "# Unnamed: 0 데이터 분포 확인하기\n",
    "cdf[\"Unnamed: 0\"].value_counts() "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "0       1\n",
       "3330    1\n",
       "3337    1\n",
       "3336    1\n",
       "3335    1\n",
       "       ..\n",
       "1666    1\n",
       "1665    1\n",
       "1664    1\n",
       "1663    1\n",
       "4999    1\n",
       "Name: count, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:07:12.998975Z",
     "start_time": "2024-08-22T02:07:12.994019Z"
    }
   },
   "source": [
    "# Unnamed 컬럼 삭제하기\n",
    "cdf.drop(\"Unnamed: 0\", axis = 1, inplace =True)"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:07:17.564739Z",
     "start_time": "2024-08-22T02:07:17.548784Z"
    }
   },
   "source": [
    " # 기초 통계정보 확인하기\n",
    "cdf.describe(include='all')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        airline  flight source_city departure_time stops arrival_time  \\\n",
       "count      5000    5000        5000           5000  5000         5000   \n",
       "unique        6     222           1              6     3            6   \n",
       "top     Vistara  UK-819       Delhi        Evening   one        Night   \n",
       "freq       1496      90        5000           1391  3619         1702   \n",
       "mean        NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "std         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "min         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "25%         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "50%         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "75%         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "max         NaN     NaN         NaN            NaN   NaN          NaN   \n",
       "\n",
       "       destination_city    class     duration    days_left         price  \n",
       "count              5000     5000  5000.000000  5000.000000   5000.000000  \n",
       "unique                1        1          NaN          NaN           NaN  \n",
       "top              Mumbai  Economy          NaN          NaN           NaN  \n",
       "freq               5000     5000          NaN          NaN           NaN  \n",
       "mean                NaN      NaN     9.665682    14.216800   7589.786600  \n",
       "std                 NaN      NaN     7.247512     7.109536   4476.362204  \n",
       "min                 NaN      NaN     2.000000     1.000000   2409.000000  \n",
       "25%                 NaN      NaN     2.330000     8.000000   4678.000000  \n",
       "50%                 NaN      NaN     7.670000    14.000000   5955.000000  \n",
       "75%                 NaN      NaN    14.080000    20.000000  10549.000000  \n",
       "max                 NaN      NaN    30.080000    26.000000  31260.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-819</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>one</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1496</td>\n",
       "      <td>90</td>\n",
       "      <td>5000</td>\n",
       "      <td>1391</td>\n",
       "      <td>3619</td>\n",
       "      <td>1702</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.665682</td>\n",
       "      <td>14.216800</td>\n",
       "      <td>7589.786600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.247512</td>\n",
       "      <td>7.109536</td>\n",
       "      <td>4476.362204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.330000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5955.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.080000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.080000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>31260.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Null 데이터 분석 및 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:07:21.981166Z",
     "start_time": "2024-08-22T02:07:21.975115Z"
    }
   },
   "source": [
    "# info를 통해 Null 데이터 및 type 확인 있는지 1차 확인하기(isna를 사용해도 됨)\n",
    "print(\"Null 데이터 확인\")\n",
    "cdf.info() "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null 데이터 확인\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   airline           5000 non-null   object \n",
      " 1   flight            5000 non-null   object \n",
      " 2   source_city       5000 non-null   object \n",
      " 3   departure_time    5000 non-null   object \n",
      " 4   stops             5000 non-null   object \n",
      " 5   arrival_time      5000 non-null   object \n",
      " 6   destination_city  5000 non-null   object \n",
      " 7   class             5000 non-null   object \n",
      " 8   duration          5000 non-null   float64\n",
      " 9   days_left         5000 non-null   int64  \n",
      " 10  price             5000 non-null   int64  \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 429.8+ KB\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) airline 컬럼 분석 및 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:07:28.160924Z",
     "start_time": "2024-08-22T02:07:28.156423Z"
    }
   },
   "source": [
    "# 첫 번째 컬럼이 의미있는 컬럼인지 확인하기 위해 value_count로 분포 확인하기\n",
    "cdf.airline.value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline\n",
       "Vistara      1496\n",
       "Air_India    1311\n",
       "Indigo        813\n",
       "GO_FIRST      801\n",
       "SpiceJet      296\n",
       "AirAsia       283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:07:39.757249Z",
     "start_time": "2024-08-22T02:07:39.754420Z"
    }
   },
   "source": [
    "# 그래프 라이브러리 불러오기(matplotlib, seaborn)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:08:20.698557Z",
     "start_time": "2024-08-22T02:08:20.572339Z"
    }
   },
   "source": [
    "# Seaborn 으로 막대그래프 그리기\n",
    "# 배경 사이즈 설정하기\n",
    "plt.figure(figsize=(5,5))\n",
    "# 막대그래프 차트 그리기 \n",
    "ax = sns.barplot(x='airline', y='price', data=cdf)\n",
    "# 상단 타이틀 지정하기\n",
    "ax.set(title='airline & price')\n",
    "# 그래프 출력하기\n",
    "plt.show() "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) flight 컬럼 분석 및 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:08:24.369623Z",
     "start_time": "2024-08-22T02:08:24.363955Z"
    }
   },
   "source": [
    "# 2번째 flight 값 재확인하기\n",
    "cdf.head(1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    airline   flight source_city departure_time stops arrival_time  \\\n",
       "0  SpiceJet  SG-8709       Delhi        Evening  zero        Night   \n",
       "\n",
       "  destination_city    class  duration  days_left  price  \n",
       "0           Mumbai  Economy      2.17          1   5953  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:08:26.129680Z",
     "start_time": "2024-08-22T02:08:26.124153Z"
    }
   },
   "source": [
    "# flight column 분포 확인하기\n",
    "cdf.flight.value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flight\n",
       "UK-819     90\n",
       "UK-879     62\n",
       "UK-899     61\n",
       "UK-705     61\n",
       "UK-835     60\n",
       "           ..\n",
       "AI-9939     2\n",
       "I5-881      2\n",
       "I5-744      1\n",
       "SG-9974     1\n",
       "SG-8339     1\n",
       "Name: count, Length: 222, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:08:42.121776Z",
     "start_time": "2024-08-22T02:08:42.117555Z"
    }
   },
   "source": [
    "# flight 칼럼은 다른 칼럼과 의미가 중복되는 것으로 보이므로 삭제하기\n",
    "cdf.drop('flight', axis=1, inplace=True)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:08:49.219784Z",
     "start_time": "2024-08-22T02:08:49.216175Z"
    }
   },
   "source": [
    "# 잘 삭제되었는지 shape 확인하기\n",
    "cdf.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 원핫 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:08:57.614769Z",
     "start_time": "2024-08-22T02:08:57.607419Z"
    }
   },
   "source": [
    "# one_hot 인코딩을 위해 get_dummies 처리하기\n",
    "dummies_cdf = pd.get_dummies(cdf, \n",
    "               columns=[\"airline\", 'source_city','departure_time', 'stops','arrival_time', 'destination_city', 'class'],\n",
    "               drop_first=True\n",
    "              )"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:08:59.650973Z",
     "start_time": "2024-08-22T02:08:59.648313Z"
    }
   },
   "source": [
    "# 인코딩 확인하기\n",
    "print(f'''원핫인코딩 전 {cdf.shape}\n",
    "원핫인코딩 후 {dummies_cdf.shape}''')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원핫인코딩 전 (5000, 10)\n",
      "원핫인코딩 후 (5000, 20)\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (6) 학습 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:06.475888Z",
     "start_time": "2024-08-22T02:09:06.471327Z"
    }
   },
   "source": [
    "# 데이터프레임에서 타깃 변수만 y로 추출하기\n",
    "y = dummies_cdf.price\n",
    "\n",
    "# y 값의 형태 확인하기\n",
    "y.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5953\n",
       "1    5953\n",
       "2    5956\n",
       "3    5955\n",
       "4    5955\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:17.846808Z",
     "start_time": "2024-08-22T02:09:17.836740Z"
    }
   },
   "source": [
    "# 데이터프레임에서 타깃 변수를 제외한 입력 데이터세트를 생성하기\n",
    "x = dummies_cdf.drop('price', axis=1)\n",
    "\n",
    "x.head(5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   duration  days_left  airline_Air_India  airline_GO_FIRST  airline_Indigo  \\\n",
       "0      2.17          1              False             False           False   \n",
       "1      2.33          1              False             False           False   \n",
       "2      2.17          1              False             False           False   \n",
       "3      2.25          1              False             False           False   \n",
       "4      2.33          1              False             False           False   \n",
       "\n",
       "   airline_SpiceJet  airline_Vistara  departure_time_Early_Morning  \\\n",
       "0              True            False                         False   \n",
       "1              True            False                          True   \n",
       "2             False            False                          True   \n",
       "3             False             True                         False   \n",
       "4             False             True                         False   \n",
       "\n",
       "   departure_time_Evening  departure_time_Late_Night  departure_time_Morning  \\\n",
       "0                    True                      False                   False   \n",
       "1                   False                      False                   False   \n",
       "2                   False                      False                   False   \n",
       "3                   False                      False                    True   \n",
       "4                   False                      False                    True   \n",
       "\n",
       "   departure_time_Night  stops_two_or_more  stops_zero  \\\n",
       "0                 False              False        True   \n",
       "1                 False              False        True   \n",
       "2                 False              False        True   \n",
       "3                 False              False        True   \n",
       "4                 False              False        True   \n",
       "\n",
       "   arrival_time_Early_Morning  arrival_time_Evening  arrival_time_Late_Night  \\\n",
       "0                       False                 False                    False   \n",
       "1                       False                 False                    False   \n",
       "2                        True                 False                    False   \n",
       "3                       False                 False                    False   \n",
       "4                       False                 False                    False   \n",
       "\n",
       "   arrival_time_Morning  arrival_time_Night  \n",
       "0                 False                True  \n",
       "1                  True               False  \n",
       "2                 False               False  \n",
       "3                 False               False  \n",
       "4                  True               False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>airline_Air_India</th>\n",
       "      <th>airline_GO_FIRST</th>\n",
       "      <th>airline_Indigo</th>\n",
       "      <th>airline_SpiceJet</th>\n",
       "      <th>airline_Vistara</th>\n",
       "      <th>departure_time_Early_Morning</th>\n",
       "      <th>departure_time_Evening</th>\n",
       "      <th>departure_time_Late_Night</th>\n",
       "      <th>departure_time_Morning</th>\n",
       "      <th>departure_time_Night</th>\n",
       "      <th>stops_two_or_more</th>\n",
       "      <th>stops_zero</th>\n",
       "      <th>arrival_time_Early_Morning</th>\n",
       "      <th>arrival_time_Evening</th>\n",
       "      <th>arrival_time_Late_Night</th>\n",
       "      <th>arrival_time_Morning</th>\n",
       "      <th>arrival_time_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:19.562652Z",
     "start_time": "2024-08-22T02:09:19.560563Z"
    }
   },
   "source": [
    "# shape 확인하기\n",
    "x.shape, y.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 19), (5000,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 모델 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 머신러닝 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:27.095685Z",
     "start_time": "2024-08-22T02:09:25.323095Z"
    }
   },
   "source": [
    "# xgboost, lightgbm모델 설치하기\n",
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (2.1.1)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from xgboost) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from xgboost) (1.13.1)\r\n",
      "Requirement already satisfied: lightgbm in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (4.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from lightgbm) (1.26.4)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from lightgbm) (1.13.1)\r\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:37.464218Z",
     "start_time": "2024-08-22T02:09:37.461375Z"
    }
   },
   "source": [
    "# scikit learn 기반 라이브러리 불러오기\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# scikit learn 외 라이브러리 불러오기\n",
    "from xgboost import XGBRFRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# 학습_검증 데이터 분리 라이브러리 불러오기\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 머신러닝 모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:40.642492Z",
     "start_time": "2024-08-22T02:09:40.639260Z"
    }
   },
   "source": [
    "# 머신러닝 모델 생성하기\n",
    "# 모델 생성 시 n_jobs 옵션이 있는 모델은 -1을 적용하여 동작 시키는 것을 권유함\n",
    "lr = LinearRegression( n_jobs=-1)\n",
    "dtr = DecisionTreeRegressor( random_state=1)\n",
    "rfr = RandomForestRegressor( random_state=1)\n",
    "gbr = GradientBoostingRegressor( random_state=1)\n",
    "xgbr = XGBRFRegressor(n_jobs=-1, random_state=1)\n",
    "etr = ExtraTreesRegressor(n_jobs=-1, random_state=1)\n",
    "lgbmr = LGBMRegressor(n_jobs=-1, random_state=1)"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:42.608694Z",
     "start_time": "2024-08-22T02:09:42.605109Z"
    }
   },
   "source": [
    "# 훈련 데이터 분할하기\n",
    "x_train, x_test, y_train ,y_test = train_test_split(x, y , \n",
    "                   test_size=0.3,\n",
    "                   random_state=2023, # 서로 다른 결과를 나타내지 않기\n",
    "                )"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:44.927318Z",
     "start_time": "2024-08-22T02:09:44.924471Z"
    }
   },
   "source": [
    "# shape 확인하기\n",
    "x_test.shape, y_test.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 19), (1500,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:09:46.463997Z",
     "start_time": "2024-08-22T02:09:46.460694Z"
    }
   },
   "source": [
    "# shape 확인하기\n",
    "x_train.shape, y_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500, 19), (3500,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 머신러닝 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:10:06.596530Z",
     "start_time": "2024-08-22T02:10:05.742818Z"
    }
   },
   "source": [
    "%%time \n",
    "# 머신러닝 모델(base 모델) 학습하기\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "dtr.fit(x_train, y_train)\n",
    "rfr.fit(x_train, y_train)\n",
    "gbr.fit(x_train, y_train)\n",
    "xgbr.fit(x_train, y_train)\n",
    "etr.fit(x_train, y_train)\n",
    "lgbmr.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7548.349714\n",
      "CPU times: user 2.32 s, sys: 2.58 s, total: 4.9 s\n",
      "Wall time: 850 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(n_jobs=-1, random_state=1)"
      ],
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(n_jobs=-1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(n_jobs=-1, random_state=1)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 머신러닝 모델 성능 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:10:12.202042Z",
     "start_time": "2024-08-22T02:10:12.199315Z"
    }
   },
   "source": [
    "# 결과 검증용 라이브러리 불러오기\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T02:10:14.555550Z",
     "start_time": "2024-08-22T02:10:14.549853Z"
    }
   },
   "source": [
    "# 리스트에 모델 입력하기\n",
    "models = [lr, dtr, rfr, gbr, xgbr, etr, lgbmr]"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T04:02:10.154033Z",
     "start_time": "2024-08-22T04:02:10.023879Z"
    }
   },
   "source": [
    "r2_score_list = []\n",
    "rmse_score_list = []\n",
    "\n",
    "# 모델 결과 확인하기\n",
    "for model in models:\n",
    "    pred = model.predict(x_test)\n",
    "    r2_score_list.append(\n",
    "        round(r2_score(y_test, pred\n",
    "                       ),5)\n",
    "    )\n",
    "    # squared를 False로 하면 RMSE가 됨\n",
    "    rmse_score_list.append(\n",
    "        round(mean_squared_error(\n",
    "            y_test, pred, squared=False),5)\n",
    "    ) \n",
    "    \n",
    "r2_score_df = pd.DataFrame([r2_score_list, rmse_score_list], \n",
    "                           columns=[\"lr\", \"dtr\", \"rfr\", \"gbr\", \"xgbr\", \"etr\",\"lgbmr\"],\n",
    "                           index=[\"r2\", \"rmse\"]\n",
    "                          )\n",
    "\n",
    "r2_score_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              lr         dtr         rfr         gbr        xgbr         etr  \\\n",
       "r2       0.61523     0.70927     0.79828     0.76376     0.72916     0.74605   \n",
       "rmse  2818.92861  2450.35112  2041.09163  2208.84675  2365.06569  2290.13674   \n",
       "\n",
       "           lgbmr  \n",
       "r2       0.79957  \n",
       "rmse  2034.53417  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>dtr</th>\n",
       "      <th>rfr</th>\n",
       "      <th>gbr</th>\n",
       "      <th>xgbr</th>\n",
       "      <th>etr</th>\n",
       "      <th>lgbmr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.61523</td>\n",
       "      <td>0.70927</td>\n",
       "      <td>0.79828</td>\n",
       "      <td>0.76376</td>\n",
       "      <td>0.72916</td>\n",
       "      <td>0.74605</td>\n",
       "      <td>0.79957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>2818.92861</td>\n",
       "      <td>2450.35112</td>\n",
       "      <td>2041.09163</td>\n",
       "      <td>2208.84675</td>\n",
       "      <td>2365.06569</td>\n",
       "      <td>2290.13674</td>\n",
       "      <td>2034.53417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 최적의 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T04:02:18.140501Z",
     "start_time": "2024-08-22T04:02:18.137607Z"
    }
   },
   "source": [
    "# GridSearchCV 라이브러리 불러오기\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T04:02:21.562575Z",
     "start_time": "2024-08-22T04:02:21.559479Z"
    }
   },
   "source": [
    "# 비교 하이퍼파라미터 선정하기\n",
    "param_grid = { \n",
    "    'learning_rate': [0.1, 0.01, 0.003],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'max_depth' : [20, 30, 40],\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T04:07:28.479221Z",
     "start_time": "2024-08-22T04:07:19.499006Z"
    }
   },
   "source": [
    "# 최적 하이퍼파라미터 검색하기\n",
    "cv_lgbmr = GridSearchCV(estimator=lgbmr,\n",
    "                      param_grid=param_grid,\n",
    "                      cv= 5,\n",
    "                      verbose=1\n",
    "                     )\n",
    "\n",
    "cv_lgbmr.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7548.349714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMRegressor(n_jobs=-1, random_state=1),\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7],\n",
       "                         'learning_rate': [0.1, 0.01, 0.003],\n",
       "                         'max_depth': [20, 30, 40]},\n",
       "             verbose=1)"
      ],
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMRegressor(n_jobs=-1, random_state=1),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.7],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 0.01, 0.003],\n",
       "                         &#x27;max_depth&#x27;: [20, 30, 40]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=LGBMRegressor(n_jobs=-1, random_state=1),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.7],\n",
       "                         &#x27;learning_rate&#x27;: [0.1, 0.01, 0.003],\n",
       "                         &#x27;max_depth&#x27;: [20, 30, 40]},\n",
       "             verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(colsample_bytree=0.7, max_depth=30, n_jobs=-1, random_state=1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(colsample_bytree=0.7, max_depth=30, n_jobs=-1, random_state=1)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T04:09:13.263934Z",
     "start_time": "2024-08-22T04:09:13.260442Z"
    }
   },
   "source": [
    "# 최적 하이퍼파라미터 조합 확인하기\n",
    "cv_lgbmr.best_params_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 30}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T04:15:42.922840Z",
     "start_time": "2024-08-22T04:15:42.917287Z"
    }
   },
   "source": [
    "# 최적 하이퍼파라미터 결과 확인하기\n",
    "cv_lgbmr.best_score_ # 예측 정확도 확인하기"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803203388259023"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T04:15:52.391247Z",
     "start_time": "2024-08-22T04:15:52.276892Z"
    }
   },
   "source": [
    "# 머신러닝 모델 검증하기\n",
    "# 최적의 하이퍼파라미터로 재학습하기\n",
    "best_lgbmr = LGBMRegressor(max_depth= 30, \n",
    "                                 colsample_bytree= 0.7,\n",
    "                                 learning_rate= 0.1,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state= 1\n",
    "                                )\n",
    "best_lgbmr.fit(x_train,y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7548.349714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(colsample_bytree=0.7, max_depth=30, n_jobs=-1, random_state=1)"
      ],
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(colsample_bytree=0.7, max_depth=30, n_jobs=-1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMRegressor<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(colsample_bytree=0.7, max_depth=30, n_jobs=-1, random_state=1)</pre></div> </div></div></div></div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T04:16:02.990230Z",
     "start_time": "2024-08-22T04:16:02.981432Z"
    }
   },
   "source": [
    "# 모델 성능 검증하기\n",
    "b_pred=best_lgbmr.predict(x_test)\n",
    "print('r2 : ', round(r2_score(y_test, b_pred),5))\n",
    "print('rmse : ', round(mean_squared_error(y_test, b_pred, squared=False),5))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 :  0.80154\n",
      "rmse :  2024.49371\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:22:04.380681Z",
     "start_time": "2024-08-22T07:22:04.377831Z"
    }
   },
   "source": [
    "# RandomizedSearchCV 라이브러리 호출하기\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# 비교 파라미터 선정하기\n",
    "param_dists = { \n",
    "    'learning_rate': [0.1 ,0.01, 0.003],\n",
    "    'colsample_bytree': [0.5, 0.7],\n",
    "    'max_depth' : [ 20,30,40],\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:22:41.381221Z",
     "start_time": "2024-08-22T07:22:32.968192Z"
    }
   },
   "source": [
    "%%time\n",
    "# 최적 파라미터 검색하기\n",
    "cv_lgbmr = RandomizedSearchCV(estimator=lgbmr,\n",
    "                      param_distributions=param_dists,\n",
    "                      n_iter = 500,\n",
    "                      cv= 5,\n",
    "                      verbose=1\n",
    "                     )\n",
    "\n",
    "cv_lgbmr.fit(x_train, y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7601.929643\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7576.702500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7485.184643\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 225\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7503.671429\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224\n",
      "[LightGBM] [Info] Number of data points in the train set: 2800, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7574.260357\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 7548.349714\n",
      "CPU times: user 52.2 s, sys: 25.2 s, total: 1min 17s\n",
      "Wall time: 8.41 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMRegressor(n_jobs=-1, random_state=1),\n",
       "                   n_iter=500,\n",
       "                   param_distributions={'colsample_bytree': [0.5, 0.7],\n",
       "                                        'learning_rate': [0.1, 0.01, 0.003],\n",
       "                                        'max_depth': [20, 30, 40]},\n",
       "                   verbose=1)"
      ],
      "text/html": [
       "<style>#sk-container-id-7 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-7 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-7 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-7 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-7 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-7 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-7 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-7 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-7 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-7 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-7 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(n_jobs=-1, random_state=1),\n",
       "                   n_iter=500,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.5, 0.7],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1, 0.01, 0.003],\n",
       "                                        &#x27;max_depth&#x27;: [20, 30, 40]},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(n_jobs=-1, random_state=1),\n",
       "                   n_iter=500,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.5, 0.7],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1, 0.01, 0.003],\n",
       "                                        &#x27;max_depth&#x27;: [20, 30, 40]},\n",
       "                   verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(colsample_bytree=0.7, max_depth=30, n_jobs=-1, random_state=1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(colsample_bytree=0.7, max_depth=30, n_jobs=-1, random_state=1)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:22:51.810560Z",
     "start_time": "2024-08-22T07:22:51.807857Z"
    }
   },
   "source": [
    "# 최적의 파라미터 조합 확인하기\n",
    "cv_lgbmr.best_params_"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'learning_rate': 0.1, 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [분류] 항공사 고객 만족 여부 예측 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:23:24.167200Z",
     "start_time": "2024-08-22T07:23:24.052580Z"
    }
   },
   "source": [
    "# 판다스 라이브러리 불러오기\n",
    "import pandas as pd \n",
    "\n",
    "# 파일이 저장된 경로에서 데이터 로딩하기\n",
    "cdf = pd.read_csv(\"./dataset/Invistico_Airline.csv\") \n",
    "\n",
    "# 학습시간 단축을 위해 5,000건만 추출하기\n",
    "cdf = cdf[:5000]\n",
    "\n",
    "# 중간에 Column 이 '...'으로 표시되는 것 확인하기\n",
    "cdf.head(1) "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  satisfaction  Gender   Customer Type  Age   Type of Travel Class  \\\n",
       "0    satisfied  Female  Loyal Customer   65  Personal Travel   Eco   \n",
       "\n",
       "   Flight Distance  Seat comfort  Departure/Arrival time convenient  \\\n",
       "0              265             0                                  0   \n",
       "\n",
       "   Food and drink  ...  Online support  Ease of Online booking  \\\n",
       "0               0  ...               2                       3   \n",
       "\n",
       "   On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
       "0                 3                 0                 3                5   \n",
       "\n",
       "   Cleanliness  Online boarding  Departure Delay in Minutes  \\\n",
       "0            3                2                           0   \n",
       "\n",
       "   Arrival Delay in Minutes  \n",
       "0                       0.0  \n",
       "\n",
       "[1 rows x 23 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>...</th>\n",
       "      <th>Online support</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>65</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:23:29.666177Z",
     "start_time": "2024-08-22T07:23:29.657684Z"
    }
   },
   "source": [
    "# 모든 칼럼을 표시하기\n",
    "pd.set_option('display.max_columns', None) \n",
    "cdf.head(1)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  satisfaction  Gender   Customer Type  Age   Type of Travel Class  \\\n",
       "0    satisfied  Female  Loyal Customer   65  Personal Travel   Eco   \n",
       "\n",
       "   Flight Distance  Seat comfort  Departure/Arrival time convenient  \\\n",
       "0              265             0                                  0   \n",
       "\n",
       "   Food and drink  Gate location  Inflight wifi service  \\\n",
       "0               0              2                      2   \n",
       "\n",
       "   Inflight entertainment  Online support  Ease of Online booking  \\\n",
       "0                       4               2                       3   \n",
       "\n",
       "   On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
       "0                 3                 0                 3                5   \n",
       "\n",
       "   Cleanliness  Online boarding  Departure Delay in Minutes  \\\n",
       "0            3                2                           0   \n",
       "\n",
       "   Arrival Delay in Minutes  \n",
       "0                       0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>Online support</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>65</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 레이블 불균형 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:23:44.289120Z",
     "start_time": "2024-08-22T07:23:44.283645Z"
    }
   },
   "source": [
    "# 타깃 변수 satisfaction 칼럼의 레이블 별 갯수를 출력하기\n",
    "cdf.satisfaction.value_counts() "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction\n",
       "satisfied       2869\n",
       "dissatisfied    2131\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:23:48.359499Z",
     "start_time": "2024-08-22T07:23:48.292028Z"
    }
   },
   "source": [
    "# 그래프를 활용하기 위한 라이브러리 불러오기\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# 막대그래프로 표현하기\n",
    "cdf['satisfaction'].value_counts().plot(kind='bar') \n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) null 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:23:51.522082Z",
     "start_time": "2024-08-22T07:23:51.515708Z"
    }
   },
   "source": [
    "# null 데이터 확인하기\n",
    "cdf.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   satisfaction                       5000 non-null   object \n",
      " 1   Gender                             5000 non-null   object \n",
      " 2   Customer Type                      5000 non-null   object \n",
      " 3   Age                                5000 non-null   int64  \n",
      " 4   Type of Travel                     5000 non-null   object \n",
      " 5   Class                              5000 non-null   object \n",
      " 6   Flight Distance                    5000 non-null   int64  \n",
      " 7   Seat comfort                       5000 non-null   int64  \n",
      " 8   Departure/Arrival time convenient  5000 non-null   int64  \n",
      " 9   Food and drink                     5000 non-null   int64  \n",
      " 10  Gate location                      5000 non-null   int64  \n",
      " 11  Inflight wifi service              5000 non-null   int64  \n",
      " 12  Inflight entertainment             5000 non-null   int64  \n",
      " 13  Online support                     5000 non-null   int64  \n",
      " 14  Ease of Online booking             5000 non-null   int64  \n",
      " 15  On-board service                   5000 non-null   int64  \n",
      " 16  Leg room service                   5000 non-null   int64  \n",
      " 17  Baggage handling                   5000 non-null   int64  \n",
      " 18  Checkin service                    5000 non-null   int64  \n",
      " 19  Cleanliness                        5000 non-null   int64  \n",
      " 20  Online boarding                    5000 non-null   int64  \n",
      " 21  Departure Delay in Minutes         5000 non-null   int64  \n",
      " 22  Arrival Delay in Minutes           4973 non-null   float64\n",
      "dtypes: float64(1), int64(17), object(5)\n",
      "memory usage: 898.6+ KB\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:24:01.066759Z",
     "start_time": "2024-08-22T07:24:01.058766Z"
    }
   },
   "source": [
    "# 결측치 행 삭제하기\n",
    "cdf.dropna(axis=0, inplace=True)\n",
    "\n",
    "# 삭제 여부 확인하기\n",
    "cdf.info() "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4973 entries, 0 to 4999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   satisfaction                       4973 non-null   object \n",
      " 1   Gender                             4973 non-null   object \n",
      " 2   Customer Type                      4973 non-null   object \n",
      " 3   Age                                4973 non-null   int64  \n",
      " 4   Type of Travel                     4973 non-null   object \n",
      " 5   Class                              4973 non-null   object \n",
      " 6   Flight Distance                    4973 non-null   int64  \n",
      " 7   Seat comfort                       4973 non-null   int64  \n",
      " 8   Departure/Arrival time convenient  4973 non-null   int64  \n",
      " 9   Food and drink                     4973 non-null   int64  \n",
      " 10  Gate location                      4973 non-null   int64  \n",
      " 11  Inflight wifi service              4973 non-null   int64  \n",
      " 12  Inflight entertainment             4973 non-null   int64  \n",
      " 13  Online support                     4973 non-null   int64  \n",
      " 14  Ease of Online booking             4973 non-null   int64  \n",
      " 15  On-board service                   4973 non-null   int64  \n",
      " 16  Leg room service                   4973 non-null   int64  \n",
      " 17  Baggage handling                   4973 non-null   int64  \n",
      " 18  Checkin service                    4973 non-null   int64  \n",
      " 19  Cleanliness                        4973 non-null   int64  \n",
      " 20  Online boarding                    4973 non-null   int64  \n",
      " 21  Departure Delay in Minutes         4973 non-null   int64  \n",
      " 22  Arrival Delay in Minutes           4973 non-null   float64\n",
      "dtypes: float64(1), int64(17), object(5)\n",
      "memory usage: 932.4+ KB\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 학습 데이터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:24:04.932100Z",
     "start_time": "2024-08-22T07:24:04.928650Z"
    }
   },
   "source": [
    "# 라벨 데이터 y를 나누기\n",
    "\n",
    "# cdf 데이터프레임에서 label만 y로 추출하기\n",
    "y = cdf.satisfaction \n",
    "\n",
    "# y 값의 형태 확인하기\n",
    "y.head(5) "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    satisfied\n",
       "1    satisfied\n",
       "2    satisfied\n",
       "3    satisfied\n",
       "4    satisfied\n",
       "Name: satisfaction, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:24:07.103124Z",
     "start_time": "2024-08-22T07:24:07.097499Z"
    }
   },
   "source": [
    "# price 칼럼 삭제하고 입력 데이터 만들기\n",
    "x = cdf.drop(\"satisfaction\", axis=1 ) \n",
    "\n",
    "# 타깃 변수 데이터 만들기\n",
    "y = cdf.satisfaction \n",
    "\n",
    "# 데이터 크기 확인하기\n",
    "x.shape, y.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4973, 22), (4973,))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4)원핫 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:24:16.730220Z",
     "start_time": "2024-08-22T07:24:16.720217Z"
    }
   },
   "source": [
    "# info 메소드로 데이터 유형 확인하기\n",
    "x.info() \n",
    "x.head(5) "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4973 entries, 0 to 4999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Gender                             4973 non-null   object \n",
      " 1   Customer Type                      4973 non-null   object \n",
      " 2   Age                                4973 non-null   int64  \n",
      " 3   Type of Travel                     4973 non-null   object \n",
      " 4   Class                              4973 non-null   object \n",
      " 5   Flight Distance                    4973 non-null   int64  \n",
      " 6   Seat comfort                       4973 non-null   int64  \n",
      " 7   Departure/Arrival time convenient  4973 non-null   int64  \n",
      " 8   Food and drink                     4973 non-null   int64  \n",
      " 9   Gate location                      4973 non-null   int64  \n",
      " 10  Inflight wifi service              4973 non-null   int64  \n",
      " 11  Inflight entertainment             4973 non-null   int64  \n",
      " 12  Online support                     4973 non-null   int64  \n",
      " 13  Ease of Online booking             4973 non-null   int64  \n",
      " 14  On-board service                   4973 non-null   int64  \n",
      " 15  Leg room service                   4973 non-null   int64  \n",
      " 16  Baggage handling                   4973 non-null   int64  \n",
      " 17  Checkin service                    4973 non-null   int64  \n",
      " 18  Cleanliness                        4973 non-null   int64  \n",
      " 19  Online boarding                    4973 non-null   int64  \n",
      " 20  Departure Delay in Minutes         4973 non-null   int64  \n",
      " 21  Arrival Delay in Minutes           4973 non-null   float64\n",
      "dtypes: float64(1), int64(17), object(4)\n",
      "memory usage: 893.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Gender   Customer Type  Age   Type of Travel     Class  Flight Distance  \\\n",
       "0  Female  Loyal Customer   65  Personal Travel       Eco              265   \n",
       "1    Male  Loyal Customer   47  Personal Travel  Business             2464   \n",
       "2  Female  Loyal Customer   15  Personal Travel       Eco             2138   \n",
       "3  Female  Loyal Customer   60  Personal Travel       Eco              623   \n",
       "4  Female  Loyal Customer   70  Personal Travel       Eco              354   \n",
       "\n",
       "   Seat comfort  Departure/Arrival time convenient  Food and drink  \\\n",
       "0             0                                  0               0   \n",
       "1             0                                  0               0   \n",
       "2             0                                  0               0   \n",
       "3             0                                  0               0   \n",
       "4             0                                  0               0   \n",
       "\n",
       "   Gate location  Inflight wifi service  Inflight entertainment  \\\n",
       "0              2                      2                       4   \n",
       "1              3                      0                       2   \n",
       "2              3                      2                       0   \n",
       "3              3                      3                       4   \n",
       "4              3                      4                       3   \n",
       "\n",
       "   Online support  Ease of Online booking  On-board service  Leg room service  \\\n",
       "0               2                       3                 3                 0   \n",
       "1               2                       3                 4                 4   \n",
       "2               2                       2                 3                 3   \n",
       "3               3                       1                 1                 0   \n",
       "4               4                       2                 2                 0   \n",
       "\n",
       "   Baggage handling  Checkin service  Cleanliness  Online boarding  \\\n",
       "0                 3                5            3                2   \n",
       "1                 4                2            3                2   \n",
       "2                 4                4            4                2   \n",
       "3                 1                4            1                3   \n",
       "4                 2                4            2                5   \n",
       "\n",
       "   Departure Delay in Minutes  Arrival Delay in Minutes  \n",
       "0                           0                       0.0  \n",
       "1                         310                     305.0  \n",
       "2                           0                       0.0  \n",
       "3                           0                       0.0  \n",
       "4                           0                       0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>Online support</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>65</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>47</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>2464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>15</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>2138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>60</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>70</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:24:25.478220Z",
     "start_time": "2024-08-22T07:24:25.460826Z"
    }
   },
   "source": [
    "# get_dummies 함수를 활용해 object 유형의 칼럼을 원핫 인코딩하기\n",
    "x_gd = pd.get_dummies(x, \n",
    "               columns=['Gender', 'Customer Type',\n",
    "                        'Type of Travel', 'Class'], \n",
    "               drop_first=False)\n",
    "x_gd.info()\n",
    "x_gd.head(5)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4973 entries, 0 to 4999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Age                                4973 non-null   int64  \n",
      " 1   Flight Distance                    4973 non-null   int64  \n",
      " 2   Seat comfort                       4973 non-null   int64  \n",
      " 3   Departure/Arrival time convenient  4973 non-null   int64  \n",
      " 4   Food and drink                     4973 non-null   int64  \n",
      " 5   Gate location                      4973 non-null   int64  \n",
      " 6   Inflight wifi service              4973 non-null   int64  \n",
      " 7   Inflight entertainment             4973 non-null   int64  \n",
      " 8   Online support                     4973 non-null   int64  \n",
      " 9   Ease of Online booking             4973 non-null   int64  \n",
      " 10  On-board service                   4973 non-null   int64  \n",
      " 11  Leg room service                   4973 non-null   int64  \n",
      " 12  Baggage handling                   4973 non-null   int64  \n",
      " 13  Checkin service                    4973 non-null   int64  \n",
      " 14  Cleanliness                        4973 non-null   int64  \n",
      " 15  Online boarding                    4973 non-null   int64  \n",
      " 16  Departure Delay in Minutes         4973 non-null   int64  \n",
      " 17  Arrival Delay in Minutes           4973 non-null   float64\n",
      " 18  Gender_Female                      4973 non-null   bool   \n",
      " 19  Gender_Male                        4973 non-null   bool   \n",
      " 20  Customer Type_Loyal Customer       4973 non-null   bool   \n",
      " 21  Type of Travel_Personal Travel     4973 non-null   bool   \n",
      " 22  Class_Business                     4973 non-null   bool   \n",
      " 23  Class_Eco                          4973 non-null   bool   \n",
      " 24  Class_Eco Plus                     4973 non-null   bool   \n",
      "dtypes: bool(7), float64(1), int64(17)\n",
      "memory usage: 772.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Age  Flight Distance  Seat comfort  Departure/Arrival time convenient  \\\n",
       "0   65              265             0                                  0   \n",
       "1   47             2464             0                                  0   \n",
       "2   15             2138             0                                  0   \n",
       "3   60              623             0                                  0   \n",
       "4   70              354             0                                  0   \n",
       "\n",
       "   Food and drink  Gate location  Inflight wifi service  \\\n",
       "0               0              2                      2   \n",
       "1               0              3                      0   \n",
       "2               0              3                      2   \n",
       "3               0              3                      3   \n",
       "4               0              3                      4   \n",
       "\n",
       "   Inflight entertainment  Online support  Ease of Online booking  \\\n",
       "0                       4               2                       3   \n",
       "1                       2               2                       3   \n",
       "2                       0               2                       2   \n",
       "3                       4               3                       1   \n",
       "4                       3               4                       2   \n",
       "\n",
       "   On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
       "0                 3                 0                 3                5   \n",
       "1                 4                 4                 4                2   \n",
       "2                 3                 3                 4                4   \n",
       "3                 1                 0                 1                4   \n",
       "4                 2                 0                 2                4   \n",
       "\n",
       "   Cleanliness  Online boarding  Departure Delay in Minutes  \\\n",
       "0            3                2                           0   \n",
       "1            3                2                         310   \n",
       "2            4                2                           0   \n",
       "3            1                3                           0   \n",
       "4            2                5                           0   \n",
       "\n",
       "   Arrival Delay in Minutes  Gender_Female  Gender_Male  \\\n",
       "0                       0.0           True        False   \n",
       "1                     305.0          False         True   \n",
       "2                       0.0           True        False   \n",
       "3                       0.0           True        False   \n",
       "4                       0.0           True        False   \n",
       "\n",
       "   Customer Type_Loyal Customer  Type of Travel_Personal Travel  \\\n",
       "0                          True                            True   \n",
       "1                          True                            True   \n",
       "2                          True                            True   \n",
       "3                          True                            True   \n",
       "4                          True                            True   \n",
       "\n",
       "   Class_Business  Class_Eco  Class_Eco Plus  \n",
       "0           False       True           False  \n",
       "1            True      False           False  \n",
       "2           False       True           False  \n",
       "3           False       True           False  \n",
       "4           False       True           False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>Online support</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Customer Type_Loyal Customer</th>\n",
       "      <th>Type of Travel_Personal Travel</th>\n",
       "      <th>Class_Business</th>\n",
       "      <th>Class_Eco</th>\n",
       "      <th>Class_Eco Plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>2464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>305.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>2138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 레이블 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:24:48.765655Z",
     "start_time": "2024-08-22T07:24:48.754933Z"
    }
   },
   "source": [
    "# 라이브러리 불러오기\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "# train_test_split 수행하기\n",
    "x_train, x_test, y_train ,y_test = train_test_split( x_gd, y, stratify=y, test_size=0.2, random_state=2023)\n",
    "\n",
    "# 레이블 인코더 생성하기\n",
    "le = LabelEncoder() \n",
    "\n",
    "# fit을 통해 y_train의 값마다 0과 1을 부여하는 규칙 생성하기\n",
    "le.fit(y_train) \n",
    "\n",
    "#y_train을 레이블 인코딩하기\n",
    "le_y_train = le.transform(y_train) \n",
    "\n",
    "#y_test를 레이블 인코딩하기\n",
    "le_y_test = le.transform(y_test) \n",
    "\n",
    "# 인코딩이 수행된 데이터 확인하기\n",
    "print('레이블 인코딩 후 데이터 :',le_y_train) \n",
    "\n",
    "# 라벨 별로 어떤 값이 부여되어 있는지 규칙 확인하기\n",
    "print('레이블 인코딩 클래스 확인 :',le.classes_) \n",
    "\n",
    "# 레이블 인코딩된 데이터를 디코딩했을 때 데이터 확인하기\n",
    "print('레이블 인코딩을 디코딩 했을 때 :',le.inverse_transform(le_y_train))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 인코딩 후 데이터 : [1 1 1 ... 0 1 1]\n",
      "레이블 인코딩 클래스 확인 : ['dissatisfied' 'satisfied']\n",
      "레이블 인코딩을 디코딩 했을 때 : ['satisfied' 'satisfied' 'satisfied' ... 'dissatisfied' 'satisfied'\n",
      " 'satisfied']\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-08-22T07:25:09.228732Z",
     "start_time": "2024-08-22T07:25:08.119810Z"
    }
   },
   "source": [
    "%%time\n",
    "# 다양한 학습 모델 불러오기\n",
    "# scikit-learn 기반 모델 불러오기\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# scikit-learn 이외의 모델 불러오기\n",
    "from xgboost import XGBRFClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 모델 생성하기\n",
    "lr = LogisticRegression()\n",
    "dtc = DecisionTreeClassifier(random_state=1)\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "gbc = GradientBoostingClassifier(random_state=1)\n",
    "xgbc = XGBRFClassifier(random_state=1)\n",
    "etc = ExtraTreesClassifier(random_state=1)\n",
    "lgbmc = LGBMClassifier(random_state=1)\n",
    "\n",
    "# 모델 학습 수행하기\n",
    "lr.fit(x_train, le_y_train)\n",
    "dtc.fit(x_train, le_y_train)\n",
    "rfc.fit(x_train, le_y_train)\n",
    "gbc.fit(x_train, le_y_train)\n",
    "xgbc.fit(x_train, le_y_train)\n",
    "etc.fit(x_train, le_y_train)\n",
    "lgbmc.fit(x_train, le_y_train)\n",
    "\n",
    "# 순서대로 적용할 모델을 리스트에 저장하기\n",
    "models = [lr, dtc, rfc, gbc, xgbc, etc, lgbmc]\n",
    "\n",
    "# for문을 활용해 학습 모델 별 Score를 리스트에 저장하기\n",
    "acc_train_list = []\n",
    "acc_test_list = []\n",
    "for model in models:\n",
    "    acc_train_list.append(round(model.score(x_train, le_y_train),5))\n",
    "    acc_test_list.append(round(model.score(x_test, le_y_test),5))\n",
    "\n",
    "# 모델 별 정확도를 출력하기\n",
    "for i in range(len(models)):\n",
    "    print('학습모델 : ',models[i])\n",
    "    print('train 정확도: ',acc_train_list[i])\n",
    "    print('test 정확도: ',acc_test_list[i])\n",
    "    print('----------------------------------')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 2284, number of negative: 1694\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 674\n",
      "[LightGBM] [Info] Number of data points in the train set: 3978, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.574158 -> initscore=0.298836\n",
      "[LightGBM] [Info] Start training from score 0.298836\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "학습모델 :  LogisticRegression()\n",
      "train 정확도:  0.88009\n",
      "test 정확도:  0.86131\n",
      "----------------------------------\n",
      "학습모델 :  DecisionTreeClassifier(random_state=1)\n",
      "train 정확도:  1.0\n",
      "test 정확도:  1.0\n",
      "----------------------------------\n",
      "학습모델 :  RandomForestClassifier(random_state=1)\n",
      "train 정확도:  1.0\n",
      "test 정확도:  1.0\n",
      "----------------------------------\n",
      "학습모델 :  GradientBoostingClassifier(random_state=1)\n",
      "train 정확도:  1.0\n",
      "test 정확도:  1.0\n",
      "----------------------------------\n",
      "학습모델 :  XGBRFClassifier(base_score=None, booster=None, callbacks=None,\n",
      "                colsample_bylevel=None, colsample_bytree=None, device=None,\n",
      "                early_stopping_rounds=None, enable_categorical=False,\n",
      "                eval_metric=None, feature_types=None, gamma=None,\n",
      "                grow_policy=None, importance_type=None,\n",
      "                interaction_constraints=None, max_bin=None,\n",
      "                max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "                max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "                multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "                num_parallel_tree=None, objective='binary:logistic',\n",
      "                random_state=1, reg_alpha=None, ...)\n",
      "train 정확도:  0.9995\n",
      "test 정확도:  1.0\n",
      "----------------------------------\n",
      "학습모델 :  ExtraTreesClassifier(random_state=1)\n",
      "train 정확도:  1.0\n",
      "test 정확도:  1.0\n",
      "----------------------------------\n",
      "학습모델 :  LGBMClassifier(random_state=1)\n",
      "train 정확도:  1.0\n",
      "test 정확도:  1.0\n",
      "----------------------------------\n",
      "CPU times: user 3.03 s, sys: 4.15 s, total: 7.18 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 최적의 하이퍼 파라미터 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 그리드 서치하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:26:06.936453Z",
     "start_time": "2024-08-22T07:25:48.948035Z"
    }
   },
   "source": [
    "%%time\n",
    "#GridSearchCV를 불러오기\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# param_grid를 정의하여 각 파라미터 별로 교차해서 모든 학습을 수행하기\n",
    "param_grid = { \n",
    "    'n_estimators': [50 ,100, 200, 500],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth' : [10,20,30,40,50,None],\n",
    "}\n",
    "\n",
    "# estimator=rfc :가장 우수한 모델이었던 rfc 활용하기\n",
    "# param_grid=param_grid : 미리 정의한 파라미터들을 교차 적용하기\n",
    "# n_jobs=-1 : -1로 지정하면 모든 CPU 활용하기\n",
    "cv_rfc = GridSearchCV(\n",
    "    estimator=rfc, \n",
    "    param_grid=param_grid, \n",
    "    n_jobs=-1,\n",
    "    cv=5)\n",
    "\n",
    "# 학습 수행하기\n",
    "cv_rfc.fit(x_train, le_y_train) \n",
    "\n",
    "# best_score를 출력하기\n",
    "print('최적의 파라미터 학습시 Score :',round(cv_rfc.best_score_ , 5)) \n",
    "\n",
    "# best params을 출력하기\n",
    "print('최적의 파라미터 :',cv_rfc.best_params_) "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 파라미터 학습시 Score : 0.9995\n",
      "최적의 파라미터 : {'max_depth': 10, 'max_features': None, 'n_estimators': 50}\n",
      "CPU times: user 3.43 s, sys: 436 ms, total: 3.86 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:27:13.937310Z",
     "start_time": "2024-08-22T07:27:13.873306Z"
    }
   },
   "source": [
    "# 최적의 하이퍼파라미터로 도출된 값을 모델에 입력하기\n",
    "rfc = RandomForestClassifier(\n",
    "    n_estimators = 50,\n",
    "    max_features = None,\n",
    "    n_jobs=-1,\n",
    "    max_depth = 10)\n",
    "\n",
    "# rfc 학습 수행하기\n",
    "rfc.fit(x_train, le_y_train) \n",
    "\n",
    "# 이전에 하이퍼파라미터 설정 없이 수행했을 때의 정확도 확인하기\n",
    "print('기존 모델의 Test 정확도: 1.0') \n",
    "\n",
    "# 최적의 하이퍼파라미터 입력 후 학습시킨 모델의 정확도 확인하기\n",
    "print('최적의 하이퍼 파라미터 반영한 모델의 Test 정확도: ',round(rfc.score(x_test, le_y_test),5)) \n",
    "\n",
    "# 향상된 정확도 gap 계산하기\n",
    "print('정확도 향상: ',round(rfc.score(x_test, le_y_test)-1.0 , 5))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 모델의 Test 정확도: 1.0\n",
      "최적의 하이퍼 파라미터 반영한 모델의 Test 정확도:  1.0\n",
      "정확도 향상:  0.0\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 오차행렬으로 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T07:27:36.040733Z",
     "start_time": "2024-08-22T07:27:35.943532Z"
    }
   },
   "source": [
    "# 라이브러리 불러오기\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# rfc 모델로 x_test를 예측한 값을 y_pred로 저장하기\n",
    "y_pred = rfc.predict(x_test) \n",
    "\n",
    "# 실제값 le_y_test(레이블 인코딩을 해야 0,1로 표현됨)와 예측값 y_pred 비교하기\n",
    "cm = confusion_matrix(le_y_test, y_pred, labels=[0,1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])\n",
    "disp.plot()\n",
    "\n",
    "# 오차행렬(Confusion Matrix) 출력하기\n",
    "plt.show() \n",
    "\n",
    "# 오차행렬(Confusion Matrix)를 통한 각종 지표들을 리포트로 출력하기\n",
    "print(classification_report(le_y_test, y_pred)) "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       424\n",
      "           1       1.00      1.00      1.00       571\n",
      "\n",
      "    accuracy                           1.00       995\n",
      "   macro avg       1.00      1.00      1.00       995\n",
      "weighted avg       1.00      1.00      1.00       995\n",
      "\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
