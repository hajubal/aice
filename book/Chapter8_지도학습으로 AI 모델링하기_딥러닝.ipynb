{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SECTION 02. 딥러닝으로 AI모델링하기"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 텐서플로 설치 및 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# tensorflow 라이브러리 설치하기\n",
    "!pip install tensorflow"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:38:44.971828Z",
     "start_time": "2024-09-02T06:38:44.968326Z"
    }
   },
   "source": [
    "# 설치된 텐서플로 버전 확인하기\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# 경고 무시하도록 설정\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:38:46.751335Z",
     "start_time": "2024-09-02T06:38:46.746369Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 모델 학습 데이터 생성하기\n",
    "x = [1, 2, 3, 4,  5, 6,  7,  8,  9, 10]\n",
    "y = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "x_train = np.array(x)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "y_train = np.array(y)\n",
    "\n",
    "print(f'입력 데이터 : {x_train}')\n",
    "print(f'입력 데이터 형태: {x_train.shape}')\n",
    "print(f'출력 데이터: {y_train}')\n",
    "print(f'출력 데이터 형태 : {y_train.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 : [[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]]\n",
      "입력 데이터 형태: (10, 1)\n",
      "출력 데이터: [ 3  5  7  9 11 13 15 17 19 21]\n",
      "출력 데이터 형태 : (10,)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:39:57.440181Z",
     "start_time": "2024-09-02T06:39:57.398853Z"
    }
   },
   "source": [
    "# Keras의 Sequential 모델 구성하기\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42) #모델 시드 고정하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_shape=(1,), kernel_initializer=initializer))\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m2\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2\u001B[0m (8.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m2\u001B[0m (8.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:40:05.567429Z",
     "start_time": "2024-09-02T06:40:05.557118Z"
    }
   },
   "source": [
    "# 모델을 학습시킬 최적화 방법, loss 계산 방법, 평가 방법 설정하기\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mae'])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:40:18.393142Z",
     "start_time": "2024-09-02T06:40:07.501411Z"
    }
   },
   "source": [
    "# 모델 학습하기\n",
    "model.fit(x_train, y_train, epochs=1000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 128ms/step - loss: 323.2250 - mae: 16.1452\n",
      "Epoch 2/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 14.9011 - mae: 3.5555\n",
      "Epoch 3/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.7542 - mae: 0.8584\n",
      "Epoch 4/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.1045 - mae: 0.2802\n",
      "Epoch 5/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0741 - mae: 0.2255\n",
      "Epoch 6/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0721 - mae: 0.2238\n",
      "Epoch 7/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0715 - mae: 0.2230\n",
      "Epoch 8/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0709 - mae: 0.2223\n",
      "Epoch 9/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0703 - mae: 0.2214\n",
      "Epoch 10/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0697 - mae: 0.2205\n",
      "Epoch 11/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0691 - mae: 0.2196\n",
      "Epoch 12/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0685 - mae: 0.2187\n",
      "Epoch 13/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0679 - mae: 0.2178\n",
      "Epoch 14/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0674 - mae: 0.2168\n",
      "Epoch 15/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0668 - mae: 0.2159\n",
      "Epoch 16/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0663 - mae: 0.2150\n",
      "Epoch 17/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0657 - mae: 0.2141\n",
      "Epoch 18/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0651 - mae: 0.2132\n",
      "Epoch 19/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0646 - mae: 0.2123\n",
      "Epoch 20/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0641 - mae: 0.2114\n",
      "Epoch 21/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0635 - mae: 0.2106\n",
      "Epoch 22/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0630 - mae: 0.2097\n",
      "Epoch 23/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0625 - mae: 0.2088\n",
      "Epoch 24/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0619 - mae: 0.2079\n",
      "Epoch 25/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0614 - mae: 0.2070\n",
      "Epoch 26/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0609 - mae: 0.2062\n",
      "Epoch 27/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0604 - mae: 0.2053\n",
      "Epoch 28/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0599 - mae: 0.2044\n",
      "Epoch 29/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0594 - mae: 0.2036\n",
      "Epoch 30/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0589 - mae: 0.2027\n",
      "Epoch 31/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0584 - mae: 0.2019\n",
      "Epoch 32/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0579 - mae: 0.2010\n",
      "Epoch 33/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0574 - mae: 0.2002\n",
      "Epoch 34/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0569 - mae: 0.1993\n",
      "Epoch 35/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0565 - mae: 0.1985\n",
      "Epoch 36/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0560 - mae: 0.1977\n",
      "Epoch 37/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0555 - mae: 0.1968\n",
      "Epoch 38/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0551 - mae: 0.1960\n",
      "Epoch 39/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0546 - mae: 0.1952\n",
      "Epoch 40/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0541 - mae: 0.1944\n",
      "Epoch 41/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0537 - mae: 0.1936\n",
      "Epoch 42/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0532 - mae: 0.1927\n",
      "Epoch 43/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0528 - mae: 0.1919\n",
      "Epoch 44/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0523 - mae: 0.1911\n",
      "Epoch 45/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0519 - mae: 0.1903\n",
      "Epoch 46/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0515 - mae: 0.1895\n",
      "Epoch 47/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0510 - mae: 0.1887\n",
      "Epoch 48/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0506 - mae: 0.1879\n",
      "Epoch 49/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0502 - mae: 0.1871\n",
      "Epoch 50/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0498 - mae: 0.1864\n",
      "Epoch 51/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0493 - mae: 0.1856\n",
      "Epoch 52/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0489 - mae: 0.1848\n",
      "Epoch 53/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0485 - mae: 0.1840\n",
      "Epoch 54/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0481 - mae: 0.1832\n",
      "Epoch 55/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0477 - mae: 0.1825\n",
      "Epoch 56/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0473 - mae: 0.1817\n",
      "Epoch 57/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0469 - mae: 0.1810\n",
      "Epoch 58/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0465 - mae: 0.1802\n",
      "Epoch 59/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0461 - mae: 0.1794\n",
      "Epoch 60/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0457 - mae: 0.1787\n",
      "Epoch 61/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0454 - mae: 0.1779\n",
      "Epoch 62/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0450 - mae: 0.1772\n",
      "Epoch 63/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0446 - mae: 0.1764\n",
      "Epoch 64/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0442 - mae: 0.1757\n",
      "Epoch 65/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0439 - mae: 0.1750\n",
      "Epoch 66/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0435 - mae: 0.1742\n",
      "Epoch 67/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0431 - mae: 0.1735\n",
      "Epoch 68/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0428 - mae: 0.1728\n",
      "Epoch 69/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0424 - mae: 0.1720\n",
      "Epoch 70/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0421 - mae: 0.1713\n",
      "Epoch 71/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0417 - mae: 0.1706\n",
      "Epoch 72/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0414 - mae: 0.1699\n",
      "Epoch 73/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0410 - mae: 0.1692\n",
      "Epoch 74/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0407 - mae: 0.1685\n",
      "Epoch 75/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0403 - mae: 0.1677\n",
      "Epoch 76/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0400 - mae: 0.1670\n",
      "Epoch 77/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0396 - mae: 0.1663\n",
      "Epoch 78/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0393 - mae: 0.1656\n",
      "Epoch 79/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0390 - mae: 0.1649\n",
      "Epoch 80/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0387 - mae: 0.1643\n",
      "Epoch 81/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0383 - mae: 0.1636\n",
      "Epoch 82/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0380 - mae: 0.1629\n",
      "Epoch 83/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0377 - mae: 0.1622\n",
      "Epoch 84/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0374 - mae: 0.1615\n",
      "Epoch 85/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0371 - mae: 0.1608\n",
      "Epoch 86/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0368 - mae: 0.1602\n",
      "Epoch 87/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0364 - mae: 0.1595\n",
      "Epoch 88/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0361 - mae: 0.1588\n",
      "Epoch 89/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0358 - mae: 0.1582\n",
      "Epoch 90/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0355 - mae: 0.1575\n",
      "Epoch 91/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0352 - mae: 0.1568\n",
      "Epoch 92/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0349 - mae: 0.1562\n",
      "Epoch 93/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0347 - mae: 0.1555\n",
      "Epoch 94/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0344 - mae: 0.1549\n",
      "Epoch 95/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0341 - mae: 0.1542\n",
      "Epoch 96/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0338 - mae: 0.1536\n",
      "Epoch 97/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0335 - mae: 0.1529\n",
      "Epoch 98/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0332 - mae: 0.1523\n",
      "Epoch 99/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0329 - mae: 0.1516\n",
      "Epoch 100/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0327 - mae: 0.1510\n",
      "Epoch 101/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0324 - mae: 0.1504\n",
      "Epoch 102/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0321 - mae: 0.1497\n",
      "Epoch 103/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0319 - mae: 0.1491\n",
      "Epoch 104/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0316 - mae: 0.1485\n",
      "Epoch 105/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0313 - mae: 0.1479\n",
      "Epoch 106/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0311 - mae: 0.1472\n",
      "Epoch 107/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0308 - mae: 0.1466\n",
      "Epoch 108/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0305 - mae: 0.1460\n",
      "Epoch 109/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0303 - mae: 0.1454\n",
      "Epoch 110/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0300 - mae: 0.1448\n",
      "Epoch 111/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0298 - mae: 0.1442\n",
      "Epoch 112/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0295 - mae: 0.1436\n",
      "Epoch 113/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0293 - mae: 0.1430\n",
      "Epoch 114/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0290 - mae: 0.1424\n",
      "Epoch 115/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0288 - mae: 0.1418\n",
      "Epoch 116/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0286 - mae: 0.1412\n",
      "Epoch 117/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0283 - mae: 0.1406\n",
      "Epoch 118/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0281 - mae: 0.1400\n",
      "Epoch 119/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0278 - mae: 0.1394\n",
      "Epoch 120/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0276 - mae: 0.1388\n",
      "Epoch 121/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0274 - mae: 0.1382\n",
      "Epoch 122/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0271 - mae: 0.1376\n",
      "Epoch 123/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0269 - mae: 0.1371\n",
      "Epoch 124/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0267 - mae: 0.1365\n",
      "Epoch 125/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0265 - mae: 0.1359\n",
      "Epoch 126/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0262 - mae: 0.1353\n",
      "Epoch 127/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0260 - mae: 0.1348\n",
      "Epoch 128/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0258 - mae: 0.1342\n",
      "Epoch 129/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0256 - mae: 0.1336\n",
      "Epoch 130/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0254 - mae: 0.1331\n",
      "Epoch 131/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0252 - mae: 0.1325\n",
      "Epoch 132/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0250 - mae: 0.1320\n",
      "Epoch 133/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0247 - mae: 0.1314\n",
      "Epoch 134/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0245 - mae: 0.1309\n",
      "Epoch 135/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0243 - mae: 0.1303\n",
      "Epoch 136/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0241 - mae: 0.1298\n",
      "Epoch 137/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0239 - mae: 0.1292\n",
      "Epoch 138/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0237 - mae: 0.1287\n",
      "Epoch 139/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0235 - mae: 0.1281\n",
      "Epoch 140/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0233 - mae: 0.1276\n",
      "Epoch 141/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0231 - mae: 0.1271\n",
      "Epoch 142/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0229 - mae: 0.1265\n",
      "Epoch 143/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0227 - mae: 0.1260\n",
      "Epoch 144/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0226 - mae: 0.1255\n",
      "Epoch 145/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0224 - mae: 0.1249\n",
      "Epoch 146/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0222 - mae: 0.1244\n",
      "Epoch 147/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0220 - mae: 0.1239\n",
      "Epoch 148/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0218 - mae: 0.1234\n",
      "Epoch 149/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0216 - mae: 0.1229\n",
      "Epoch 150/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0214 - mae: 0.1223\n",
      "Epoch 151/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 0.0213 - mae: 0.1218\n",
      "Epoch 152/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 0.0211 - mae: 0.1213\n",
      "Epoch 153/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0209 - mae: 0.1208\n",
      "Epoch 154/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0207 - mae: 0.1203\n",
      "Epoch 155/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0206 - mae: 0.1198\n",
      "Epoch 156/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0204 - mae: 0.1193\n",
      "Epoch 157/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0202 - mae: 0.1188\n",
      "Epoch 158/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0201 - mae: 0.1183\n",
      "Epoch 159/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0199 - mae: 0.1178\n",
      "Epoch 160/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0197 - mae: 0.1173\n",
      "Epoch 161/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0196 - mae: 0.1168\n",
      "Epoch 162/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0194 - mae: 0.1163\n",
      "Epoch 163/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0192 - mae: 0.1158\n",
      "Epoch 164/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0191 - mae: 0.1153\n",
      "Epoch 165/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0189 - mae: 0.1149\n",
      "Epoch 166/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0187 - mae: 0.1144\n",
      "Epoch 167/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0186 - mae: 0.1139\n",
      "Epoch 168/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0184 - mae: 0.1134\n",
      "Epoch 169/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0183 - mae: 0.1129\n",
      "Epoch 170/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0181 - mae: 0.1125\n",
      "Epoch 171/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0180 - mae: 0.1120\n",
      "Epoch 172/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0178 - mae: 0.1115\n",
      "Epoch 173/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0177 - mae: 0.1111\n",
      "Epoch 174/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0175 - mae: 0.1106\n",
      "Epoch 175/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0174 - mae: 0.1101\n",
      "Epoch 176/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0172 - mae: 0.1097\n",
      "Epoch 177/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0171 - mae: 0.1092\n",
      "Epoch 178/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0169 - mae: 0.1087\n",
      "Epoch 179/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0168 - mae: 0.1083\n",
      "Epoch 180/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0167 - mae: 0.1078\n",
      "Epoch 181/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0165 - mae: 0.1074\n",
      "Epoch 182/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0164 - mae: 0.1069\n",
      "Epoch 183/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0162 - mae: 0.1065\n",
      "Epoch 184/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0161 - mae: 0.1060\n",
      "Epoch 185/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0160 - mae: 0.1056\n",
      "Epoch 186/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0158 - mae: 0.1051\n",
      "Epoch 187/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0157 - mae: 0.1047\n",
      "Epoch 188/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0156 - mae: 0.1043\n",
      "Epoch 189/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0154 - mae: 0.1038\n",
      "Epoch 190/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0153 - mae: 0.1034\n",
      "Epoch 191/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0152 - mae: 0.1030\n",
      "Epoch 192/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0151 - mae: 0.1025\n",
      "Epoch 193/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0149 - mae: 0.1021\n",
      "Epoch 194/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0148 - mae: 0.1017\n",
      "Epoch 195/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0147 - mae: 0.1012\n",
      "Epoch 196/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0146 - mae: 0.1008\n",
      "Epoch 197/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0144 - mae: 0.1004\n",
      "Epoch 198/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0143 - mae: 0.1000\n",
      "Epoch 199/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0142 - mae: 0.0995\n",
      "Epoch 200/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0141 - mae: 0.0991\n",
      "Epoch 201/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0140 - mae: 0.0987\n",
      "Epoch 202/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0138 - mae: 0.0983\n",
      "Epoch 203/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0137 - mae: 0.0979\n",
      "Epoch 204/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0136 - mae: 0.0975\n",
      "Epoch 205/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0135 - mae: 0.0971\n",
      "Epoch 206/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0134 - mae: 0.0967\n",
      "Epoch 207/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0133 - mae: 0.0963\n",
      "Epoch 208/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0132 - mae: 0.0958\n",
      "Epoch 209/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0131 - mae: 0.0954\n",
      "Epoch 210/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0129 - mae: 0.0950\n",
      "Epoch 211/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0128 - mae: 0.0946\n",
      "Epoch 212/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0127 - mae: 0.0942\n",
      "Epoch 213/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0126 - mae: 0.0939\n",
      "Epoch 214/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0125 - mae: 0.0935\n",
      "Epoch 215/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0124 - mae: 0.0931\n",
      "Epoch 216/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0123 - mae: 0.0927\n",
      "Epoch 217/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0122 - mae: 0.0923\n",
      "Epoch 218/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0121 - mae: 0.0919\n",
      "Epoch 219/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0120 - mae: 0.0915\n",
      "Epoch 220/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0119 - mae: 0.0911\n",
      "Epoch 221/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0118 - mae: 0.0907\n",
      "Epoch 222/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0117 - mae: 0.0904\n",
      "Epoch 223/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0116 - mae: 0.0900\n",
      "Epoch 224/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0115 - mae: 0.0896\n",
      "Epoch 225/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0114 - mae: 0.0892\n",
      "Epoch 226/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0113 - mae: 0.0889\n",
      "Epoch 227/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0112 - mae: 0.0885\n",
      "Epoch 228/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0111 - mae: 0.0881\n",
      "Epoch 229/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0110 - mae: 0.0877\n",
      "Epoch 230/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0109 - mae: 0.0874\n",
      "Epoch 231/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0108 - mae: 0.0870\n",
      "Epoch 232/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0108 - mae: 0.0866\n",
      "Epoch 233/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0107 - mae: 0.0863\n",
      "Epoch 234/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0106 - mae: 0.0859\n",
      "Epoch 235/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0105 - mae: 0.0856\n",
      "Epoch 236/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0104 - mae: 0.0852\n",
      "Epoch 237/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0103 - mae: 0.0848\n",
      "Epoch 238/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0102 - mae: 0.0845\n",
      "Epoch 239/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0101 - mae: 0.0841\n",
      "Epoch 240/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0101 - mae: 0.0838\n",
      "Epoch 241/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0100 - mae: 0.0834\n",
      "Epoch 242/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0099 - mae: 0.0831\n",
      "Epoch 243/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 0.0098 - mae: 0.0827\n",
      "Epoch 244/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0097 - mae: 0.0824\n",
      "Epoch 245/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0096 - mae: 0.0820\n",
      "Epoch 246/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0096 - mae: 0.0817\n",
      "Epoch 247/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0095 - mae: 0.0813\n",
      "Epoch 248/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0094 - mae: 0.0810\n",
      "Epoch 249/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0093 - mae: 0.0807\n",
      "Epoch 250/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0092 - mae: 0.0803\n",
      "Epoch 251/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0092 - mae: 0.0800\n",
      "Epoch 252/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0091 - mae: 0.0796\n",
      "Epoch 253/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0090 - mae: 0.0793\n",
      "Epoch 254/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0089 - mae: 0.0790\n",
      "Epoch 255/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0089 - mae: 0.0786\n",
      "Epoch 256/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0088 - mae: 0.0783\n",
      "Epoch 257/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0087 - mae: 0.0780\n",
      "Epoch 258/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0086 - mae: 0.0777\n",
      "Epoch 259/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0086 - mae: 0.0773\n",
      "Epoch 260/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0085 - mae: 0.0770\n",
      "Epoch 261/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0084 - mae: 0.0767\n",
      "Epoch 262/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0084 - mae: 0.0764\n",
      "Epoch 263/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0083 - mae: 0.0760\n",
      "Epoch 264/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0082 - mae: 0.0757\n",
      "Epoch 265/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0081 - mae: 0.0754\n",
      "Epoch 266/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0081 - mae: 0.0751\n",
      "Epoch 267/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0080 - mae: 0.0748\n",
      "Epoch 268/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0079 - mae: 0.0745\n",
      "Epoch 269/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0079 - mae: 0.0741\n",
      "Epoch 270/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0078 - mae: 0.0738\n",
      "Epoch 271/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0077 - mae: 0.0735\n",
      "Epoch 272/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0077 - mae: 0.0732\n",
      "Epoch 273/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0076 - mae: 0.0729\n",
      "Epoch 274/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0076 - mae: 0.0726\n",
      "Epoch 275/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0075 - mae: 0.0723\n",
      "Epoch 276/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0074 - mae: 0.0720\n",
      "Epoch 277/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0074 - mae: 0.0717\n",
      "Epoch 278/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0073 - mae: 0.0714\n",
      "Epoch 279/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0072 - mae: 0.0711\n",
      "Epoch 280/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0072 - mae: 0.0708\n",
      "Epoch 281/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0071 - mae: 0.0705\n",
      "Epoch 282/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0071 - mae: 0.0702\n",
      "Epoch 283/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0070 - mae: 0.0699\n",
      "Epoch 284/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0069 - mae: 0.0696\n",
      "Epoch 285/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0069 - mae: 0.0693\n",
      "Epoch 286/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0068 - mae: 0.0690\n",
      "Epoch 287/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0068 - mae: 0.0687\n",
      "Epoch 288/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0067 - mae: 0.0684\n",
      "Epoch 289/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0067 - mae: 0.0682\n",
      "Epoch 290/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0066 - mae: 0.0679\n",
      "Epoch 291/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0065 - mae: 0.0676\n",
      "Epoch 292/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0065 - mae: 0.0673\n",
      "Epoch 293/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0064 - mae: 0.0670\n",
      "Epoch 294/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0064 - mae: 0.0667\n",
      "Epoch 295/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0063 - mae: 0.0665\n",
      "Epoch 296/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0063 - mae: 0.0662\n",
      "Epoch 297/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0062 - mae: 0.0659\n",
      "Epoch 298/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0062 - mae: 0.0656\n",
      "Epoch 299/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0061 - mae: 0.0654\n",
      "Epoch 300/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0061 - mae: 0.0651\n",
      "Epoch 301/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0060 - mae: 0.0648\n",
      "Epoch 302/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0060 - mae: 0.0645\n",
      "Epoch 303/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0059 - mae: 0.0643\n",
      "Epoch 304/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0059 - mae: 0.0640\n",
      "Epoch 305/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0058 - mae: 0.0637\n",
      "Epoch 306/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0058 - mae: 0.0635\n",
      "Epoch 307/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0057 - mae: 0.0632\n",
      "Epoch 308/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0057 - mae: 0.0629\n",
      "Epoch 309/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0056 - mae: 0.0627\n",
      "Epoch 310/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0056 - mae: 0.0624\n",
      "Epoch 311/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0055 - mae: 0.0621\n",
      "Epoch 312/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0055 - mae: 0.0619\n",
      "Epoch 313/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0054 - mae: 0.0616\n",
      "Epoch 314/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0054 - mae: 0.0614\n",
      "Epoch 315/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0053 - mae: 0.0611\n",
      "Epoch 316/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0053 - mae: 0.0608\n",
      "Epoch 317/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0053 - mae: 0.0606\n",
      "Epoch 318/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0052 - mae: 0.0603\n",
      "Epoch 319/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0052 - mae: 0.0601\n",
      "Epoch 320/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0051 - mae: 0.0598\n",
      "Epoch 321/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0051 - mae: 0.0596\n",
      "Epoch 322/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0050 - mae: 0.0593\n",
      "Epoch 323/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0050 - mae: 0.0591\n",
      "Epoch 324/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0050 - mae: 0.0588\n",
      "Epoch 325/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0049 - mae: 0.0586\n",
      "Epoch 326/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0049 - mae: 0.0583\n",
      "Epoch 327/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0048 - mae: 0.0581\n",
      "Epoch 328/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0048 - mae: 0.0578\n",
      "Epoch 329/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0048 - mae: 0.0576\n",
      "Epoch 330/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0047 - mae: 0.0574\n",
      "Epoch 331/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0047 - mae: 0.0571\n",
      "Epoch 332/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0046 - mae: 0.0569\n",
      "Epoch 333/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0046 - mae: 0.0566\n",
      "Epoch 334/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0046 - mae: 0.0564\n",
      "Epoch 335/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0045 - mae: 0.0562\n",
      "Epoch 336/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0045 - mae: 0.0559\n",
      "Epoch 337/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0044 - mae: 0.0557\n",
      "Epoch 338/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0044 - mae: 0.0555\n",
      "Epoch 339/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0044 - mae: 0.0552\n",
      "Epoch 340/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0043 - mae: 0.0550\n",
      "Epoch 341/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0043 - mae: 0.0548\n",
      "Epoch 342/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0043 - mae: 0.0545\n",
      "Epoch 343/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0042 - mae: 0.0543\n",
      "Epoch 344/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0042 - mae: 0.0541\n",
      "Epoch 345/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0042 - mae: 0.0539\n",
      "Epoch 346/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0041 - mae: 0.0536\n",
      "Epoch 347/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0041 - mae: 0.0534\n",
      "Epoch 348/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0041 - mae: 0.0532\n",
      "Epoch 349/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0040 - mae: 0.0530\n",
      "Epoch 350/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0040 - mae: 0.0527\n",
      "Epoch 351/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0040 - mae: 0.0525\n",
      "Epoch 352/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0039 - mae: 0.0523\n",
      "Epoch 353/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0039 - mae: 0.0521\n",
      "Epoch 354/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0039 - mae: 0.0518\n",
      "Epoch 355/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0038 - mae: 0.0516\n",
      "Epoch 356/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0038 - mae: 0.0514\n",
      "Epoch 357/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0038 - mae: 0.0512\n",
      "Epoch 358/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0037 - mae: 0.0510\n",
      "Epoch 359/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0037 - mae: 0.0508\n",
      "Epoch 360/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0037 - mae: 0.0506\n",
      "Epoch 361/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0036 - mae: 0.0503\n",
      "Epoch 362/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0036 - mae: 0.0501\n",
      "Epoch 363/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0036 - mae: 0.0499\n",
      "Epoch 364/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0035 - mae: 0.0497\n",
      "Epoch 365/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0035 - mae: 0.0495\n",
      "Epoch 366/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0035 - mae: 0.0493\n",
      "Epoch 367/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0035 - mae: 0.0491\n",
      "Epoch 368/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0034 - mae: 0.0489\n",
      "Epoch 369/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0034 - mae: 0.0487\n",
      "Epoch 370/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0034 - mae: 0.0485\n",
      "Epoch 371/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0033 - mae: 0.0483\n",
      "Epoch 372/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0033 - mae: 0.0481\n",
      "Epoch 373/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0033 - mae: 0.0479\n",
      "Epoch 374/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0033 - mae: 0.0477\n",
      "Epoch 375/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0032 - mae: 0.0475\n",
      "Epoch 376/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0032 - mae: 0.0473\n",
      "Epoch 377/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0032 - mae: 0.0471\n",
      "Epoch 378/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0031 - mae: 0.0469\n",
      "Epoch 379/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0031 - mae: 0.0467\n",
      "Epoch 380/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0031 - mae: 0.0465\n",
      "Epoch 381/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0031 - mae: 0.0463\n",
      "Epoch 382/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0030 - mae: 0.0461\n",
      "Epoch 383/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0030 - mae: 0.0459\n",
      "Epoch 384/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0030 - mae: 0.0457\n",
      "Epoch 385/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0030 - mae: 0.0455\n",
      "Epoch 386/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0029 - mae: 0.0453\n",
      "Epoch 387/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0029 - mae: 0.0451\n",
      "Epoch 388/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0029 - mae: 0.0449\n",
      "Epoch 389/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0029 - mae: 0.0447\n",
      "Epoch 390/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0028 - mae: 0.0446\n",
      "Epoch 391/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0028 - mae: 0.0444\n",
      "Epoch 392/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0028 - mae: 0.0442\n",
      "Epoch 393/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0028 - mae: 0.0440\n",
      "Epoch 394/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0028 - mae: 0.0438\n",
      "Epoch 395/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0027 - mae: 0.0436\n",
      "Epoch 396/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0027 - mae: 0.0434\n",
      "Epoch 397/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0027 - mae: 0.0433\n",
      "Epoch 398/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0027 - mae: 0.0431\n",
      "Epoch 399/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0026 - mae: 0.0429\n",
      "Epoch 400/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0026 - mae: 0.0427\n",
      "Epoch 401/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0026 - mae: 0.0425\n",
      "Epoch 402/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0026 - mae: 0.0424\n",
      "Epoch 403/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0026 - mae: 0.0422\n",
      "Epoch 404/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0025 - mae: 0.0420\n",
      "Epoch 405/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0025 - mae: 0.0418\n",
      "Epoch 406/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0025 - mae: 0.0417\n",
      "Epoch 407/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0025 - mae: 0.0415\n",
      "Epoch 408/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0024 - mae: 0.0413\n",
      "Epoch 409/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0024 - mae: 0.0411\n",
      "Epoch 410/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0024 - mae: 0.0410\n",
      "Epoch 411/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0024 - mae: 0.0408\n",
      "Epoch 412/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0024 - mae: 0.0406\n",
      "Epoch 413/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0023 - mae: 0.0404\n",
      "Epoch 414/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0023 - mae: 0.0403\n",
      "Epoch 415/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0023 - mae: 0.0401\n",
      "Epoch 416/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0023 - mae: 0.0399\n",
      "Epoch 417/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0023 - mae: 0.0398\n",
      "Epoch 418/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0022 - mae: 0.0396\n",
      "Epoch 419/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0022 - mae: 0.0394\n",
      "Epoch 420/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0022 - mae: 0.0393\n",
      "Epoch 421/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0022 - mae: 0.0391\n",
      "Epoch 422/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0022 - mae: 0.0389\n",
      "Epoch 423/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0022 - mae: 0.0388\n",
      "Epoch 424/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0021 - mae: 0.0386\n",
      "Epoch 425/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0021 - mae: 0.0385\n",
      "Epoch 426/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0021 - mae: 0.0383\n",
      "Epoch 427/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0021 - mae: 0.0381\n",
      "Epoch 428/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0021 - mae: 0.0380\n",
      "Epoch 429/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0020 - mae: 0.0378\n",
      "Epoch 430/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0020 - mae: 0.0377\n",
      "Epoch 431/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0020 - mae: 0.0375\n",
      "Epoch 432/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0020 - mae: 0.0373\n",
      "Epoch 433/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0020 - mae: 0.0372\n",
      "Epoch 434/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0020 - mae: 0.0370\n",
      "Epoch 435/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0019 - mae: 0.0369\n",
      "Epoch 436/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0019 - mae: 0.0367\n",
      "Epoch 437/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0019 - mae: 0.0366\n",
      "Epoch 438/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0019 - mae: 0.0364\n",
      "Epoch 439/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0019 - mae: 0.0363\n",
      "Epoch 440/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0019 - mae: 0.0361\n",
      "Epoch 441/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0019 - mae: 0.0360\n",
      "Epoch 442/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0018 - mae: 0.0358\n",
      "Epoch 443/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0018 - mae: 0.0357\n",
      "Epoch 444/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0018 - mae: 0.0355\n",
      "Epoch 445/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0018 - mae: 0.0354\n",
      "Epoch 446/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0018 - mae: 0.0352\n",
      "Epoch 447/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0018 - mae: 0.0351\n",
      "Epoch 448/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0017 - mae: 0.0349\n",
      "Epoch 449/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0017 - mae: 0.0348\n",
      "Epoch 450/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0017 - mae: 0.0346\n",
      "Epoch 451/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0017 - mae: 0.0345\n",
      "Epoch 452/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0017 - mae: 0.0343\n",
      "Epoch 453/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0017 - mae: 0.0342\n",
      "Epoch 454/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0017 - mae: 0.0340\n",
      "Epoch 455/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0016 - mae: 0.0339\n",
      "Epoch 456/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0016 - mae: 0.0338\n",
      "Epoch 457/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0016 - mae: 0.0336\n",
      "Epoch 458/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0016 - mae: 0.0335\n",
      "Epoch 459/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0016 - mae: 0.0333\n",
      "Epoch 460/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0016 - mae: 0.0332\n",
      "Epoch 461/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0016 - mae: 0.0331\n",
      "Epoch 462/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0016 - mae: 0.0329\n",
      "Epoch 463/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0328\n",
      "Epoch 464/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0015 - mae: 0.0326\n",
      "Epoch 465/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0015 - mae: 0.0325\n",
      "Epoch 466/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0324\n",
      "Epoch 467/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0015 - mae: 0.0322\n",
      "Epoch 468/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0321\n",
      "Epoch 469/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0015 - mae: 0.0320\n",
      "Epoch 470/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0318\n",
      "Epoch 471/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0317\n",
      "Epoch 472/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0316\n",
      "Epoch 473/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0014 - mae: 0.0314\n",
      "Epoch 474/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0014 - mae: 0.0313\n",
      "Epoch 475/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0312\n",
      "Epoch 476/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0310\n",
      "Epoch 477/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0014 - mae: 0.0309\n",
      "Epoch 478/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0308\n",
      "Epoch 479/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0013 - mae: 0.0306\n",
      "Epoch 480/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0305\n",
      "Epoch 481/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0304\n",
      "Epoch 482/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0303\n",
      "Epoch 483/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0013 - mae: 0.0301\n",
      "Epoch 484/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0300\n",
      "Epoch 485/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0299\n",
      "Epoch 486/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0297\n",
      "Epoch 487/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0013 - mae: 0.0296\n",
      "Epoch 488/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0295\n",
      "Epoch 489/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0012 - mae: 0.0294\n",
      "Epoch 490/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0012 - mae: 0.0293\n",
      "Epoch 491/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0012 - mae: 0.0291\n",
      "Epoch 492/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0290\n",
      "Epoch 493/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0012 - mae: 0.0289\n",
      "Epoch 494/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0012 - mae: 0.0288\n",
      "Epoch 495/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0286\n",
      "Epoch 496/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0285\n",
      "Epoch 497/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0012 - mae: 0.0284\n",
      "Epoch 498/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0283\n",
      "Epoch 499/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0282\n",
      "Epoch 500/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0280\n",
      "Epoch 501/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0279\n",
      "Epoch 502/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0278\n",
      "Epoch 503/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0277\n",
      "Epoch 504/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0276\n",
      "Epoch 505/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0275\n",
      "Epoch 506/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 507/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0272\n",
      "Epoch 508/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 509/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0010 - mae: 0.0270\n",
      "Epoch 510/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0010 - mae: 0.0269\n",
      "Epoch 511/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0010 - mae: 0.0268\n",
      "Epoch 512/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0010 - mae: 0.0267\n",
      "Epoch 513/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0010 - mae: 0.0266\n",
      "Epoch 514/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0010 - mae: 0.0264\n",
      "Epoch 515/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.9354e-04 - mae: 0.0263\n",
      "Epoch 516/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.8521e-04 - mae: 0.0262\n",
      "Epoch 517/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.7696e-04 - mae: 0.0261\n",
      "Epoch 518/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.6877e-04 - mae: 0.0260\n",
      "Epoch 519/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.6064e-04 - mae: 0.0259\n",
      "Epoch 520/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.5259e-04 - mae: 0.0258\n",
      "Epoch 521/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.4462e-04 - mae: 0.0257\n",
      "Epoch 522/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.3669e-04 - mae: 0.0256\n",
      "Epoch 523/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.2885e-04 - mae: 0.0255\n",
      "Epoch 524/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.2105e-04 - mae: 0.0254\n",
      "Epoch 525/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.1334e-04 - mae: 0.0252\n",
      "Epoch 526/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.0569e-04 - mae: 0.0251\n",
      "Epoch 527/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.9809e-04 - mae: 0.0250\n",
      "Epoch 528/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.9057e-04 - mae: 0.0249\n",
      "Epoch 529/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.8311e-04 - mae: 0.0248\n",
      "Epoch 530/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.7570e-04 - mae: 0.0247\n",
      "Epoch 531/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.6837e-04 - mae: 0.0246\n",
      "Epoch 532/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.6108e-04 - mae: 0.0245\n",
      "Epoch 533/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.5385e-04 - mae: 0.0244\n",
      "Epoch 534/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.4669e-04 - mae: 0.0243\n",
      "Epoch 535/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.3962e-04 - mae: 0.0242\n",
      "Epoch 536/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.3259e-04 - mae: 0.0241\n",
      "Epoch 537/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.2559e-04 - mae: 0.0240\n",
      "Epoch 538/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.1868e-04 - mae: 0.0239\n",
      "Epoch 539/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.1183e-04 - mae: 0.0238\n",
      "Epoch 540/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.0501e-04 - mae: 0.0237\n",
      "Epoch 541/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.9826e-04 - mae: 0.0236\n",
      "Epoch 542/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.9156e-04 - mae: 0.0235\n",
      "Epoch 543/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.8493e-04 - mae: 0.0234\n",
      "Epoch 544/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.7836e-04 - mae: 0.0233\n",
      "Epoch 545/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.7183e-04 - mae: 0.0232\n",
      "Epoch 546/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.6535e-04 - mae: 0.0231\n",
      "Epoch 547/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.5895e-04 - mae: 0.0230\n",
      "Epoch 548/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.5259e-04 - mae: 0.0229\n",
      "Epoch 549/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.4627e-04 - mae: 0.0228\n",
      "Epoch 550/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.4002e-04 - mae: 0.0227\n",
      "Epoch 551/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.3383e-04 - mae: 0.0226\n",
      "Epoch 552/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.2768e-04 - mae: 0.0225\n",
      "Epoch 553/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.2157e-04 - mae: 0.0224\n",
      "Epoch 554/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.1554e-04 - mae: 0.0223\n",
      "Epoch 555/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.0952e-04 - mae: 0.0223\n",
      "Epoch 556/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 7.0359e-04 - mae: 0.0222\n",
      "Epoch 557/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.9770e-04 - mae: 0.0221\n",
      "Epoch 558/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.9183e-04 - mae: 0.0220\n",
      "Epoch 559/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.8603e-04 - mae: 0.0219\n",
      "Epoch 560/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.8029e-04 - mae: 0.0218\n",
      "Epoch 561/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.7458e-04 - mae: 0.0217\n",
      "Epoch 562/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.6894e-04 - mae: 0.0216\n",
      "Epoch 563/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.6334e-04 - mae: 0.0215\n",
      "Epoch 564/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.5776e-04 - mae: 0.0214\n",
      "Epoch 565/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.5225e-04 - mae: 0.0213\n",
      "Epoch 566/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.4679e-04 - mae: 0.0212\n",
      "Epoch 567/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.4138e-04 - mae: 0.0212\n",
      "Epoch 568/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 6.3598e-04 - mae: 0.0211\n",
      "Epoch 569/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.3065e-04 - mae: 0.0210\n",
      "Epoch 570/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.2536e-04 - mae: 0.0209\n",
      "Epoch 571/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.2012e-04 - mae: 0.0208\n",
      "Epoch 572/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 6.1494e-04 - mae: 0.0207\n",
      "Epoch 573/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.0978e-04 - mae: 0.0206\n",
      "Epoch 574/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.0467e-04 - mae: 0.0205\n",
      "Epoch 575/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.9961e-04 - mae: 0.0205\n",
      "Epoch 576/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.9459e-04 - mae: 0.0204\n",
      "Epoch 577/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.8958e-04 - mae: 0.0203\n",
      "Epoch 578/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.8465e-04 - mae: 0.0202\n",
      "Epoch 579/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.7975e-04 - mae: 0.0201\n",
      "Epoch 580/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.7490e-04 - mae: 0.0200\n",
      "Epoch 581/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.7008e-04 - mae: 0.0199\n",
      "Epoch 582/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.6530e-04 - mae: 0.0199\n",
      "Epoch 583/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.6056e-04 - mae: 0.0198\n",
      "Epoch 584/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.5586e-04 - mae: 0.0197\n",
      "Epoch 585/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.5119e-04 - mae: 0.0196\n",
      "Epoch 586/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.4658e-04 - mae: 0.0195\n",
      "Epoch 587/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.4199e-04 - mae: 0.0194\n",
      "Epoch 588/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3746e-04 - mae: 0.0194\n",
      "Epoch 589/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3295e-04 - mae: 0.0193\n",
      "Epoch 590/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.2850e-04 - mae: 0.0192\n",
      "Epoch 591/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.2405e-04 - mae: 0.0191\n",
      "Epoch 592/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.1966e-04 - mae: 0.0190\n",
      "Epoch 593/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.1531e-04 - mae: 0.0190\n",
      "Epoch 594/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.1098e-04 - mae: 0.0189\n",
      "Epoch 595/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 5.0671e-04 - mae: 0.0188\n",
      "Epoch 596/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.0246e-04 - mae: 0.0187\n",
      "Epoch 597/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9823e-04 - mae: 0.0186\n",
      "Epoch 598/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.9408e-04 - mae: 0.0186\n",
      "Epoch 599/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.8993e-04 - mae: 0.0185\n",
      "Epoch 600/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8583e-04 - mae: 0.0184\n",
      "Epoch 601/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8174e-04 - mae: 0.0183\n",
      "Epoch 602/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.7771e-04 - mae: 0.0183\n",
      "Epoch 603/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.7371e-04 - mae: 0.0182\n",
      "Epoch 604/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.6974e-04 - mae: 0.0181\n",
      "Epoch 605/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6579e-04 - mae: 0.0180\n",
      "Epoch 606/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6189e-04 - mae: 0.0180\n",
      "Epoch 607/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.5802e-04 - mae: 0.0179\n",
      "Epoch 608/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5419e-04 - mae: 0.0178\n",
      "Epoch 609/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5037e-04 - mae: 0.0177\n",
      "Epoch 610/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.4660e-04 - mae: 0.0177\n",
      "Epoch 611/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.4286e-04 - mae: 0.0176\n",
      "Epoch 612/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3915e-04 - mae: 0.0175\n",
      "Epoch 613/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 4.3548e-04 - mae: 0.0174\n",
      "Epoch 614/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3182e-04 - mae: 0.0174\n",
      "Epoch 615/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.2820e-04 - mae: 0.0173\n",
      "Epoch 616/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.2461e-04 - mae: 0.0172\n",
      "Epoch 617/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.2105e-04 - mae: 0.0171\n",
      "Epoch 618/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1753e-04 - mae: 0.0171\n",
      "Epoch 619/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1402e-04 - mae: 0.0170\n",
      "Epoch 620/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1056e-04 - mae: 0.0169\n",
      "Epoch 621/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0711e-04 - mae: 0.0169\n",
      "Epoch 622/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.0369e-04 - mae: 0.0168\n",
      "Epoch 623/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0032e-04 - mae: 0.0167\n",
      "Epoch 624/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.9696e-04 - mae: 0.0166\n",
      "Epoch 625/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.9363e-04 - mae: 0.0166\n",
      "Epoch 626/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.9033e-04 - mae: 0.0165\n",
      "Epoch 627/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.8706e-04 - mae: 0.0164\n",
      "Epoch 628/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.8381e-04 - mae: 0.0164\n",
      "Epoch 629/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.8060e-04 - mae: 0.0163\n",
      "Epoch 630/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.7741e-04 - mae: 0.0162\n",
      "Epoch 631/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.7425e-04 - mae: 0.0162\n",
      "Epoch 632/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.7112e-04 - mae: 0.0161\n",
      "Epoch 633/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.6799e-04 - mae: 0.0160\n",
      "Epoch 634/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.6492e-04 - mae: 0.0160\n",
      "Epoch 635/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.6185e-04 - mae: 0.0159\n",
      "Epoch 636/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.5882e-04 - mae: 0.0158\n",
      "Epoch 637/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5582e-04 - mae: 0.0158\n",
      "Epoch 638/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.5284e-04 - mae: 0.0157\n",
      "Epoch 639/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4988e-04 - mae: 0.0156\n",
      "Epoch 640/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.4694e-04 - mae: 0.0156\n",
      "Epoch 641/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.4405e-04 - mae: 0.0155\n",
      "Epoch 642/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4116e-04 - mae: 0.0154\n",
      "Epoch 643/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.3830e-04 - mae: 0.0154\n",
      "Epoch 644/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3546e-04 - mae: 0.0153\n",
      "Epoch 645/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3264e-04 - mae: 0.0152\n",
      "Epoch 646/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.2986e-04 - mae: 0.0152\n",
      "Epoch 647/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.2708e-04 - mae: 0.0151\n",
      "Epoch 648/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2435e-04 - mae: 0.0150\n",
      "Epoch 649/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2164e-04 - mae: 0.0150\n",
      "Epoch 650/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1893e-04 - mae: 0.0149\n",
      "Epoch 651/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1626e-04 - mae: 0.0149\n",
      "Epoch 652/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1361e-04 - mae: 0.0148\n",
      "Epoch 653/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1099e-04 - mae: 0.0147\n",
      "Epoch 654/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.0838e-04 - mae: 0.0147\n",
      "Epoch 655/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.0580e-04 - mae: 0.0146\n",
      "Epoch 656/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0324e-04 - mae: 0.0145\n",
      "Epoch 657/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0069e-04 - mae: 0.0145\n",
      "Epoch 658/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9817e-04 - mae: 0.0144\n",
      "Epoch 659/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9567e-04 - mae: 0.0144\n",
      "Epoch 660/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9319e-04 - mae: 0.0143\n",
      "Epoch 661/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9073e-04 - mae: 0.0142\n",
      "Epoch 662/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8829e-04 - mae: 0.0142\n",
      "Epoch 663/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8588e-04 - mae: 0.0141\n",
      "Epoch 664/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8349e-04 - mae: 0.0141\n",
      "Epoch 665/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8112e-04 - mae: 0.0140\n",
      "Epoch 666/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7875e-04 - mae: 0.0139\n",
      "Epoch 667/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7642e-04 - mae: 0.0139\n",
      "Epoch 668/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7410e-04 - mae: 0.0138\n",
      "Epoch 669/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7181e-04 - mae: 0.0138\n",
      "Epoch 670/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6953e-04 - mae: 0.0137\n",
      "Epoch 671/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6727e-04 - mae: 0.0137\n",
      "Epoch 672/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6503e-04 - mae: 0.0136\n",
      "Epoch 673/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6280e-04 - mae: 0.0135\n",
      "Epoch 674/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6060e-04 - mae: 0.0135\n",
      "Epoch 675/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.5842e-04 - mae: 0.0134\n",
      "Epoch 676/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5626e-04 - mae: 0.0134\n",
      "Epoch 677/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5411e-04 - mae: 0.0133\n",
      "Epoch 678/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5197e-04 - mae: 0.0133\n",
      "Epoch 679/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.4987e-04 - mae: 0.0132\n",
      "Epoch 680/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4777e-04 - mae: 0.0131\n",
      "Epoch 681/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.4570e-04 - mae: 0.0131\n",
      "Epoch 682/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4364e-04 - mae: 0.0130\n",
      "Epoch 683/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4159e-04 - mae: 0.0130\n",
      "Epoch 684/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3957e-04 - mae: 0.0129\n",
      "Epoch 685/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3755e-04 - mae: 0.0129\n",
      "Epoch 686/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3557e-04 - mae: 0.0128\n",
      "Epoch 687/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3360e-04 - mae: 0.0128\n",
      "Epoch 688/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3163e-04 - mae: 0.0127\n",
      "Epoch 689/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2970e-04 - mae: 0.0127\n",
      "Epoch 690/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2777e-04 - mae: 0.0126\n",
      "Epoch 691/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2587e-04 - mae: 0.0126\n",
      "Epoch 692/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2397e-04 - mae: 0.0125\n",
      "Epoch 693/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2209e-04 - mae: 0.0124\n",
      "Epoch 694/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2022e-04 - mae: 0.0124\n",
      "Epoch 695/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1838e-04 - mae: 0.0123\n",
      "Epoch 696/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1656e-04 - mae: 0.0123\n",
      "Epoch 697/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1474e-04 - mae: 0.0122\n",
      "Epoch 698/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1294e-04 - mae: 0.0122\n",
      "Epoch 699/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1115e-04 - mae: 0.0121\n",
      "Epoch 700/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0938e-04 - mae: 0.0121\n",
      "Epoch 701/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0763e-04 - mae: 0.0120\n",
      "Epoch 702/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0589e-04 - mae: 0.0120\n",
      "Epoch 703/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0416e-04 - mae: 0.0119\n",
      "Epoch 704/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0245e-04 - mae: 0.0119\n",
      "Epoch 705/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0075e-04 - mae: 0.0118\n",
      "Epoch 706/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9907e-04 - mae: 0.0118\n",
      "Epoch 707/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9740e-04 - mae: 0.0117\n",
      "Epoch 708/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9575e-04 - mae: 0.0117\n",
      "Epoch 709/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9410e-04 - mae: 0.0116\n",
      "Epoch 710/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9249e-04 - mae: 0.0116\n",
      "Epoch 711/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.9087e-04 - mae: 0.0115\n",
      "Epoch 712/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8926e-04 - mae: 0.0115\n",
      "Epoch 713/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8768e-04 - mae: 0.0114\n",
      "Epoch 714/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8610e-04 - mae: 0.0114\n",
      "Epoch 715/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8455e-04 - mae: 0.0113\n",
      "Epoch 716/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8300e-04 - mae: 0.0113\n",
      "Epoch 717/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8147e-04 - mae: 0.0113\n",
      "Epoch 718/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7995e-04 - mae: 0.0112\n",
      "Epoch 719/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7844e-04 - mae: 0.0112\n",
      "Epoch 720/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7695e-04 - mae: 0.0111\n",
      "Epoch 721/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7546e-04 - mae: 0.0111\n",
      "Epoch 722/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7399e-04 - mae: 0.0110\n",
      "Epoch 723/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.7253e-04 - mae: 0.0110\n",
      "Epoch 724/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7109e-04 - mae: 0.0109\n",
      "Epoch 725/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.6965e-04 - mae: 0.0109\n",
      "Epoch 726/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6823e-04 - mae: 0.0108\n",
      "Epoch 727/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.6681e-04 - mae: 0.0108\n",
      "Epoch 728/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.6542e-04 - mae: 0.0107\n",
      "Epoch 729/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6404e-04 - mae: 0.0107\n",
      "Epoch 730/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6266e-04 - mae: 0.0107\n",
      "Epoch 731/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6130e-04 - mae: 0.0106\n",
      "Epoch 732/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5995e-04 - mae: 0.0106\n",
      "Epoch 733/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5861e-04 - mae: 0.0105\n",
      "Epoch 734/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5727e-04 - mae: 0.0105\n",
      "Epoch 735/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5596e-04 - mae: 0.0104\n",
      "Epoch 736/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5465e-04 - mae: 0.0104\n",
      "Epoch 737/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5335e-04 - mae: 0.0103\n",
      "Epoch 738/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5206e-04 - mae: 0.0103\n",
      "Epoch 739/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5079e-04 - mae: 0.0103\n",
      "Epoch 740/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.4952e-04 - mae: 0.0102\n",
      "Epoch 741/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4827e-04 - mae: 0.0102\n",
      "Epoch 742/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.4703e-04 - mae: 0.0101\n",
      "Epoch 743/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4580e-04 - mae: 0.0101\n",
      "Epoch 744/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4457e-04 - mae: 0.0100\n",
      "Epoch 745/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.4337e-04 - mae: 0.0100\n",
      "Epoch 746/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.4217e-04 - mae: 0.0100\n",
      "Epoch 747/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.4097e-04 - mae: 0.0099\n",
      "Epoch 748/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3980e-04 - mae: 0.0099\n",
      "Epoch 749/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3862e-04 - mae: 0.0098\n",
      "Epoch 750/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3745e-04 - mae: 0.0098\n",
      "Epoch 751/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3631e-04 - mae: 0.0098\n",
      "Epoch 752/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3516e-04 - mae: 0.0097\n",
      "Epoch 753/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3404e-04 - mae: 0.0097\n",
      "Epoch 754/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3291e-04 - mae: 0.0096\n",
      "Epoch 755/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3179e-04 - mae: 0.0096\n",
      "Epoch 756/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3069e-04 - mae: 0.0096\n",
      "Epoch 757/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2959e-04 - mae: 0.0095\n",
      "Epoch 758/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2851e-04 - mae: 0.0095\n",
      "Epoch 759/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2743e-04 - mae: 0.0094\n",
      "Epoch 760/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2636e-04 - mae: 0.0094\n",
      "Epoch 761/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2531e-04 - mae: 0.0094\n",
      "Epoch 762/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2425e-04 - mae: 0.0093\n",
      "Epoch 763/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2321e-04 - mae: 0.0093\n",
      "Epoch 764/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2218e-04 - mae: 0.0092\n",
      "Epoch 765/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2115e-04 - mae: 0.0092\n",
      "Epoch 766/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2014e-04 - mae: 0.0092\n",
      "Epoch 767/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1913e-04 - mae: 0.0091\n",
      "Epoch 768/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1814e-04 - mae: 0.0091\n",
      "Epoch 769/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1714e-04 - mae: 0.0090\n",
      "Epoch 770/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1616e-04 - mae: 0.0090\n",
      "Epoch 771/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1519e-04 - mae: 0.0090\n",
      "Epoch 772/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1422e-04 - mae: 0.0089\n",
      "Epoch 773/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1327e-04 - mae: 0.0089\n",
      "Epoch 774/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1232e-04 - mae: 0.0089\n",
      "Epoch 775/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1138e-04 - mae: 0.0088\n",
      "Epoch 776/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1044e-04 - mae: 0.0088\n",
      "Epoch 777/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0952e-04 - mae: 0.0087\n",
      "Epoch 778/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0859e-04 - mae: 0.0087\n",
      "Epoch 779/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0768e-04 - mae: 0.0087\n",
      "Epoch 780/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0678e-04 - mae: 0.0086\n",
      "Epoch 781/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0589e-04 - mae: 0.0086\n",
      "Epoch 782/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0500e-04 - mae: 0.0086\n",
      "Epoch 783/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0413e-04 - mae: 0.0085\n",
      "Epoch 784/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0325e-04 - mae: 0.0085\n",
      "Epoch 785/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0238e-04 - mae: 0.0085\n",
      "Epoch 786/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0153e-04 - mae: 0.0084\n",
      "Epoch 787/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0068e-04 - mae: 0.0084\n",
      "Epoch 788/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.9830e-05 - mae: 0.0083\n",
      "Epoch 789/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.8995e-05 - mae: 0.0083\n",
      "Epoch 790/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 9.8168e-05 - mae: 0.0083\n",
      "Epoch 791/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.7342e-05 - mae: 0.0082\n",
      "Epoch 792/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.6524e-05 - mae: 0.0082\n",
      "Epoch 793/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.5717e-05 - mae: 0.0082\n",
      "Epoch 794/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.4913e-05 - mae: 0.0081\n",
      "Epoch 795/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.4118e-05 - mae: 0.0081\n",
      "Epoch 796/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.3331e-05 - mae: 0.0081\n",
      "Epoch 797/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.2550e-05 - mae: 0.0080\n",
      "Epoch 798/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.1777e-05 - mae: 0.0080\n",
      "Epoch 799/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.1005e-05 - mae: 0.0080\n",
      "Epoch 800/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.0244e-05 - mae: 0.0079\n",
      "Epoch 801/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.9490e-05 - mae: 0.0079\n",
      "Epoch 802/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.8738e-05 - mae: 0.0079\n",
      "Epoch 803/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.7987e-05 - mae: 0.0078\n",
      "Epoch 804/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.7252e-05 - mae: 0.0078\n",
      "Epoch 805/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.6524e-05 - mae: 0.0078\n",
      "Epoch 806/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.5802e-05 - mae: 0.0077\n",
      "Epoch 807/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.5078e-05 - mae: 0.0077\n",
      "Epoch 808/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.4366e-05 - mae: 0.0077\n",
      "Epoch 809/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.3656e-05 - mae: 0.0076\n",
      "Epoch 810/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.2956e-05 - mae: 0.0076\n",
      "Epoch 811/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.2261e-05 - mae: 0.0076\n",
      "Epoch 812/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.1567e-05 - mae: 0.0075\n",
      "Epoch 813/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.0883e-05 - mae: 0.0075\n",
      "Epoch 814/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 8.0210e-05 - mae: 0.0075\n",
      "Epoch 815/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.9542e-05 - mae: 0.0075\n",
      "Epoch 816/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.8873e-05 - mae: 0.0074\n",
      "Epoch 817/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.8207e-05 - mae: 0.0074\n",
      "Epoch 818/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.7550e-05 - mae: 0.0074\n",
      "Epoch 819/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.6901e-05 - mae: 0.0073\n",
      "Epoch 820/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.6259e-05 - mae: 0.0073\n",
      "Epoch 821/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.5623e-05 - mae: 0.0073\n",
      "Epoch 822/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.4986e-05 - mae: 0.0072\n",
      "Epoch 823/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.4361e-05 - mae: 0.0072\n",
      "Epoch 824/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.3737e-05 - mae: 0.0072\n",
      "Epoch 825/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.3116e-05 - mae: 0.0071\n",
      "Epoch 826/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.2506e-05 - mae: 0.0071\n",
      "Epoch 827/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.1897e-05 - mae: 0.0071\n",
      "Epoch 828/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.1290e-05 - mae: 0.0071\n",
      "Epoch 829/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.0701e-05 - mae: 0.0070\n",
      "Epoch 830/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.0108e-05 - mae: 0.0070\n",
      "Epoch 831/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.9512e-05 - mae: 0.0070\n",
      "Epoch 832/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.8934e-05 - mae: 0.0069\n",
      "Epoch 833/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.8359e-05 - mae: 0.0069\n",
      "Epoch 834/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.7782e-05 - mae: 0.0069\n",
      "Epoch 835/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.7214e-05 - mae: 0.0068\n",
      "Epoch 836/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.6650e-05 - mae: 0.0068\n",
      "Epoch 837/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.6093e-05 - mae: 0.0068\n",
      "Epoch 838/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.5536e-05 - mae: 0.0068\n",
      "Epoch 839/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.4991e-05 - mae: 0.0067\n",
      "Epoch 840/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.4444e-05 - mae: 0.0067\n",
      "Epoch 841/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.3904e-05 - mae: 0.0067\n",
      "Epoch 842/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.3372e-05 - mae: 0.0067\n",
      "Epoch 843/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.2835e-05 - mae: 0.0066\n",
      "Epoch 844/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.2311e-05 - mae: 0.0066\n",
      "Epoch 845/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.1794e-05 - mae: 0.0066\n",
      "Epoch 846/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.1272e-05 - mae: 0.0065\n",
      "Epoch 847/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.0758e-05 - mae: 0.0065\n",
      "Epoch 848/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.0248e-05 - mae: 0.0065\n",
      "Epoch 849/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.9744e-05 - mae: 0.0065\n",
      "Epoch 850/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.9241e-05 - mae: 0.0064\n",
      "Epoch 851/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.8751e-05 - mae: 0.0064\n",
      "Epoch 852/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.8254e-05 - mae: 0.0064\n",
      "Epoch 853/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.7764e-05 - mae: 0.0063\n",
      "Epoch 854/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.7279e-05 - mae: 0.0063\n",
      "Epoch 855/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.6803e-05 - mae: 0.0063\n",
      "Epoch 856/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.6325e-05 - mae: 0.0063\n",
      "Epoch 857/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5855e-05 - mae: 0.0062\n",
      "Epoch 858/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5388e-05 - mae: 0.0062\n",
      "Epoch 859/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.4921e-05 - mae: 0.0062\n",
      "Epoch 860/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.4459e-05 - mae: 0.0062\n",
      "Epoch 861/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.4003e-05 - mae: 0.0061\n",
      "Epoch 862/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.3550e-05 - mae: 0.0061\n",
      "Epoch 863/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3105e-05 - mae: 0.0061\n",
      "Epoch 864/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.2659e-05 - mae: 0.0061\n",
      "Epoch 865/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.2217e-05 - mae: 0.0060\n",
      "Epoch 866/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.1782e-05 - mae: 0.0060\n",
      "Epoch 867/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.1345e-05 - mae: 0.0060\n",
      "Epoch 868/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.0915e-05 - mae: 0.0060\n",
      "Epoch 869/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.0490e-05 - mae: 0.0059\n",
      "Epoch 870/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.0068e-05 - mae: 0.0059\n",
      "Epoch 871/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9642e-05 - mae: 0.0059\n",
      "Epoch 872/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9230e-05 - mae: 0.0059\n",
      "Epoch 873/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8816e-05 - mae: 0.0058\n",
      "Epoch 874/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8406e-05 - mae: 0.0058\n",
      "Epoch 875/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.7998e-05 - mae: 0.0058\n",
      "Epoch 876/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.7597e-05 - mae: 0.0058\n",
      "Epoch 877/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.7200e-05 - mae: 0.0057\n",
      "Epoch 878/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 4.6804e-05 - mae: 0.0057\n",
      "Epoch 879/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6408e-05 - mae: 0.0057\n",
      "Epoch 880/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6024e-05 - mae: 0.0057\n",
      "Epoch 881/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5639e-05 - mae: 0.0056\n",
      "Epoch 882/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5256e-05 - mae: 0.0056\n",
      "Epoch 883/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.4877e-05 - mae: 0.0056\n",
      "Epoch 884/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.4499e-05 - mae: 0.0056\n",
      "Epoch 885/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.4127e-05 - mae: 0.0055\n",
      "Epoch 886/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3753e-05 - mae: 0.0055\n",
      "Epoch 887/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3390e-05 - mae: 0.0055\n",
      "Epoch 888/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 4.3026e-05 - mae: 0.0055\n",
      "Epoch 889/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.2664e-05 - mae: 0.0055\n",
      "Epoch 890/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.2305e-05 - mae: 0.0054\n",
      "Epoch 891/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1953e-05 - mae: 0.0054\n",
      "Epoch 892/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1601e-05 - mae: 0.0054\n",
      "Epoch 893/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1255e-05 - mae: 0.0054\n",
      "Epoch 894/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0905e-05 - mae: 0.0053\n",
      "Epoch 895/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0564e-05 - mae: 0.0053\n",
      "Epoch 896/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0227e-05 - mae: 0.0053\n",
      "Epoch 897/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.9888e-05 - mae: 0.0053\n",
      "Epoch 898/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.9551e-05 - mae: 0.0053\n",
      "Epoch 899/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 3.9224e-05 - mae: 0.0052\n",
      "Epoch 900/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.8894e-05 - mae: 0.0052\n",
      "Epoch 901/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.8569e-05 - mae: 0.0052\n",
      "Epoch 902/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.8244e-05 - mae: 0.0052\n",
      "Epoch 903/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.7928e-05 - mae: 0.0051\n",
      "Epoch 904/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.7607e-05 - mae: 0.0051\n",
      "Epoch 905/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.7292e-05 - mae: 0.0051\n",
      "Epoch 906/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.6978e-05 - mae: 0.0051\n",
      "Epoch 907/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.6668e-05 - mae: 0.0051\n",
      "Epoch 908/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.6362e-05 - mae: 0.0050\n",
      "Epoch 909/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.6056e-05 - mae: 0.0050\n",
      "Epoch 910/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5756e-05 - mae: 0.0050\n",
      "Epoch 911/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5453e-05 - mae: 0.0050\n",
      "Epoch 912/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5159e-05 - mae: 0.0050\n",
      "Epoch 913/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.4862e-05 - mae: 0.0049\n",
      "Epoch 914/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.4571e-05 - mae: 0.0049\n",
      "Epoch 915/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.4281e-05 - mae: 0.0049\n",
      "Epoch 916/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3994e-05 - mae: 0.0049\n",
      "Epoch 917/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3711e-05 - mae: 0.0049\n",
      "Epoch 918/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3425e-05 - mae: 0.0048\n",
      "Epoch 919/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3148e-05 - mae: 0.0048\n",
      "Epoch 920/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2869e-05 - mae: 0.0048\n",
      "Epoch 921/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2593e-05 - mae: 0.0048\n",
      "Epoch 922/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2320e-05 - mae: 0.0047\n",
      "Epoch 923/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2052e-05 - mae: 0.0047\n",
      "Epoch 924/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.1778e-05 - mae: 0.0047\n",
      "Epoch 925/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.1513e-05 - mae: 0.0047\n",
      "Epoch 926/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.1250e-05 - mae: 0.0047\n",
      "Epoch 927/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.0990e-05 - mae: 0.0047\n",
      "Epoch 928/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 3.0730e-05 - mae: 0.0046\n",
      "Epoch 929/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0468e-05 - mae: 0.0046\n",
      "Epoch 930/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0217e-05 - mae: 0.0046\n",
      "Epoch 931/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9963e-05 - mae: 0.0046\n",
      "Epoch 932/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9713e-05 - mae: 0.0046\n",
      "Epoch 933/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9464e-05 - mae: 0.0045\n",
      "Epoch 934/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9214e-05 - mae: 0.0045\n",
      "Epoch 935/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8970e-05 - mae: 0.0045\n",
      "Epoch 936/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 2.8729e-05 - mae: 0.0045\n",
      "Epoch 937/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 2.8485e-05 - mae: 0.0045\n",
      "Epoch 938/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8250e-05 - mae: 0.0044\n",
      "Epoch 939/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8011e-05 - mae: 0.0044\n",
      "Epoch 940/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7778e-05 - mae: 0.0044\n",
      "Epoch 941/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7545e-05 - mae: 0.0044\n",
      "Epoch 942/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7313e-05 - mae: 0.0044\n",
      "Epoch 943/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7084e-05 - mae: 0.0043\n",
      "Epoch 944/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6858e-05 - mae: 0.0043\n",
      "Epoch 945/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6631e-05 - mae: 0.0043\n",
      "Epoch 946/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6409e-05 - mae: 0.0043\n",
      "Epoch 947/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6185e-05 - mae: 0.0043\n",
      "Epoch 948/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5968e-05 - mae: 0.0043\n",
      "Epoch 949/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5751e-05 - mae: 0.0042\n",
      "Epoch 950/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5535e-05 - mae: 0.0042\n",
      "Epoch 951/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5321e-05 - mae: 0.0042\n",
      "Epoch 952/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5108e-05 - mae: 0.0042\n",
      "Epoch 953/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4899e-05 - mae: 0.0042\n",
      "Epoch 954/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4690e-05 - mae: 0.0042\n",
      "Epoch 955/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.4482e-05 - mae: 0.0041\n",
      "Epoch 956/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4278e-05 - mae: 0.0041\n",
      "Epoch 957/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.4073e-05 - mae: 0.0041\n",
      "Epoch 958/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3875e-05 - mae: 0.0041\n",
      "Epoch 959/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3673e-05 - mae: 0.0041\n",
      "Epoch 960/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3473e-05 - mae: 0.0040\n",
      "Epoch 961/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3278e-05 - mae: 0.0040\n",
      "Epoch 962/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3082e-05 - mae: 0.0040\n",
      "Epoch 963/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2889e-05 - mae: 0.0040\n",
      "Epoch 964/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2695e-05 - mae: 0.0040\n",
      "Epoch 965/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2508e-05 - mae: 0.0040\n",
      "Epoch 966/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2319e-05 - mae: 0.0039\n",
      "Epoch 967/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2130e-05 - mae: 0.0039\n",
      "Epoch 968/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.1947e-05 - mae: 0.0039\n",
      "Epoch 969/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1763e-05 - mae: 0.0039\n",
      "Epoch 970/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1579e-05 - mae: 0.0039\n",
      "Epoch 971/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1398e-05 - mae: 0.0039\n",
      "Epoch 972/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1220e-05 - mae: 0.0038\n",
      "Epoch 973/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1041e-05 - mae: 0.0038\n",
      "Epoch 974/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0864e-05 - mae: 0.0038\n",
      "Epoch 975/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0692e-05 - mae: 0.0038\n",
      "Epoch 976/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0517e-05 - mae: 0.0038\n",
      "Epoch 977/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0347e-05 - mae: 0.0038\n",
      "Epoch 978/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0174e-05 - mae: 0.0038\n",
      "Epoch 979/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0005e-05 - mae: 0.0037\n",
      "Epoch 980/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9837e-05 - mae: 0.0037\n",
      "Epoch 981/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9672e-05 - mae: 0.0037\n",
      "Epoch 982/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 1.9506e-05 - mae: 0.0037\n",
      "Epoch 983/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9344e-05 - mae: 0.0037\n",
      "Epoch 984/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9180e-05 - mae: 0.0037\n",
      "Epoch 985/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9021e-05 - mae: 0.0036\n",
      "Epoch 986/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8862e-05 - mae: 0.0036\n",
      "Epoch 987/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8703e-05 - mae: 0.0036\n",
      "Epoch 988/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8547e-05 - mae: 0.0036\n",
      "Epoch 989/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8390e-05 - mae: 0.0036\n",
      "Epoch 990/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8239e-05 - mae: 0.0036\n",
      "Epoch 991/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8084e-05 - mae: 0.0036\n",
      "Epoch 992/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7933e-05 - mae: 0.0035\n",
      "Epoch 993/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7781e-05 - mae: 0.0035\n",
      "Epoch 994/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7630e-05 - mae: 0.0035\n",
      "Epoch 995/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.7483e-05 - mae: 0.0035\n",
      "Epoch 996/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7338e-05 - mae: 0.0035\n",
      "Epoch 997/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 1.7193e-05 - mae: 0.0035\n",
      "Epoch 998/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7050e-05 - mae: 0.0034\n",
      "Epoch 999/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.6905e-05 - mae: 0.0034\n",
      "Epoch 1000/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.6764e-05 - mae: 0.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17dae1410>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:40:28.735124Z",
     "start_time": "2024-09-02T06:40:28.733049Z"
    }
   },
   "source": [
    "# 모델 가중치 확인하기\n",
    "print(model.weights)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasVariable shape=(1, 1), dtype=float32, path=sequential/dense/kernel>, <KerasVariable shape=(1,), dtype=float32, path=sequential/dense/bias>]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:40:32.355445Z",
     "start_time": "2024-09-02T06:40:32.350774Z"
    }
   },
   "source": [
    "# 모델 레이어의 가중치 출력하기\n",
    "print(f'weight : {model.layers[0].weights[0].numpy()}')\n",
    "print(f'bias : {model.layers[0].bias.numpy()}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : [[2.001265]]\n",
      "bias : [0.99119264]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-09-02T06:41:07.865527Z",
     "start_time": "2024-09-02T06:41:07.823988Z"
    }
   },
   "source": [
    "# 학습 완료된 모델 사용하여 예측하기\n",
    "print(model.predict(np.array([[11],[12],[13]])))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "[[23.005108]\n",
      " [25.006372]\n",
      " [27.007637]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:41:10.291093Z",
     "start_time": "2024-09-02T06:41:10.287913Z"
    }
   },
   "cell_type": "code",
   "source": "help(model.predict)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method predict in module keras.src.backend.tensorflow.trainer:\n",
      "\n",
      "predict(x, batch_size=None, verbose='auto', steps=None, callbacks=None) method of keras.src.models.sequential.Sequential instance\n",
      "    Generates output predictions for the input samples.\n",
      "    \n",
      "    Computation is done in batches. This method is designed for batch\n",
      "    processing of large numbers of inputs. It is not intended for use inside\n",
      "    of loops that iterate over your data and process small numbers of inputs\n",
      "    at a time.\n",
      "    \n",
      "    For small numbers of inputs that fit in one batch,\n",
      "    directly use `__call__()` for faster execution, e.g.,\n",
      "    `model(x)`, or `model(x, training=False)` if you have layers such as\n",
      "    `BatchNormalization` that behave differently during\n",
      "    inference.\n",
      "    \n",
      "    Note: See [this FAQ entry](\n",
      "    https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
      "    for more details about the difference between `Model` methods\n",
      "    `predict()` and `__call__()`.\n",
      "    \n",
      "    Args:\n",
      "        x: Input samples. It could be:\n",
      "            - A NumPy array (or array-like), or a list of arrays\n",
      "                (in case the model has multiple inputs).\n",
      "            - A tensor, or a list of tensors\n",
      "                (in case the model has multiple inputs).\n",
      "            - A `tf.data.Dataset`.\n",
      "            - A `keras.utils.PyDataset` instance.\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per batch.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of dataset, generators, or `keras.utils.PyDataset`\n",
      "            instances (since they generate batches).\n",
      "        verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = single line.\n",
      "            `\"auto\"` becomes 1 for most cases. Note that the progress bar\n",
      "            is not particularly useful when logged to a file,\n",
      "            so `verbose=2` is recommended when not running interactively\n",
      "            (e.g. in a production environment). Defaults to `\"auto\"`.\n",
      "        steps: Total number of steps (batches of samples)\n",
      "            before declaring the prediction round finished.\n",
      "            Ignored with the default value of `None`.\n",
      "            If `x` is a `tf.data.Dataset` and `steps` is `None`,\n",
      "            `predict()` will run until the input dataset is exhausted.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during prediction.\n",
      "    \n",
      "    Returns:\n",
      "        NumPy array(s) of predictions.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:41:12.483994Z",
     "start_time": "2024-09-02T06:41:12.481723Z"
    }
   },
   "source": [
    "# 클래스와 메소드 사용법 확인하기\n",
    "help(model.fit)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module keras.src.backend.tensorflow.trainer:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1) method of keras.src.models.sequential.Sequential instance\n",
      "    Trains the model for a fixed number of epochs (dataset iterations).\n",
      "    \n",
      "    Args:\n",
      "        x: Input data. It could be:\n",
      "            - A NumPy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "            - A tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "            - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "            - A `tf.data.Dataset`. Should return a tuple\n",
      "            of either `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "            - A `keras.utils.PyDataset` returning `(inputs,\n",
      "            targets)` or `(inputs, targets, sample_weights)`.\n",
      "        y: Target data. Like the input data `x`,\n",
      "            it could be either NumPy array(s) or backend-native tensor(s).\n",
      "            If `x` is a dataset, generator,\n",
      "            or `keras.utils.PyDataset` instance, `y` should\n",
      "            not be specified (since targets will be obtained from `x`).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of datasets, generators, or `keras.utils.PyDataset`\n",
      "            instances (since they generate batches).\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided\n",
      "            (unless the `steps_per_epoch` flag is set to\n",
      "            something other than None).\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "            \"auto\" becomes 1 for most cases.\n",
      "            Note that the progress bar is not\n",
      "            particularly useful when logged to a file,\n",
      "            so `verbose=2` is recommended when not running interactively\n",
      "            (e.g., in a production environment). Defaults to `\"auto\"`.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training.\n",
      "            See `keras.callbacks`. Note\n",
      "            `keras.callbacks.ProgbarLogger` and\n",
      "            `keras.callbacks.History` callbacks are created\n",
      "            automatically and need not be passed to `model.fit()`.\n",
      "            `keras.callbacks.ProgbarLogger` is created\n",
      "            or not based on the `verbose` argument in `model.fit()`.\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate\n",
      "            the loss and any model metrics\n",
      "            on this data at the end of each epoch.\n",
      "            The validation data is selected from the last samples\n",
      "            in the `x` and `y` data provided, before shuffling. This\n",
      "            argument is not supported when `x` is a dataset, generator or\n",
      "            `keras.utils.PyDataset` instance.\n",
      "            If both `validation_data` and `validation_split` are provided,\n",
      "            `validation_data` will override `validation_split`.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data. Thus, note the fact\n",
      "            that the validation loss of data provided using\n",
      "            `validation_split` or `validation_data` is not affected by\n",
      "            regularization layers like noise and dropout.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            It could be:\n",
      "            - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
      "            - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
      "            arrays.\n",
      "            - A `tf.data.Dataset`.\n",
      "            - A Python generator or `keras.utils.PyDataset` returning\n",
      "            `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
      "        shuffle: Boolean, whether to shuffle the training data\n",
      "            before each epoch. This argument is\n",
      "            ignored when `x` is a generator or a `tf.data.Dataset`.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class. When `class_weight` is specified\n",
      "            and targets have a rank of 2 or greater, either `y` must be\n",
      "            one-hot encoded, or an explicit final dimension of `1` must\n",
      "            be included for sparse class labels.\n",
      "        sample_weight: Optional NumPy array of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            NumPy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample.\n",
      "            This argument is not supported when `x` is a dataset, generator,\n",
      "            or `keras.utils.PyDataset` instance, instead provide the\n",
      "            sample_weights as the third element of `x`.\n",
      "            Note that sample weighting does not apply to metrics specified\n",
      "            via the `metrics` argument in `compile()`. To apply sample\n",
      "            weighting to your metrics, you can specify them via the\n",
      "            `weighted_metrics` in `compile()` instead.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring one epoch finished and starting the\n",
      "            next epoch. When training with input tensors such as\n",
      "            backend-native tensors, the default `None` is equal to\n",
      "            the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined. If `x` is a\n",
      "            `tf.data.Dataset`, and `steps_per_epoch`\n",
      "            is `None`, the epoch will run until the input dataset is\n",
      "            exhausted.  When passing an infinitely repeating dataset, you\n",
      "            must specify the `steps_per_epoch` argument. If\n",
      "            `steps_per_epoch=-1` the training will run indefinitely with an\n",
      "            infinitely repeating dataset.\n",
      "        validation_steps: Only relevant if `validation_data` is provided.\n",
      "            Total number of steps (batches of\n",
      "            samples) to draw before stopping when performing validation\n",
      "            at the end of every epoch. If `validation_steps` is `None`,\n",
      "            validation will run until the `validation_data` dataset is\n",
      "            exhausted. In the case of an infinitely repeated dataset, it\n",
      "            will run into an infinite loop. If `validation_steps` is\n",
      "            specified and only part of the dataset will be consumed, the\n",
      "            evaluation will start from the beginning of the dataset at each\n",
      "            epoch. This ensures that the same validation samples are used\n",
      "            every time.\n",
      "        validation_batch_size: Integer or `None`.\n",
      "            Number of samples per validation batch.\n",
      "            If unspecified, will default to `batch_size`.\n",
      "            Do not specify the `validation_batch_size` if your data is in\n",
      "            the form of datasets or `keras.utils.PyDataset`\n",
      "            instances (since they generate batches).\n",
      "        validation_freq: Only relevant if validation data is provided.\n",
      "            Specifies how many training epochs to run\n",
      "            before a new validation run is performed,\n",
      "            e.g. `validation_freq=2` runs validation every 2 epochs.\n",
      "    \n",
      "    Unpacking behavior for iterator-like inputs:\n",
      "        A common pattern is to pass an iterator like object such as a\n",
      "        `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
      "        which will in fact yield not only features (`x`)\n",
      "        but optionally targets (`y`) and sample weights (`sample_weight`).\n",
      "        Keras requires that the output of such iterator-likes be\n",
      "        unambiguous. The iterator should return a tuple\n",
      "        of length 1, 2, or 3, where the optional second and third elements\n",
      "        will be used for `y` and `sample_weight` respectively.\n",
      "        Any other type provided will be wrapped in\n",
      "        a length-one tuple, effectively treating everything as `x`. When\n",
      "        yielding dicts, they should still adhere to the top-level tuple\n",
      "        structure,\n",
      "        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      "        features, targets, and weights from the keys of a single dict.\n",
      "        A notable unsupported data type is the `namedtuple`. The reason is\n",
      "        that it behaves like both an ordered datatype (tuple) and a mapping\n",
      "        datatype (dict). So given a namedtuple of the form:\n",
      "        `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      "        it is ambiguous whether to reverse the order of the elements when\n",
      "        interpreting the value. Even worse is a tuple of the form:\n",
      "        `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      "        where it is unclear if the tuple was intended to be unpacked\n",
      "        into `x`, `y`, and `sample_weight` or passed through\n",
      "        as a single element to `x`.\n",
      "    \n",
      "    Returns:\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 심층신경망으로 항공사 고객 만족 분류 모델 구현 실습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터 로드 및 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:41:27.784045Z",
     "start_time": "2024-09-02T06:41:27.781841Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# 경고 메시지를 무시하도록 설정하기\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:41:30.861092Z",
     "start_time": "2024-09-02T06:41:30.735817Z"
    }
   },
   "source": [
    "# csv 파일에서 데이터를 로드해서 데이터프레임으로 저장하기\n",
    "df = pd.read_csv('./dataset/Invistico_Airline.csv')\n",
    "\n",
    "# 데이터프레임 정보 확인하기\n",
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129880 entries, 0 to 129879\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   satisfaction                       129880 non-null  object \n",
      " 1   Gender                             129880 non-null  object \n",
      " 2   Customer Type                      129880 non-null  object \n",
      " 3   Age                                129880 non-null  int64  \n",
      " 4   Type of Travel                     129880 non-null  object \n",
      " 5   Class                              129880 non-null  object \n",
      " 6   Flight Distance                    129880 non-null  int64  \n",
      " 7   Seat comfort                       129880 non-null  int64  \n",
      " 8   Departure/Arrival time convenient  129880 non-null  int64  \n",
      " 9   Food and drink                     129880 non-null  int64  \n",
      " 10  Gate location                      129880 non-null  int64  \n",
      " 11  Inflight wifi service              129880 non-null  int64  \n",
      " 12  Inflight entertainment             129880 non-null  int64  \n",
      " 13  Online support                     129880 non-null  int64  \n",
      " 14  Ease of Online booking             129880 non-null  int64  \n",
      " 15  On-board service                   129880 non-null  int64  \n",
      " 16  Leg room service                   129880 non-null  int64  \n",
      " 17  Baggage handling                   129880 non-null  int64  \n",
      " 18  Checkin service                    129880 non-null  int64  \n",
      " 19  Cleanliness                        129880 non-null  int64  \n",
      " 20  Online boarding                    129880 non-null  int64  \n",
      " 21  Departure Delay in Minutes         129880 non-null  int64  \n",
      " 22  Arrival Delay in Minutes           129487 non-null  float64\n",
      "dtypes: float64(1), int64(17), object(5)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 데이터프레임의 처음 5개 행의 데이터 출력하기\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 데이터프레임의 요약 통계량 확인하기\n",
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 결측치 확인하기\n",
    "df.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 전처리하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 결측치 처리하기 "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:41:48.104172Z",
     "start_time": "2024-09-02T06:41:47.950559Z"
    }
   },
   "source": [
    "# SimpleImputer 객체로 결측치 대체하기\n",
    "from sklearn.impute import SimpleImputer\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df[\"Arrival Delay in Minutes\"] = mean_imputer.fit_transform(df[[\"Arrival Delay in Minutes\"]])"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:41:49.919535Z",
     "start_time": "2024-09-02T06:41:49.916065Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"Arrival Delay in Minutes\"].isnull().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 데이터 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:43:58.260595Z",
     "start_time": "2024-09-02T06:43:58.239072Z"
    }
   },
   "source": [
    "# object 칼럼 유형을 string 유형으로 변경하기\n",
    "cols = ['satisfaction', 'Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
    "df[cols].info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129880 entries, 0 to 129879\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   satisfaction    129880 non-null  object\n",
      " 1   Gender          129880 non-null  object\n",
      " 2   Customer Type   129880 non-null  object\n",
      " 3   Type of Travel  129880 non-null  object\n",
      " 4   Class           129880 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:44:42.506896Z",
     "start_time": "2024-09-02T06:44:42.451182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[cols] = df[cols].astype(str)\n",
    "df[cols].info()\n",
    "df[cols]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129880 entries, 0 to 129879\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   satisfaction    129880 non-null  object\n",
      " 1   Gender          129880 non-null  object\n",
      " 2   Customer Type   129880 non-null  object\n",
      " 3   Type of Travel  129880 non-null  object\n",
      " 4   Class           129880 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 5.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        satisfaction  Gender      Customer Type   Type of Travel     Class\n",
       "0          satisfied  Female     Loyal Customer  Personal Travel       Eco\n",
       "1          satisfied    Male     Loyal Customer  Personal Travel  Business\n",
       "2          satisfied  Female     Loyal Customer  Personal Travel       Eco\n",
       "3          satisfied  Female     Loyal Customer  Personal Travel       Eco\n",
       "4          satisfied  Female     Loyal Customer  Personal Travel       Eco\n",
       "...              ...     ...                ...              ...       ...\n",
       "129875     satisfied  Female  disloyal Customer  Personal Travel       Eco\n",
       "129876  dissatisfied    Male  disloyal Customer  Personal Travel  Business\n",
       "129877  dissatisfied    Male  disloyal Customer  Personal Travel       Eco\n",
       "129878  dissatisfied    Male  disloyal Customer  Personal Travel       Eco\n",
       "129879  dissatisfied  Female  disloyal Customer  Personal Travel       Eco\n",
       "\n",
       "[129880 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129875</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129876</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129877</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129878</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129879</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129880 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:44:50.220392Z",
     "start_time": "2024-09-02T06:44:50.187565Z"
    }
   },
   "source": [
    "# 범주형 데이터를 수치값으로 변경하기\n",
    "df['satisfaction'].replace(['dissatisfied','satisfied'], [0,1], inplace=True)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:44:52.682772Z",
     "start_time": "2024-09-02T06:44:52.666774Z"
    }
   },
   "cell_type": "code",
   "source": "sum(df['satisfaction'] == 1), sum(df['satisfaction'] == 0)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71087, 58793)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:46:11.819410Z",
     "start_time": "2024-09-02T06:46:11.807722Z"
    }
   },
   "source": [
    "# 순서형 인코딩(Ordinal Encoding)하기\n",
    "categories = pd.Categorical(\n",
    "    df['Class'],\n",
    "    categories=['Eco', 'Eco Plus', 'Business'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# pd.factorize(categories, sort=True) 첫번째 파라미터로 df['Class'] 사용하지 않는 이유:\n",
    "# 카테고리의 특성에 따라 \"Eco:0, Eco Plus:1, Business:2\" 가 되어야 하는데 categories화 하여 순서를 지정하지 않으면 \"Business:1, Eco:2, Eco Plus: 1\" 과 같이 될 수 있다.\n",
    "labels, unique = pd.factorize(categories, sort=True)\n",
    "df['Class'] = labels"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:55:23.158312Z",
     "start_time": "2024-09-02T06:55:23.113565Z"
    }
   },
   "source": [
    "# 원핫 인코딩(One Hot Encoding)하기\n",
    "cat_cols = ['Gender','Customer Type','Type of Travel']\n",
    "df = pd.get_dummies(df, columns=cat_cols)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:55:24.708458Z",
     "start_time": "2024-09-02T06:55:24.700996Z"
    }
   },
   "source": [
    "# 데이터 전처리 결과 확인하기\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   satisfaction  Age  Class  Flight Distance  Seat comfort  \\\n",
       "0             1   65      0              265             0   \n",
       "1             1   47      2             2464             0   \n",
       "2             1   15      0             2138             0   \n",
       "3             1   60      0              623             0   \n",
       "4             1   70      0              354             0   \n",
       "\n",
       "   Departure/Arrival time convenient  Food and drink  Gate location  \\\n",
       "0                                  0               0              2   \n",
       "1                                  0               0              3   \n",
       "2                                  0               0              3   \n",
       "3                                  0               0              3   \n",
       "4                                  0               0              3   \n",
       "\n",
       "   Inflight wifi service  Inflight entertainment  ...  Cleanliness  \\\n",
       "0                      2                       4  ...            3   \n",
       "1                      0                       2  ...            3   \n",
       "2                      2                       0  ...            4   \n",
       "3                      3                       4  ...            1   \n",
       "4                      4                       3  ...            2   \n",
       "\n",
       "   Online boarding  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0                2                           0                       0.0   \n",
       "1                2                         310                     305.0   \n",
       "2                2                           0                       0.0   \n",
       "3                3                           0                       0.0   \n",
       "4                5                           0                       0.0   \n",
       "\n",
       "   Gender_Female  Gender_Male  Customer Type_Loyal Customer  \\\n",
       "0           True        False                          True   \n",
       "1          False         True                          True   \n",
       "2           True        False                          True   \n",
       "3           True        False                          True   \n",
       "4           True        False                          True   \n",
       "\n",
       "   Customer Type_disloyal Customer  Type of Travel_Business travel  \\\n",
       "0                            False                           False   \n",
       "1                            False                           False   \n",
       "2                            False                           False   \n",
       "3                            False                           False   \n",
       "4                            False                           False   \n",
       "\n",
       "   Type of Travel_Personal Travel  \n",
       "0                            True  \n",
       "1                            True  \n",
       "2                            True  \n",
       "3                            True  \n",
       "4                            True  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>...</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Customer Type_Loyal Customer</th>\n",
       "      <th>Customer Type_disloyal Customer</th>\n",
       "      <th>Type of Travel_Business travel</th>\n",
       "      <th>Type of Travel_Personal Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>305.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:55:29.233544Z",
     "start_time": "2024-09-02T06:55:29.227955Z"
    }
   },
   "source": [
    "# 데이터 유형 확인하기\n",
    "df.dtypes"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction                           int64\n",
       "Age                                    int64\n",
       "Class                                  int64\n",
       "Flight Distance                        int64\n",
       "Seat comfort                           int64\n",
       "Departure/Arrival time convenient      int64\n",
       "Food and drink                         int64\n",
       "Gate location                          int64\n",
       "Inflight wifi service                  int64\n",
       "Inflight entertainment                 int64\n",
       "Online support                         int64\n",
       "Ease of Online booking                 int64\n",
       "On-board service                       int64\n",
       "Leg room service                       int64\n",
       "Baggage handling                       int64\n",
       "Checkin service                        int64\n",
       "Cleanliness                            int64\n",
       "Online boarding                        int64\n",
       "Departure Delay in Minutes             int64\n",
       "Arrival Delay in Minutes             float64\n",
       "Gender_Female                           bool\n",
       "Gender_Male                             bool\n",
       "Customer Type_Loyal Customer            bool\n",
       "Customer Type_disloyal Customer         bool\n",
       "Type of Travel_Business travel          bool\n",
       "Type of Travel_Personal Travel          bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 데이터셋 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:55:35.799735Z",
     "start_time": "2024-09-02T06:55:35.751331Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋을 입력(X)과 레이블(y)로 분리하기\n",
    "X = df.drop(['satisfaction'], axis=1)\n",
    "\n",
    "# df['satisfaction']을 추출하는 과정에서 원본 데이터프레임 df의 인덱스가 그대로 유지됩니다. \n",
    "# 원본 데이터프레임이 어떤 이유로 인덱스가 변경되었거나, 행이 삭제된 경우, 인덱스가 연속되지 않을 수 있습니다.\n",
    "# 데이터셋을 train_test_split으로 나누거나 다른 머신러닝 작업을 수행할 때, 인덱스가 연속적이고 일관되게 유지되는 것이 좋습니다. 이는 데이터 추적 및 관리 측면에서 더 명확하게 할 수 있습니다.\n",
    "y = df['satisfaction'].reset_index(drop=True)\n",
    "\n",
    "# 데이터셋을 훈련 데이터와 검증 데이터로 분리하기\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y)\n",
    "\n",
    "print(f'훈련 데이터셋 크기 : X_train {X_train.shape}, y_train {y_train.shape}')\n",
    "print(f'검증 데이터셋 크기 : X_val {X_val.shape}, y_val {y_val.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 크기 : X_train (103904, 25), y_train (103904,)\n",
      "검증 데이터셋 크기 : X_val (25976, 25), y_val (25976,)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 데이터 스케일링하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T06:56:31.216380Z",
     "start_time": "2024-09-02T06:56:31.206858Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터 정규화하기\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "print(X_train)\n",
    "print(X_train.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15384615 0.         0.34502246 ... 1.         1.         0.        ]\n",
      " [0.33333333 0.         0.44051587 ... 1.         1.         0.        ]\n",
      " [0.48717949 0.         0.26546877 ... 0.         1.         0.        ]\n",
      " ...\n",
      " [0.35897436 1.         0.31459209 ... 0.         1.         0.        ]\n",
      " [0.17948718 0.         0.25010868 ... 0.         0.         1.        ]\n",
      " [0.19230769 1.         0.62860455 ... 0.         1.         0.        ]]\n",
      "(103904, 25)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 심층신경망 모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T07:03:54.672540Z",
     "start_time": "2024-09-02T07:03:54.634999Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import random\n",
    "\n",
    "# 모델 시드 고정하기\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Keras의 Sequential 객체로 딥러닝 모델 구성하기\n",
    "# initializer = tf.keras.initializers.GlorotUniform(seed=42) #모델 시드 고정하기\n",
    "model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_shape=(25,),kernel_initializer=initializer))\n",
    "model.add(Dense(32, activation='relu', input_shape=(25,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T07:03:11.184050Z",
     "start_time": "2024-09-02T07:03:11.175185Z"
    }
   },
   "source": [
    "# 모델 구조 및 파라미터 정보 확인하기\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_3\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_13 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │           \u001B[38;5;34m832\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m2,112\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │         \u001B[38;5;34m8,320\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m8,256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m21,633\u001B[0m (84.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,633</span> (84.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m21,633\u001B[0m (84.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,633</span> (84.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 모델 컴파일하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T07:03:58.401431Z",
     "start_time": "2024-09-02T07:03:58.393815Z"
    }
   },
   "source": [
    "# 모델을 학습시킬 최적화 방법, loss 계산 방법, 평가 방법 설정하기\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) "
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T07:04:27.733872Z",
     "start_time": "2024-09-02T07:04:00.089494Z"
    }
   },
   "source": [
    "# 모델 학습하기\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=128,\n",
    "          verbose=1, validation_data=(X_val, y_val), callbacks=[es])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.8408 - loss: 0.3547 - val_accuracy: 0.9241 - val_loss: 0.1754\n",
      "Epoch 2/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 934us/step - accuracy: 0.9234 - loss: 0.1830 - val_accuracy: 0.9319 - val_loss: 0.1544\n",
      "Epoch 3/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 929us/step - accuracy: 0.9329 - loss: 0.1592 - val_accuracy: 0.9359 - val_loss: 0.1448\n",
      "Epoch 4/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 945us/step - accuracy: 0.9382 - loss: 0.1461 - val_accuracy: 0.9385 - val_loss: 0.1401\n",
      "Epoch 5/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 916us/step - accuracy: 0.9403 - loss: 0.1387 - val_accuracy: 0.9381 - val_loss: 0.1406\n",
      "Epoch 6/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 916us/step - accuracy: 0.9424 - loss: 0.1317 - val_accuracy: 0.9448 - val_loss: 0.1257\n",
      "Epoch 7/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 920us/step - accuracy: 0.9448 - loss: 0.1266 - val_accuracy: 0.9470 - val_loss: 0.1224\n",
      "Epoch 8/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 966us/step - accuracy: 0.9464 - loss: 0.1223 - val_accuracy: 0.9482 - val_loss: 0.1186\n",
      "Epoch 9/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 996us/step - accuracy: 0.9478 - loss: 0.1187 - val_accuracy: 0.9472 - val_loss: 0.1198\n",
      "Epoch 10/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 953us/step - accuracy: 0.9490 - loss: 0.1170 - val_accuracy: 0.9495 - val_loss: 0.1171\n",
      "Epoch 11/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 935us/step - accuracy: 0.9491 - loss: 0.1149 - val_accuracy: 0.9503 - val_loss: 0.1150\n",
      "Epoch 12/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 936us/step - accuracy: 0.9505 - loss: 0.1122 - val_accuracy: 0.9501 - val_loss: 0.1148\n",
      "Epoch 13/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 911us/step - accuracy: 0.9510 - loss: 0.1097 - val_accuracy: 0.9500 - val_loss: 0.1121\n",
      "Epoch 14/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 912us/step - accuracy: 0.9523 - loss: 0.1095 - val_accuracy: 0.9496 - val_loss: 0.1133\n",
      "Epoch 15/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 917us/step - accuracy: 0.9524 - loss: 0.1074 - val_accuracy: 0.9505 - val_loss: 0.1116\n",
      "Epoch 16/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 942us/step - accuracy: 0.9521 - loss: 0.1075 - val_accuracy: 0.9501 - val_loss: 0.1110\n",
      "Epoch 17/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.9529 - loss: 0.1060 - val_accuracy: 0.9516 - val_loss: 0.1099\n",
      "Epoch 18/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 960us/step - accuracy: 0.9537 - loss: 0.1032 - val_accuracy: 0.9528 - val_loss: 0.1071\n",
      "Epoch 19/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 922us/step - accuracy: 0.9544 - loss: 0.1027 - val_accuracy: 0.9521 - val_loss: 0.1080\n",
      "Epoch 20/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 923us/step - accuracy: 0.9543 - loss: 0.1018 - val_accuracy: 0.9514 - val_loss: 0.1076\n",
      "Epoch 21/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 906us/step - accuracy: 0.9555 - loss: 0.1001 - val_accuracy: 0.9526 - val_loss: 0.1068\n",
      "Epoch 22/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 895us/step - accuracy: 0.9551 - loss: 0.0992 - val_accuracy: 0.9513 - val_loss: 0.1089\n",
      "Epoch 23/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 894us/step - accuracy: 0.9563 - loss: 0.0984 - val_accuracy: 0.9534 - val_loss: 0.1047\n",
      "Epoch 24/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 898us/step - accuracy: 0.9559 - loss: 0.0977 - val_accuracy: 0.9547 - val_loss: 0.1038\n",
      "Epoch 25/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 910us/step - accuracy: 0.9571 - loss: 0.0962 - val_accuracy: 0.9549 - val_loss: 0.1016\n",
      "Epoch 26/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 920us/step - accuracy: 0.9574 - loss: 0.0954 - val_accuracy: 0.9548 - val_loss: 0.1027\n",
      "Epoch 27/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 919us/step - accuracy: 0.9573 - loss: 0.0947 - val_accuracy: 0.9537 - val_loss: 0.1048\n",
      "Epoch 28/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 940us/step - accuracy: 0.9580 - loss: 0.0949 - val_accuracy: 0.9531 - val_loss: 0.1083\n",
      "Epoch 29/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 937us/step - accuracy: 0.9581 - loss: 0.0947 - val_accuracy: 0.9495 - val_loss: 0.1161\n",
      "Epoch 30/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 922us/step - accuracy: 0.9583 - loss: 0.0941 - val_accuracy: 0.9529 - val_loss: 0.1062\n",
      "Epoch 31/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 955us/step - accuracy: 0.9594 - loss: 0.0918 - val_accuracy: 0.9540 - val_loss: 0.1067\n",
      "Epoch 32/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 955us/step - accuracy: 0.9587 - loss: 0.0923 - val_accuracy: 0.9531 - val_loss: 0.1091\n",
      "Epoch 33/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 936us/step - accuracy: 0.9584 - loss: 0.0916 - val_accuracy: 0.9541 - val_loss: 0.1030\n",
      "Epoch 34/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 945us/step - accuracy: 0.9599 - loss: 0.0901 - val_accuracy: 0.9545 - val_loss: 0.1039\n",
      "Epoch 35/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step - accuracy: 0.9590 - loss: 0.0914 - val_accuracy: 0.9544 - val_loss: 0.1046\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T07:06:20.871192Z",
     "start_time": "2024-09-02T07:06:20.591651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_, accuracy = model.evaluate(X_val, y_val)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 306us/step - accuracy: 0.9554 - loss: 0.1007\n",
      "Accuracy: 95.49\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 모델 훈련 과정 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-02T07:42:32.422501Z",
     "start_time": "2024-09-02T07:42:32.249762Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 훈련 과정 정확도(accuracy) 시각화하기\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# 훈련 과정 손실(loss) 시각화하기\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
