{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SECTION 02. 딥러닝으로 AI모델링하기"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 딥러닝 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 텐서플로 설치 및 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-08-19T04:42:28.155392Z",
     "start_time": "2024-08-19T04:42:26.776483Z"
    }
   },
   "source": [
    "# tensorflow 라이브러리 설치하기\n",
    "!pip install tensorflow"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (2.17.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (3.11.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (0.4.0)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (3.3.0)\r\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (24.1)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (4.25.4)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (69.5.1)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (4.11.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.16.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.65.4)\r\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (2.17.0)\r\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorflow) (1.26.4)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\r\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\r\n",
      "Requirement already satisfied: namex in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/aice/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T04:42:28.159559Z",
     "start_time": "2024-08-19T04:42:28.156842Z"
    }
   },
   "source": [
    "# 설치된 텐서플로 버전 확인하기\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T04:42:28.163837Z",
     "start_time": "2024-08-19T04:42:28.160308Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 모델 학습 데이터 생성하기\n",
    "x = [1, 2, 3, 4,  5, 6,  7,  8,  9, 10]\n",
    "y = [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n",
    "x_train = np.array(x)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "y_train = np.array(y)\n",
    "\n",
    "print(f'입력 데이터 : {x_train}')\n",
    "print(f'입력 데이터 형태: {x_train.shape}')\n",
    "print(f'출력 데이터: {y_train}')\n",
    "print(f'출력 데이터 형태 : {y_train.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 데이터 : [[ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]]\n",
      "입력 데이터 형태: (10, 1)\n",
      "출력 데이터: [ 3  5  7  9 11 13 15 17 19 21]\n",
      "출력 데이터 형태 : (10,)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T04:42:28.182903Z",
     "start_time": "2024-08-19T04:42:28.165223Z"
    }
   },
   "source": [
    "# Keras의 Sequential 모델 구성하기\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42) #모델 시드 고정하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1, input_shape=(1,), kernel_initializer=initializer))\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m2\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2\u001B[0m (8.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m2\u001B[0m (8.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T04:42:28.189684Z",
     "start_time": "2024-08-19T04:42:28.183535Z"
    }
   },
   "source": [
    "# 모델을 학습시킬 최적화 방법, loss 계산 방법, 평가 방법 설정하기\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mae'])"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T04:42:38.871479Z",
     "start_time": "2024-08-19T04:42:28.190432Z"
    }
   },
   "source": [
    "# 모델 학습하기\n",
    "model.fit(x_train, y_train, epochs=1000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 162ms/step - loss: 323.2250 - mae: 16.1452\n",
      "Epoch 2/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 14.9011 - mae: 3.5555\n",
      "Epoch 3/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.7542 - mae: 0.8584\n",
      "Epoch 4/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.1045 - mae: 0.2802\n",
      "Epoch 5/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0741 - mae: 0.2255\n",
      "Epoch 6/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0721 - mae: 0.2238\n",
      "Epoch 7/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0715 - mae: 0.2230\n",
      "Epoch 8/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0709 - mae: 0.2223\n",
      "Epoch 9/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0703 - mae: 0.2214\n",
      "Epoch 10/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0697 - mae: 0.2205\n",
      "Epoch 11/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0691 - mae: 0.2196\n",
      "Epoch 12/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0685 - mae: 0.2187\n",
      "Epoch 13/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0679 - mae: 0.2178\n",
      "Epoch 14/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0674 - mae: 0.2168\n",
      "Epoch 15/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0668 - mae: 0.2159\n",
      "Epoch 16/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0663 - mae: 0.2150\n",
      "Epoch 17/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 0.0657 - mae: 0.2141\n",
      "Epoch 18/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0651 - mae: 0.2132\n",
      "Epoch 19/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0646 - mae: 0.2123\n",
      "Epoch 20/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0641 - mae: 0.2114\n",
      "Epoch 21/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0635 - mae: 0.2106\n",
      "Epoch 22/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0630 - mae: 0.2097\n",
      "Epoch 23/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0625 - mae: 0.2088\n",
      "Epoch 24/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0619 - mae: 0.2079\n",
      "Epoch 25/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0614 - mae: 0.2070\n",
      "Epoch 26/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0609 - mae: 0.2062\n",
      "Epoch 27/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0604 - mae: 0.2053\n",
      "Epoch 28/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0599 - mae: 0.2044\n",
      "Epoch 29/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0594 - mae: 0.2036\n",
      "Epoch 30/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0589 - mae: 0.2027\n",
      "Epoch 31/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0584 - mae: 0.2019\n",
      "Epoch 32/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0579 - mae: 0.2010\n",
      "Epoch 33/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0574 - mae: 0.2002\n",
      "Epoch 34/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0569 - mae: 0.1993\n",
      "Epoch 35/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0565 - mae: 0.1985\n",
      "Epoch 36/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0560 - mae: 0.1977\n",
      "Epoch 37/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0555 - mae: 0.1968\n",
      "Epoch 38/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0551 - mae: 0.1960\n",
      "Epoch 39/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0546 - mae: 0.1952\n",
      "Epoch 40/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0541 - mae: 0.1944\n",
      "Epoch 41/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0537 - mae: 0.1936\n",
      "Epoch 42/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0532 - mae: 0.1927\n",
      "Epoch 43/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0528 - mae: 0.1919\n",
      "Epoch 44/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0523 - mae: 0.1911\n",
      "Epoch 45/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0519 - mae: 0.1903\n",
      "Epoch 46/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0515 - mae: 0.1895\n",
      "Epoch 47/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0510 - mae: 0.1887\n",
      "Epoch 48/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0506 - mae: 0.1879\n",
      "Epoch 49/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0502 - mae: 0.1871\n",
      "Epoch 50/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0498 - mae: 0.1864\n",
      "Epoch 51/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0493 - mae: 0.1856\n",
      "Epoch 52/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0489 - mae: 0.1848\n",
      "Epoch 53/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0485 - mae: 0.1840\n",
      "Epoch 54/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0481 - mae: 0.1832\n",
      "Epoch 55/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0477 - mae: 0.1825\n",
      "Epoch 56/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0473 - mae: 0.1817\n",
      "Epoch 57/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0469 - mae: 0.1810\n",
      "Epoch 58/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0465 - mae: 0.1802\n",
      "Epoch 59/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0461 - mae: 0.1794\n",
      "Epoch 60/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0457 - mae: 0.1787\n",
      "Epoch 61/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0454 - mae: 0.1779\n",
      "Epoch 62/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0450 - mae: 0.1772\n",
      "Epoch 63/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0446 - mae: 0.1764\n",
      "Epoch 64/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0442 - mae: 0.1757\n",
      "Epoch 65/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0439 - mae: 0.1750\n",
      "Epoch 66/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0435 - mae: 0.1742\n",
      "Epoch 67/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0431 - mae: 0.1735\n",
      "Epoch 68/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0428 - mae: 0.1728\n",
      "Epoch 69/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0424 - mae: 0.1720\n",
      "Epoch 70/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0421 - mae: 0.1713\n",
      "Epoch 71/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0417 - mae: 0.1706\n",
      "Epoch 72/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0414 - mae: 0.1699\n",
      "Epoch 73/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0410 - mae: 0.1692\n",
      "Epoch 74/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0407 - mae: 0.1685\n",
      "Epoch 75/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0403 - mae: 0.1677\n",
      "Epoch 76/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0400 - mae: 0.1670\n",
      "Epoch 77/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0396 - mae: 0.1663\n",
      "Epoch 78/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0393 - mae: 0.1656\n",
      "Epoch 79/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0390 - mae: 0.1649\n",
      "Epoch 80/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0387 - mae: 0.1643\n",
      "Epoch 81/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0383 - mae: 0.1636\n",
      "Epoch 82/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0380 - mae: 0.1629\n",
      "Epoch 83/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0377 - mae: 0.1622\n",
      "Epoch 84/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0374 - mae: 0.1615\n",
      "Epoch 85/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0371 - mae: 0.1608\n",
      "Epoch 86/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0368 - mae: 0.1602\n",
      "Epoch 87/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0364 - mae: 0.1595\n",
      "Epoch 88/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0361 - mae: 0.1588\n",
      "Epoch 89/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0358 - mae: 0.1582\n",
      "Epoch 90/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0355 - mae: 0.1575\n",
      "Epoch 91/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0352 - mae: 0.1568\n",
      "Epoch 92/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0349 - mae: 0.1562\n",
      "Epoch 93/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0347 - mae: 0.1555\n",
      "Epoch 94/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0344 - mae: 0.1549\n",
      "Epoch 95/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0341 - mae: 0.1542\n",
      "Epoch 96/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0338 - mae: 0.1536\n",
      "Epoch 97/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0335 - mae: 0.1529\n",
      "Epoch 98/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0332 - mae: 0.1523\n",
      "Epoch 99/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0329 - mae: 0.1516\n",
      "Epoch 100/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0327 - mae: 0.1510\n",
      "Epoch 101/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0324 - mae: 0.1504\n",
      "Epoch 102/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0321 - mae: 0.1497\n",
      "Epoch 103/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0319 - mae: 0.1491\n",
      "Epoch 104/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0316 - mae: 0.1485\n",
      "Epoch 105/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0313 - mae: 0.1479\n",
      "Epoch 106/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0311 - mae: 0.1472\n",
      "Epoch 107/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0308 - mae: 0.1466\n",
      "Epoch 108/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0305 - mae: 0.1460\n",
      "Epoch 109/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0303 - mae: 0.1454\n",
      "Epoch 110/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0300 - mae: 0.1448\n",
      "Epoch 111/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0298 - mae: 0.1442\n",
      "Epoch 112/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0295 - mae: 0.1436\n",
      "Epoch 113/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0293 - mae: 0.1430\n",
      "Epoch 114/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0290 - mae: 0.1424\n",
      "Epoch 115/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0288 - mae: 0.1418\n",
      "Epoch 116/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0286 - mae: 0.1412\n",
      "Epoch 117/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0283 - mae: 0.1406\n",
      "Epoch 118/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0281 - mae: 0.1400\n",
      "Epoch 119/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0278 - mae: 0.1394\n",
      "Epoch 120/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0276 - mae: 0.1388\n",
      "Epoch 121/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0274 - mae: 0.1382\n",
      "Epoch 122/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0271 - mae: 0.1376\n",
      "Epoch 123/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0269 - mae: 0.1371\n",
      "Epoch 124/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0267 - mae: 0.1365\n",
      "Epoch 125/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0265 - mae: 0.1359\n",
      "Epoch 126/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0262 - mae: 0.1353\n",
      "Epoch 127/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0260 - mae: 0.1348\n",
      "Epoch 128/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0258 - mae: 0.1342\n",
      "Epoch 129/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0256 - mae: 0.1336\n",
      "Epoch 130/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0254 - mae: 0.1331\n",
      "Epoch 131/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0252 - mae: 0.1325\n",
      "Epoch 132/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0250 - mae: 0.1320\n",
      "Epoch 133/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0247 - mae: 0.1314\n",
      "Epoch 134/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0245 - mae: 0.1309\n",
      "Epoch 135/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0243 - mae: 0.1303\n",
      "Epoch 136/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0241 - mae: 0.1298\n",
      "Epoch 137/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0239 - mae: 0.1292\n",
      "Epoch 138/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0237 - mae: 0.1287\n",
      "Epoch 139/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0235 - mae: 0.1281\n",
      "Epoch 140/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0233 - mae: 0.1276\n",
      "Epoch 141/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0231 - mae: 0.1271\n",
      "Epoch 142/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0229 - mae: 0.1265\n",
      "Epoch 143/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0227 - mae: 0.1260\n",
      "Epoch 144/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0226 - mae: 0.1255\n",
      "Epoch 145/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0224 - mae: 0.1249\n",
      "Epoch 146/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0222 - mae: 0.1244\n",
      "Epoch 147/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0220 - mae: 0.1239\n",
      "Epoch 148/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0218 - mae: 0.1234\n",
      "Epoch 149/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0216 - mae: 0.1229\n",
      "Epoch 150/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0214 - mae: 0.1223\n",
      "Epoch 151/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0213 - mae: 0.1218\n",
      "Epoch 152/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0211 - mae: 0.1213\n",
      "Epoch 153/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0209 - mae: 0.1208\n",
      "Epoch 154/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0207 - mae: 0.1203\n",
      "Epoch 155/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0206 - mae: 0.1198\n",
      "Epoch 156/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0204 - mae: 0.1193\n",
      "Epoch 157/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0202 - mae: 0.1188\n",
      "Epoch 158/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0201 - mae: 0.1183\n",
      "Epoch 159/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0199 - mae: 0.1178\n",
      "Epoch 160/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0197 - mae: 0.1173\n",
      "Epoch 161/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0196 - mae: 0.1168\n",
      "Epoch 162/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0194 - mae: 0.1163\n",
      "Epoch 163/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0192 - mae: 0.1158\n",
      "Epoch 164/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0191 - mae: 0.1153\n",
      "Epoch 165/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0189 - mae: 0.1149\n",
      "Epoch 166/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0187 - mae: 0.1144\n",
      "Epoch 167/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0186 - mae: 0.1139\n",
      "Epoch 168/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0184 - mae: 0.1134\n",
      "Epoch 169/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0183 - mae: 0.1129\n",
      "Epoch 170/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0181 - mae: 0.1125\n",
      "Epoch 171/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0180 - mae: 0.1120\n",
      "Epoch 172/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0178 - mae: 0.1115\n",
      "Epoch 173/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0177 - mae: 0.1111\n",
      "Epoch 174/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0175 - mae: 0.1106\n",
      "Epoch 175/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0174 - mae: 0.1101\n",
      "Epoch 176/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0172 - mae: 0.1097\n",
      "Epoch 177/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0171 - mae: 0.1092\n",
      "Epoch 178/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0169 - mae: 0.1087\n",
      "Epoch 179/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0168 - mae: 0.1083\n",
      "Epoch 180/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0167 - mae: 0.1078\n",
      "Epoch 181/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0165 - mae: 0.1074\n",
      "Epoch 182/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0164 - mae: 0.1069\n",
      "Epoch 183/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0162 - mae: 0.1065\n",
      "Epoch 184/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0161 - mae: 0.1060\n",
      "Epoch 185/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0160 - mae: 0.1056\n",
      "Epoch 186/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0158 - mae: 0.1051\n",
      "Epoch 187/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0157 - mae: 0.1047\n",
      "Epoch 188/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0156 - mae: 0.1043\n",
      "Epoch 189/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0154 - mae: 0.1038\n",
      "Epoch 190/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0153 - mae: 0.1034\n",
      "Epoch 191/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0152 - mae: 0.1030\n",
      "Epoch 192/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0151 - mae: 0.1025\n",
      "Epoch 193/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0149 - mae: 0.1021\n",
      "Epoch 194/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0148 - mae: 0.1017\n",
      "Epoch 195/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0147 - mae: 0.1012\n",
      "Epoch 196/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0146 - mae: 0.1008\n",
      "Epoch 197/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0144 - mae: 0.1004\n",
      "Epoch 198/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0143 - mae: 0.1000\n",
      "Epoch 199/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0142 - mae: 0.0995\n",
      "Epoch 200/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0141 - mae: 0.0991\n",
      "Epoch 201/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0140 - mae: 0.0987\n",
      "Epoch 202/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0138 - mae: 0.0983\n",
      "Epoch 203/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0137 - mae: 0.0979\n",
      "Epoch 204/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0136 - mae: 0.0975\n",
      "Epoch 205/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0135 - mae: 0.0971\n",
      "Epoch 206/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0134 - mae: 0.0967\n",
      "Epoch 207/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0133 - mae: 0.0963\n",
      "Epoch 208/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0132 - mae: 0.0958\n",
      "Epoch 209/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0131 - mae: 0.0954\n",
      "Epoch 210/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0129 - mae: 0.0950\n",
      "Epoch 211/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0128 - mae: 0.0946\n",
      "Epoch 212/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0127 - mae: 0.0942\n",
      "Epoch 213/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0126 - mae: 0.0939\n",
      "Epoch 214/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0125 - mae: 0.0935\n",
      "Epoch 215/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0124 - mae: 0.0931\n",
      "Epoch 216/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0123 - mae: 0.0927\n",
      "Epoch 217/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0122 - mae: 0.0923\n",
      "Epoch 218/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0121 - mae: 0.0919\n",
      "Epoch 219/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0120 - mae: 0.0915\n",
      "Epoch 220/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0119 - mae: 0.0911\n",
      "Epoch 221/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0118 - mae: 0.0907\n",
      "Epoch 222/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0117 - mae: 0.0904\n",
      "Epoch 223/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0116 - mae: 0.0900\n",
      "Epoch 224/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0115 - mae: 0.0896\n",
      "Epoch 225/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0114 - mae: 0.0892\n",
      "Epoch 226/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0113 - mae: 0.0889\n",
      "Epoch 227/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0112 - mae: 0.0885\n",
      "Epoch 228/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0111 - mae: 0.0881\n",
      "Epoch 229/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0110 - mae: 0.0877\n",
      "Epoch 230/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0109 - mae: 0.0874\n",
      "Epoch 231/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0108 - mae: 0.0870\n",
      "Epoch 232/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0108 - mae: 0.0866\n",
      "Epoch 233/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0107 - mae: 0.0863\n",
      "Epoch 234/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0106 - mae: 0.0859\n",
      "Epoch 235/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0105 - mae: 0.0856\n",
      "Epoch 236/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0104 - mae: 0.0852\n",
      "Epoch 237/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0103 - mae: 0.0848\n",
      "Epoch 238/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0102 - mae: 0.0845\n",
      "Epoch 239/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0101 - mae: 0.0841\n",
      "Epoch 240/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0101 - mae: 0.0838\n",
      "Epoch 241/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0100 - mae: 0.0834\n",
      "Epoch 242/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0099 - mae: 0.0831\n",
      "Epoch 243/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0098 - mae: 0.0827\n",
      "Epoch 244/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0097 - mae: 0.0824\n",
      "Epoch 245/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0096 - mae: 0.0820\n",
      "Epoch 246/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0096 - mae: 0.0817\n",
      "Epoch 247/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0095 - mae: 0.0813\n",
      "Epoch 248/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0094 - mae: 0.0810\n",
      "Epoch 249/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0093 - mae: 0.0807\n",
      "Epoch 250/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0092 - mae: 0.0803\n",
      "Epoch 251/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0092 - mae: 0.0800\n",
      "Epoch 252/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0091 - mae: 0.0796\n",
      "Epoch 253/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0090 - mae: 0.0793\n",
      "Epoch 254/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0089 - mae: 0.0790\n",
      "Epoch 255/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0089 - mae: 0.0786\n",
      "Epoch 256/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0088 - mae: 0.0783\n",
      "Epoch 257/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0087 - mae: 0.0780\n",
      "Epoch 258/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0086 - mae: 0.0777\n",
      "Epoch 259/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0086 - mae: 0.0773\n",
      "Epoch 260/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0085 - mae: 0.0770\n",
      "Epoch 261/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0084 - mae: 0.0767\n",
      "Epoch 262/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0084 - mae: 0.0764\n",
      "Epoch 263/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0083 - mae: 0.0760\n",
      "Epoch 264/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0082 - mae: 0.0757\n",
      "Epoch 265/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0081 - mae: 0.0754\n",
      "Epoch 266/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0081 - mae: 0.0751\n",
      "Epoch 267/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0080 - mae: 0.0748\n",
      "Epoch 268/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0079 - mae: 0.0745\n",
      "Epoch 269/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0079 - mae: 0.0741\n",
      "Epoch 270/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0078 - mae: 0.0738\n",
      "Epoch 271/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0077 - mae: 0.0735\n",
      "Epoch 272/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0077 - mae: 0.0732\n",
      "Epoch 273/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0076 - mae: 0.0729\n",
      "Epoch 274/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0076 - mae: 0.0726\n",
      "Epoch 275/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0075 - mae: 0.0723\n",
      "Epoch 276/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0074 - mae: 0.0720\n",
      "Epoch 277/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0074 - mae: 0.0717\n",
      "Epoch 278/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0073 - mae: 0.0714\n",
      "Epoch 279/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0072 - mae: 0.0711\n",
      "Epoch 280/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0072 - mae: 0.0708\n",
      "Epoch 281/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0071 - mae: 0.0705\n",
      "Epoch 282/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0071 - mae: 0.0702\n",
      "Epoch 283/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0070 - mae: 0.0699\n",
      "Epoch 284/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0069 - mae: 0.0696\n",
      "Epoch 285/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0069 - mae: 0.0693\n",
      "Epoch 286/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0068 - mae: 0.0690\n",
      "Epoch 287/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0068 - mae: 0.0687\n",
      "Epoch 288/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0067 - mae: 0.0684\n",
      "Epoch 289/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.0067 - mae: 0.0682\n",
      "Epoch 290/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0066 - mae: 0.0679\n",
      "Epoch 291/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0065 - mae: 0.0676\n",
      "Epoch 292/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0065 - mae: 0.0673\n",
      "Epoch 293/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0064 - mae: 0.0670\n",
      "Epoch 294/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0064 - mae: 0.0667\n",
      "Epoch 295/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0063 - mae: 0.0665\n",
      "Epoch 296/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0063 - mae: 0.0662\n",
      "Epoch 297/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0062 - mae: 0.0659\n",
      "Epoch 298/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0062 - mae: 0.0656\n",
      "Epoch 299/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0061 - mae: 0.0654\n",
      "Epoch 300/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0061 - mae: 0.0651\n",
      "Epoch 301/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0060 - mae: 0.0648\n",
      "Epoch 302/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0060 - mae: 0.0645\n",
      "Epoch 303/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0059 - mae: 0.0643\n",
      "Epoch 304/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0059 - mae: 0.0640\n",
      "Epoch 305/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0058 - mae: 0.0637\n",
      "Epoch 306/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0058 - mae: 0.0635\n",
      "Epoch 307/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0057 - mae: 0.0632\n",
      "Epoch 308/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0057 - mae: 0.0629\n",
      "Epoch 309/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0056 - mae: 0.0627\n",
      "Epoch 310/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0056 - mae: 0.0624\n",
      "Epoch 311/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0055 - mae: 0.0621\n",
      "Epoch 312/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0055 - mae: 0.0619\n",
      "Epoch 313/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0054 - mae: 0.0616\n",
      "Epoch 314/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0054 - mae: 0.0614\n",
      "Epoch 315/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0053 - mae: 0.0611\n",
      "Epoch 316/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0053 - mae: 0.0608\n",
      "Epoch 317/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0053 - mae: 0.0606\n",
      "Epoch 318/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0052 - mae: 0.0603\n",
      "Epoch 319/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0052 - mae: 0.0601\n",
      "Epoch 320/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0051 - mae: 0.0598\n",
      "Epoch 321/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0051 - mae: 0.0596\n",
      "Epoch 322/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0050 - mae: 0.0593\n",
      "Epoch 323/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0050 - mae: 0.0591\n",
      "Epoch 324/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0050 - mae: 0.0588\n",
      "Epoch 325/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0049 - mae: 0.0586\n",
      "Epoch 326/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0049 - mae: 0.0583\n",
      "Epoch 327/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0048 - mae: 0.0581\n",
      "Epoch 328/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0048 - mae: 0.0578\n",
      "Epoch 329/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0048 - mae: 0.0576\n",
      "Epoch 330/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0047 - mae: 0.0574\n",
      "Epoch 331/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0047 - mae: 0.0571\n",
      "Epoch 332/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0046 - mae: 0.0569\n",
      "Epoch 333/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0046 - mae: 0.0566\n",
      "Epoch 334/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0046 - mae: 0.0564\n",
      "Epoch 335/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0045 - mae: 0.0562\n",
      "Epoch 336/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0045 - mae: 0.0559\n",
      "Epoch 337/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0044 - mae: 0.0557\n",
      "Epoch 338/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0044 - mae: 0.0555\n",
      "Epoch 339/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0044 - mae: 0.0552\n",
      "Epoch 340/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0043 - mae: 0.0550\n",
      "Epoch 341/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0043 - mae: 0.0548\n",
      "Epoch 342/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0043 - mae: 0.0545\n",
      "Epoch 343/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0042 - mae: 0.0543\n",
      "Epoch 344/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0042 - mae: 0.0541\n",
      "Epoch 345/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0042 - mae: 0.0539\n",
      "Epoch 346/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0041 - mae: 0.0536\n",
      "Epoch 347/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0041 - mae: 0.0534\n",
      "Epoch 348/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0041 - mae: 0.0532\n",
      "Epoch 349/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0040 - mae: 0.0530\n",
      "Epoch 350/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0040 - mae: 0.0527\n",
      "Epoch 351/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0040 - mae: 0.0525\n",
      "Epoch 352/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0039 - mae: 0.0523\n",
      "Epoch 353/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0039 - mae: 0.0521\n",
      "Epoch 354/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0039 - mae: 0.0518\n",
      "Epoch 355/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0038 - mae: 0.0516\n",
      "Epoch 356/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0038 - mae: 0.0514\n",
      "Epoch 357/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0038 - mae: 0.0512\n",
      "Epoch 358/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0037 - mae: 0.0510\n",
      "Epoch 359/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0037 - mae: 0.0508\n",
      "Epoch 360/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0037 - mae: 0.0506\n",
      "Epoch 361/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0036 - mae: 0.0503\n",
      "Epoch 362/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0036 - mae: 0.0501\n",
      "Epoch 363/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0036 - mae: 0.0499\n",
      "Epoch 364/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0035 - mae: 0.0497\n",
      "Epoch 365/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0035 - mae: 0.0495\n",
      "Epoch 366/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0035 - mae: 0.0493\n",
      "Epoch 367/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0035 - mae: 0.0491\n",
      "Epoch 368/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0034 - mae: 0.0489\n",
      "Epoch 369/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0034 - mae: 0.0487\n",
      "Epoch 370/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0034 - mae: 0.0485\n",
      "Epoch 371/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0033 - mae: 0.0483\n",
      "Epoch 372/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0033 - mae: 0.0481\n",
      "Epoch 373/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0033 - mae: 0.0479\n",
      "Epoch 374/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0033 - mae: 0.0477\n",
      "Epoch 375/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0032 - mae: 0.0475\n",
      "Epoch 376/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0032 - mae: 0.0473\n",
      "Epoch 377/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0032 - mae: 0.0471\n",
      "Epoch 378/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0031 - mae: 0.0469\n",
      "Epoch 379/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0031 - mae: 0.0467\n",
      "Epoch 380/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0031 - mae: 0.0465\n",
      "Epoch 381/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0031 - mae: 0.0463\n",
      "Epoch 382/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0030 - mae: 0.0461\n",
      "Epoch 383/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0030 - mae: 0.0459\n",
      "Epoch 384/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0030 - mae: 0.0457\n",
      "Epoch 385/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0030 - mae: 0.0455\n",
      "Epoch 386/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0029 - mae: 0.0453\n",
      "Epoch 387/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0029 - mae: 0.0451\n",
      "Epoch 388/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0029 - mae: 0.0449\n",
      "Epoch 389/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0029 - mae: 0.0447\n",
      "Epoch 390/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0028 - mae: 0.0446\n",
      "Epoch 391/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0028 - mae: 0.0444\n",
      "Epoch 392/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0028 - mae: 0.0442\n",
      "Epoch 393/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0028 - mae: 0.0440\n",
      "Epoch 394/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0028 - mae: 0.0438\n",
      "Epoch 395/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0027 - mae: 0.0436\n",
      "Epoch 396/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0027 - mae: 0.0434\n",
      "Epoch 397/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0027 - mae: 0.0433\n",
      "Epoch 398/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0027 - mae: 0.0431\n",
      "Epoch 399/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0026 - mae: 0.0429\n",
      "Epoch 400/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0026 - mae: 0.0427\n",
      "Epoch 401/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0026 - mae: 0.0425\n",
      "Epoch 402/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0026 - mae: 0.0424\n",
      "Epoch 403/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0026 - mae: 0.0422\n",
      "Epoch 404/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0025 - mae: 0.0420\n",
      "Epoch 405/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0025 - mae: 0.0418\n",
      "Epoch 406/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0025 - mae: 0.0417\n",
      "Epoch 407/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0025 - mae: 0.0415\n",
      "Epoch 408/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0024 - mae: 0.0413\n",
      "Epoch 409/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0024 - mae: 0.0411\n",
      "Epoch 410/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0024 - mae: 0.0410\n",
      "Epoch 411/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0024 - mae: 0.0408\n",
      "Epoch 412/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0024 - mae: 0.0406\n",
      "Epoch 413/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0023 - mae: 0.0404\n",
      "Epoch 414/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0023 - mae: 0.0403\n",
      "Epoch 415/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0023 - mae: 0.0401\n",
      "Epoch 416/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0023 - mae: 0.0399\n",
      "Epoch 417/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0023 - mae: 0.0398\n",
      "Epoch 418/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0022 - mae: 0.0396\n",
      "Epoch 419/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0022 - mae: 0.0394\n",
      "Epoch 420/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0022 - mae: 0.0393\n",
      "Epoch 421/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0022 - mae: 0.0391\n",
      "Epoch 422/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0022 - mae: 0.0389\n",
      "Epoch 423/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0022 - mae: 0.0388\n",
      "Epoch 424/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0021 - mae: 0.0386\n",
      "Epoch 425/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0021 - mae: 0.0385\n",
      "Epoch 426/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0021 - mae: 0.0383\n",
      "Epoch 427/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0021 - mae: 0.0381\n",
      "Epoch 428/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0021 - mae: 0.0380\n",
      "Epoch 429/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0020 - mae: 0.0378\n",
      "Epoch 430/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0020 - mae: 0.0377\n",
      "Epoch 431/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0020 - mae: 0.0375\n",
      "Epoch 432/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0020 - mae: 0.0373\n",
      "Epoch 433/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0020 - mae: 0.0372\n",
      "Epoch 434/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0020 - mae: 0.0370\n",
      "Epoch 435/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0019 - mae: 0.0369\n",
      "Epoch 436/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0019 - mae: 0.0367\n",
      "Epoch 437/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0019 - mae: 0.0366\n",
      "Epoch 438/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0019 - mae: 0.0364\n",
      "Epoch 439/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0019 - mae: 0.0363\n",
      "Epoch 440/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0019 - mae: 0.0361\n",
      "Epoch 441/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0019 - mae: 0.0360\n",
      "Epoch 442/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0018 - mae: 0.0358\n",
      "Epoch 443/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0018 - mae: 0.0357\n",
      "Epoch 444/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0018 - mae: 0.0355\n",
      "Epoch 445/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0018 - mae: 0.0354\n",
      "Epoch 446/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0018 - mae: 0.0352\n",
      "Epoch 447/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0018 - mae: 0.0351\n",
      "Epoch 448/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0017 - mae: 0.0349\n",
      "Epoch 449/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0017 - mae: 0.0348\n",
      "Epoch 450/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0017 - mae: 0.0346\n",
      "Epoch 451/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0017 - mae: 0.0345\n",
      "Epoch 452/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0017 - mae: 0.0343\n",
      "Epoch 453/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0017 - mae: 0.0342\n",
      "Epoch 454/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0017 - mae: 0.0340\n",
      "Epoch 455/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0016 - mae: 0.0339\n",
      "Epoch 456/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0016 - mae: 0.0338\n",
      "Epoch 457/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0016 - mae: 0.0336\n",
      "Epoch 458/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0016 - mae: 0.0335\n",
      "Epoch 459/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0016 - mae: 0.0333\n",
      "Epoch 460/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0016 - mae: 0.0332\n",
      "Epoch 461/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0016 - mae: 0.0331\n",
      "Epoch 462/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0016 - mae: 0.0329\n",
      "Epoch 463/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0015 - mae: 0.0328\n",
      "Epoch 464/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0015 - mae: 0.0326\n",
      "Epoch 465/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0325\n",
      "Epoch 466/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0324\n",
      "Epoch 467/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0322\n",
      "Epoch 468/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0321\n",
      "Epoch 469/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0015 - mae: 0.0320\n",
      "Epoch 470/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0015 - mae: 0.0318\n",
      "Epoch 471/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0317\n",
      "Epoch 472/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0014 - mae: 0.0316\n",
      "Epoch 473/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0014 - mae: 0.0314\n",
      "Epoch 474/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0313\n",
      "Epoch 475/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0312\n",
      "Epoch 476/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0014 - mae: 0.0310\n",
      "Epoch 477/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0309\n",
      "Epoch 478/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0014 - mae: 0.0308\n",
      "Epoch 479/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0306\n",
      "Epoch 480/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0013 - mae: 0.0305\n",
      "Epoch 481/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0013 - mae: 0.0304\n",
      "Epoch 482/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 0.0013 - mae: 0.0303\n",
      "Epoch 483/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0301\n",
      "Epoch 484/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0300\n",
      "Epoch 485/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0299\n",
      "Epoch 486/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0297\n",
      "Epoch 487/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0013 - mae: 0.0296\n",
      "Epoch 488/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0295\n",
      "Epoch 489/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0294\n",
      "Epoch 490/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 0.0012 - mae: 0.0293\n",
      "Epoch 491/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0291\n",
      "Epoch 492/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0012 - mae: 0.0290\n",
      "Epoch 493/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0012 - mae: 0.0289\n",
      "Epoch 494/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0288\n",
      "Epoch 495/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0286\n",
      "Epoch 496/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0285\n",
      "Epoch 497/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0012 - mae: 0.0284\n",
      "Epoch 498/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0283\n",
      "Epoch 499/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0282\n",
      "Epoch 500/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0280\n",
      "Epoch 501/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0279\n",
      "Epoch 502/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0011 - mae: 0.0278\n",
      "Epoch 503/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0277\n",
      "Epoch 504/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0276\n",
      "Epoch 505/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0275\n",
      "Epoch 506/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0273\n",
      "Epoch 507/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0272\n",
      "Epoch 508/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0011 - mae: 0.0271\n",
      "Epoch 509/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0010 - mae: 0.0270\n",
      "Epoch 510/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0010 - mae: 0.0269\n",
      "Epoch 511/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0010 - mae: 0.0268\n",
      "Epoch 512/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 0.0010 - mae: 0.0267\n",
      "Epoch 513/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0010 - mae: 0.0266\n",
      "Epoch 514/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 0.0010 - mae: 0.0264\n",
      "Epoch 515/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.9354e-04 - mae: 0.0263\n",
      "Epoch 516/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.8521e-04 - mae: 0.0262\n",
      "Epoch 517/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.7696e-04 - mae: 0.0261\n",
      "Epoch 518/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.6877e-04 - mae: 0.0260\n",
      "Epoch 519/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.6064e-04 - mae: 0.0259\n",
      "Epoch 520/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.5259e-04 - mae: 0.0258\n",
      "Epoch 521/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.4462e-04 - mae: 0.0257\n",
      "Epoch 522/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.3669e-04 - mae: 0.0256\n",
      "Epoch 523/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.2885e-04 - mae: 0.0255\n",
      "Epoch 524/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.2105e-04 - mae: 0.0254\n",
      "Epoch 525/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.1334e-04 - mae: 0.0252\n",
      "Epoch 526/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.0569e-04 - mae: 0.0251\n",
      "Epoch 527/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.9809e-04 - mae: 0.0250\n",
      "Epoch 528/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.9057e-04 - mae: 0.0249\n",
      "Epoch 529/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.8311e-04 - mae: 0.0248\n",
      "Epoch 530/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.7570e-04 - mae: 0.0247\n",
      "Epoch 531/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.6837e-04 - mae: 0.0246\n",
      "Epoch 532/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.6108e-04 - mae: 0.0245\n",
      "Epoch 533/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.5386e-04 - mae: 0.0244\n",
      "Epoch 534/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.4669e-04 - mae: 0.0243\n",
      "Epoch 535/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.3962e-04 - mae: 0.0242\n",
      "Epoch 536/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.3259e-04 - mae: 0.0241\n",
      "Epoch 537/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.2559e-04 - mae: 0.0240\n",
      "Epoch 538/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.1868e-04 - mae: 0.0239\n",
      "Epoch 539/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.1183e-04 - mae: 0.0238\n",
      "Epoch 540/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.0501e-04 - mae: 0.0237\n",
      "Epoch 541/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.9826e-04 - mae: 0.0236\n",
      "Epoch 542/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.9156e-04 - mae: 0.0235\n",
      "Epoch 543/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.8493e-04 - mae: 0.0234\n",
      "Epoch 544/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.7836e-04 - mae: 0.0233\n",
      "Epoch 545/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.7183e-04 - mae: 0.0232\n",
      "Epoch 546/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.6535e-04 - mae: 0.0231\n",
      "Epoch 547/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.5895e-04 - mae: 0.0230\n",
      "Epoch 548/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.5259e-04 - mae: 0.0229\n",
      "Epoch 549/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.4627e-04 - mae: 0.0228\n",
      "Epoch 550/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 7.4002e-04 - mae: 0.0227\n",
      "Epoch 551/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.3383e-04 - mae: 0.0226\n",
      "Epoch 552/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.2768e-04 - mae: 0.0225\n",
      "Epoch 553/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.2157e-04 - mae: 0.0224\n",
      "Epoch 554/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 7.1554e-04 - mae: 0.0223\n",
      "Epoch 555/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.0952e-04 - mae: 0.0223\n",
      "Epoch 556/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.0359e-04 - mae: 0.0222\n",
      "Epoch 557/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.9770e-04 - mae: 0.0221\n",
      "Epoch 558/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.9183e-04 - mae: 0.0220\n",
      "Epoch 559/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.8603e-04 - mae: 0.0219\n",
      "Epoch 560/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.8029e-04 - mae: 0.0218\n",
      "Epoch 561/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.7458e-04 - mae: 0.0217\n",
      "Epoch 562/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.6894e-04 - mae: 0.0216\n",
      "Epoch 563/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.6334e-04 - mae: 0.0215\n",
      "Epoch 564/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.5776e-04 - mae: 0.0214\n",
      "Epoch 565/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.5225e-04 - mae: 0.0213\n",
      "Epoch 566/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.4679e-04 - mae: 0.0212\n",
      "Epoch 567/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.4138e-04 - mae: 0.0212\n",
      "Epoch 568/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.3598e-04 - mae: 0.0211\n",
      "Epoch 569/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.3065e-04 - mae: 0.0210\n",
      "Epoch 570/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.2536e-04 - mae: 0.0209\n",
      "Epoch 571/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.2012e-04 - mae: 0.0208\n",
      "Epoch 572/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.1494e-04 - mae: 0.0207\n",
      "Epoch 573/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.0978e-04 - mae: 0.0206\n",
      "Epoch 574/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.0467e-04 - mae: 0.0205\n",
      "Epoch 575/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.9961e-04 - mae: 0.0205\n",
      "Epoch 576/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.9459e-04 - mae: 0.0204\n",
      "Epoch 577/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.8958e-04 - mae: 0.0203\n",
      "Epoch 578/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.8465e-04 - mae: 0.0202\n",
      "Epoch 579/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.7975e-04 - mae: 0.0201\n",
      "Epoch 580/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.7490e-04 - mae: 0.0200\n",
      "Epoch 581/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.7008e-04 - mae: 0.0199\n",
      "Epoch 582/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.6530e-04 - mae: 0.0199\n",
      "Epoch 583/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.6056e-04 - mae: 0.0198\n",
      "Epoch 584/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5586e-04 - mae: 0.0197\n",
      "Epoch 585/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5119e-04 - mae: 0.0196\n",
      "Epoch 586/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.4658e-04 - mae: 0.0195\n",
      "Epoch 587/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.4199e-04 - mae: 0.0194\n",
      "Epoch 588/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3746e-04 - mae: 0.0194\n",
      "Epoch 589/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3295e-04 - mae: 0.0193\n",
      "Epoch 590/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.2850e-04 - mae: 0.0192\n",
      "Epoch 591/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.2405e-04 - mae: 0.0191\n",
      "Epoch 592/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.1966e-04 - mae: 0.0190\n",
      "Epoch 593/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.1531e-04 - mae: 0.0190\n",
      "Epoch 594/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.1098e-04 - mae: 0.0189\n",
      "Epoch 595/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.0671e-04 - mae: 0.0188\n",
      "Epoch 596/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.0246e-04 - mae: 0.0187\n",
      "Epoch 597/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.9823e-04 - mae: 0.0186\n",
      "Epoch 598/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9408e-04 - mae: 0.0186\n",
      "Epoch 599/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8993e-04 - mae: 0.0185\n",
      "Epoch 600/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.8583e-04 - mae: 0.0184\n",
      "Epoch 601/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.8174e-04 - mae: 0.0183\n",
      "Epoch 602/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 4.7771e-04 - mae: 0.0183\n",
      "Epoch 603/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.7371e-04 - mae: 0.0182\n",
      "Epoch 604/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.6974e-04 - mae: 0.0181\n",
      "Epoch 605/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 4.6579e-04 - mae: 0.0180\n",
      "Epoch 606/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6189e-04 - mae: 0.0180\n",
      "Epoch 607/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5802e-04 - mae: 0.0179\n",
      "Epoch 608/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.5419e-04 - mae: 0.0178\n",
      "Epoch 609/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5037e-04 - mae: 0.0177\n",
      "Epoch 610/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.4660e-04 - mae: 0.0177\n",
      "Epoch 611/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.4286e-04 - mae: 0.0176\n",
      "Epoch 612/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.3915e-04 - mae: 0.0175\n",
      "Epoch 613/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3548e-04 - mae: 0.0174\n",
      "Epoch 614/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.3182e-04 - mae: 0.0174\n",
      "Epoch 615/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.2820e-04 - mae: 0.0173\n",
      "Epoch 616/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.2461e-04 - mae: 0.0172\n",
      "Epoch 617/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.2105e-04 - mae: 0.0171\n",
      "Epoch 618/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1753e-04 - mae: 0.0171\n",
      "Epoch 619/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.1402e-04 - mae: 0.0170\n",
      "Epoch 620/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1056e-04 - mae: 0.0169\n",
      "Epoch 621/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.0711e-04 - mae: 0.0169\n",
      "Epoch 622/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0369e-04 - mae: 0.0168\n",
      "Epoch 623/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.0032e-04 - mae: 0.0167\n",
      "Epoch 624/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.9696e-04 - mae: 0.0166\n",
      "Epoch 625/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.9363e-04 - mae: 0.0166\n",
      "Epoch 626/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.9033e-04 - mae: 0.0165\n",
      "Epoch 627/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.8706e-04 - mae: 0.0164\n",
      "Epoch 628/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.8381e-04 - mae: 0.0164\n",
      "Epoch 629/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.8060e-04 - mae: 0.0163\n",
      "Epoch 630/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.7741e-04 - mae: 0.0162\n",
      "Epoch 631/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.7425e-04 - mae: 0.0162\n",
      "Epoch 632/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.7112e-04 - mae: 0.0161\n",
      "Epoch 633/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.6799e-04 - mae: 0.0160\n",
      "Epoch 634/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.6492e-04 - mae: 0.0160\n",
      "Epoch 635/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.6185e-04 - mae: 0.0159\n",
      "Epoch 636/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.5882e-04 - mae: 0.0158\n",
      "Epoch 637/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5582e-04 - mae: 0.0158\n",
      "Epoch 638/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.5284e-04 - mae: 0.0157\n",
      "Epoch 639/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4988e-04 - mae: 0.0156\n",
      "Epoch 640/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4694e-04 - mae: 0.0156\n",
      "Epoch 641/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.4405e-04 - mae: 0.0155\n",
      "Epoch 642/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4116e-04 - mae: 0.0154\n",
      "Epoch 643/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.3830e-04 - mae: 0.0154\n",
      "Epoch 644/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3546e-04 - mae: 0.0153\n",
      "Epoch 645/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.3264e-04 - mae: 0.0152\n",
      "Epoch 646/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.2986e-04 - mae: 0.0152\n",
      "Epoch 647/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2708e-04 - mae: 0.0151\n",
      "Epoch 648/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.2435e-04 - mae: 0.0150\n",
      "Epoch 649/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.2164e-04 - mae: 0.0150\n",
      "Epoch 650/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1893e-04 - mae: 0.0149\n",
      "Epoch 651/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1626e-04 - mae: 0.0149\n",
      "Epoch 652/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1361e-04 - mae: 0.0148\n",
      "Epoch 653/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.1099e-04 - mae: 0.0147\n",
      "Epoch 654/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0838e-04 - mae: 0.0147\n",
      "Epoch 655/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0580e-04 - mae: 0.0146\n",
      "Epoch 656/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0324e-04 - mae: 0.0145\n",
      "Epoch 657/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.0069e-04 - mae: 0.0145\n",
      "Epoch 658/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9817e-04 - mae: 0.0144\n",
      "Epoch 659/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9567e-04 - mae: 0.0144\n",
      "Epoch 660/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9319e-04 - mae: 0.0143\n",
      "Epoch 661/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9073e-04 - mae: 0.0142\n",
      "Epoch 662/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8829e-04 - mae: 0.0142\n",
      "Epoch 663/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8588e-04 - mae: 0.0141\n",
      "Epoch 664/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8349e-04 - mae: 0.0141\n",
      "Epoch 665/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.8112e-04 - mae: 0.0140\n",
      "Epoch 666/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7875e-04 - mae: 0.0139\n",
      "Epoch 667/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7642e-04 - mae: 0.0139\n",
      "Epoch 668/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.7410e-04 - mae: 0.0138\n",
      "Epoch 669/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7181e-04 - mae: 0.0138\n",
      "Epoch 670/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6953e-04 - mae: 0.0137\n",
      "Epoch 671/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.6727e-04 - mae: 0.0137\n",
      "Epoch 672/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6503e-04 - mae: 0.0136\n",
      "Epoch 673/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6280e-04 - mae: 0.0135\n",
      "Epoch 674/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6060e-04 - mae: 0.0135\n",
      "Epoch 675/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5842e-04 - mae: 0.0134\n",
      "Epoch 676/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.5626e-04 - mae: 0.0134\n",
      "Epoch 677/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5411e-04 - mae: 0.0133\n",
      "Epoch 678/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5197e-04 - mae: 0.0133\n",
      "Epoch 679/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.4987e-04 - mae: 0.0132\n",
      "Epoch 680/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.4777e-04 - mae: 0.0131\n",
      "Epoch 681/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4570e-04 - mae: 0.0131\n",
      "Epoch 682/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.4364e-04 - mae: 0.0130\n",
      "Epoch 683/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.4159e-04 - mae: 0.0130\n",
      "Epoch 684/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3957e-04 - mae: 0.0129\n",
      "Epoch 685/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3755e-04 - mae: 0.0129\n",
      "Epoch 686/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3557e-04 - mae: 0.0128\n",
      "Epoch 687/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.3360e-04 - mae: 0.0128\n",
      "Epoch 688/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3163e-04 - mae: 0.0127\n",
      "Epoch 689/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2970e-04 - mae: 0.0127\n",
      "Epoch 690/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2777e-04 - mae: 0.0126\n",
      "Epoch 691/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2587e-04 - mae: 0.0126\n",
      "Epoch 692/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2397e-04 - mae: 0.0125\n",
      "Epoch 693/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2209e-04 - mae: 0.0124\n",
      "Epoch 694/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2022e-04 - mae: 0.0124\n",
      "Epoch 695/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1838e-04 - mae: 0.0123\n",
      "Epoch 696/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1656e-04 - mae: 0.0123\n",
      "Epoch 697/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1474e-04 - mae: 0.0122\n",
      "Epoch 698/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1294e-04 - mae: 0.0122\n",
      "Epoch 699/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1115e-04 - mae: 0.0121\n",
      "Epoch 700/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 2.0938e-04 - mae: 0.0121\n",
      "Epoch 701/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0763e-04 - mae: 0.0120\n",
      "Epoch 702/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0589e-04 - mae: 0.0120\n",
      "Epoch 703/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0416e-04 - mae: 0.0119\n",
      "Epoch 704/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0245e-04 - mae: 0.0119\n",
      "Epoch 705/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0075e-04 - mae: 0.0118\n",
      "Epoch 706/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9907e-04 - mae: 0.0118\n",
      "Epoch 707/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9740e-04 - mae: 0.0117\n",
      "Epoch 708/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9575e-04 - mae: 0.0117\n",
      "Epoch 709/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9410e-04 - mae: 0.0116\n",
      "Epoch 710/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9249e-04 - mae: 0.0116\n",
      "Epoch 711/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9087e-04 - mae: 0.0115\n",
      "Epoch 712/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8926e-04 - mae: 0.0115\n",
      "Epoch 713/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8768e-04 - mae: 0.0114\n",
      "Epoch 714/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8610e-04 - mae: 0.0114\n",
      "Epoch 715/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8455e-04 - mae: 0.0113\n",
      "Epoch 716/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - loss: 1.8300e-04 - mae: 0.0113\n",
      "Epoch 717/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8147e-04 - mae: 0.0113\n",
      "Epoch 718/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7995e-04 - mae: 0.0112\n",
      "Epoch 719/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7844e-04 - mae: 0.0112\n",
      "Epoch 720/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7695e-04 - mae: 0.0111\n",
      "Epoch 721/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7546e-04 - mae: 0.0111\n",
      "Epoch 722/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7399e-04 - mae: 0.0110\n",
      "Epoch 723/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7253e-04 - mae: 0.0110\n",
      "Epoch 724/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7109e-04 - mae: 0.0109\n",
      "Epoch 725/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.6965e-04 - mae: 0.0109\n",
      "Epoch 726/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6823e-04 - mae: 0.0108\n",
      "Epoch 727/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6681e-04 - mae: 0.0108\n",
      "Epoch 728/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6542e-04 - mae: 0.0107\n",
      "Epoch 729/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6404e-04 - mae: 0.0107\n",
      "Epoch 730/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6266e-04 - mae: 0.0107\n",
      "Epoch 731/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6130e-04 - mae: 0.0106\n",
      "Epoch 732/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5995e-04 - mae: 0.0106\n",
      "Epoch 733/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5861e-04 - mae: 0.0105\n",
      "Epoch 734/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5727e-04 - mae: 0.0105\n",
      "Epoch 735/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5596e-04 - mae: 0.0104\n",
      "Epoch 736/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5465e-04 - mae: 0.0104\n",
      "Epoch 737/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5335e-04 - mae: 0.0103\n",
      "Epoch 738/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.5206e-04 - mae: 0.0103\n",
      "Epoch 739/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.5079e-04 - mae: 0.0103\n",
      "Epoch 740/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.4952e-04 - mae: 0.0102\n",
      "Epoch 741/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.4827e-04 - mae: 0.0102\n",
      "Epoch 742/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4703e-04 - mae: 0.0101\n",
      "Epoch 743/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4580e-04 - mae: 0.0101\n",
      "Epoch 744/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4457e-04 - mae: 0.0100\n",
      "Epoch 745/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4337e-04 - mae: 0.0100\n",
      "Epoch 746/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.4217e-04 - mae: 0.0100\n",
      "Epoch 747/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.4097e-04 - mae: 0.0099\n",
      "Epoch 748/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3980e-04 - mae: 0.0099\n",
      "Epoch 749/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3862e-04 - mae: 0.0098\n",
      "Epoch 750/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3745e-04 - mae: 0.0098\n",
      "Epoch 751/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3631e-04 - mae: 0.0098\n",
      "Epoch 752/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3516e-04 - mae: 0.0097\n",
      "Epoch 753/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3404e-04 - mae: 0.0097\n",
      "Epoch 754/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.3291e-04 - mae: 0.0096\n",
      "Epoch 755/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3179e-04 - mae: 0.0096\n",
      "Epoch 756/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.3069e-04 - mae: 0.0096\n",
      "Epoch 757/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2959e-04 - mae: 0.0095\n",
      "Epoch 758/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2851e-04 - mae: 0.0095\n",
      "Epoch 759/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2743e-04 - mae: 0.0094\n",
      "Epoch 760/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2636e-04 - mae: 0.0094\n",
      "Epoch 761/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2531e-04 - mae: 0.0094\n",
      "Epoch 762/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2425e-04 - mae: 0.0093\n",
      "Epoch 763/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2321e-04 - mae: 0.0093\n",
      "Epoch 764/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2218e-04 - mae: 0.0092\n",
      "Epoch 765/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.2115e-04 - mae: 0.0092\n",
      "Epoch 766/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.2014e-04 - mae: 0.0092\n",
      "Epoch 767/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.1913e-04 - mae: 0.0091\n",
      "Epoch 768/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1814e-04 - mae: 0.0091\n",
      "Epoch 769/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1714e-04 - mae: 0.0090\n",
      "Epoch 770/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1616e-04 - mae: 0.0090\n",
      "Epoch 771/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.1519e-04 - mae: 0.0090\n",
      "Epoch 772/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1422e-04 - mae: 0.0089\n",
      "Epoch 773/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1327e-04 - mae: 0.0089\n",
      "Epoch 774/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.1232e-04 - mae: 0.0089\n",
      "Epoch 775/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1138e-04 - mae: 0.0088\n",
      "Epoch 776/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.1044e-04 - mae: 0.0088\n",
      "Epoch 777/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0952e-04 - mae: 0.0087\n",
      "Epoch 778/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0859e-04 - mae: 0.0087\n",
      "Epoch 779/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0768e-04 - mae: 0.0087\n",
      "Epoch 780/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0678e-04 - mae: 0.0086\n",
      "Epoch 781/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0589e-04 - mae: 0.0086\n",
      "Epoch 782/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0500e-04 - mae: 0.0086\n",
      "Epoch 783/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.0413e-04 - mae: 0.0085\n",
      "Epoch 784/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0325e-04 - mae: 0.0085\n",
      "Epoch 785/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0238e-04 - mae: 0.0085\n",
      "Epoch 786/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.0153e-04 - mae: 0.0084\n",
      "Epoch 787/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.0068e-04 - mae: 0.0084\n",
      "Epoch 788/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.9830e-05 - mae: 0.0083\n",
      "Epoch 789/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.8995e-05 - mae: 0.0083\n",
      "Epoch 790/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.8168e-05 - mae: 0.0083\n",
      "Epoch 791/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.7342e-05 - mae: 0.0082\n",
      "Epoch 792/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.6524e-05 - mae: 0.0082\n",
      "Epoch 793/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.5717e-05 - mae: 0.0082\n",
      "Epoch 794/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.4913e-05 - mae: 0.0081\n",
      "Epoch 795/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 9.4118e-05 - mae: 0.0081\n",
      "Epoch 796/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.3331e-05 - mae: 0.0081\n",
      "Epoch 797/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.2550e-05 - mae: 0.0080\n",
      "Epoch 798/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 9.1777e-05 - mae: 0.0080\n",
      "Epoch 799/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.1005e-05 - mae: 0.0080\n",
      "Epoch 800/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 9.0244e-05 - mae: 0.0079\n",
      "Epoch 801/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.9490e-05 - mae: 0.0079\n",
      "Epoch 802/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.8738e-05 - mae: 0.0079\n",
      "Epoch 803/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.7987e-05 - mae: 0.0078\n",
      "Epoch 804/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 8.7252e-05 - mae: 0.0078\n",
      "Epoch 805/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.6524e-05 - mae: 0.0078\n",
      "Epoch 806/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.5802e-05 - mae: 0.0077\n",
      "Epoch 807/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.5078e-05 - mae: 0.0077\n",
      "Epoch 808/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.4366e-05 - mae: 0.0077\n",
      "Epoch 809/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.3656e-05 - mae: 0.0076\n",
      "Epoch 810/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.2956e-05 - mae: 0.0076\n",
      "Epoch 811/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.2261e-05 - mae: 0.0076\n",
      "Epoch 812/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.1567e-05 - mae: 0.0075\n",
      "Epoch 813/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 8.0883e-05 - mae: 0.0075\n",
      "Epoch 814/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 8.0210e-05 - mae: 0.0075\n",
      "Epoch 815/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.9542e-05 - mae: 0.0075\n",
      "Epoch 816/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.8873e-05 - mae: 0.0074\n",
      "Epoch 817/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.8207e-05 - mae: 0.0074\n",
      "Epoch 818/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.7550e-05 - mae: 0.0074\n",
      "Epoch 819/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.6901e-05 - mae: 0.0073\n",
      "Epoch 820/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.6259e-05 - mae: 0.0073\n",
      "Epoch 821/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.5623e-05 - mae: 0.0073\n",
      "Epoch 822/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.4986e-05 - mae: 0.0072\n",
      "Epoch 823/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.4361e-05 - mae: 0.0072\n",
      "Epoch 824/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.3737e-05 - mae: 0.0072\n",
      "Epoch 825/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.3116e-05 - mae: 0.0071\n",
      "Epoch 826/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.2506e-05 - mae: 0.0071\n",
      "Epoch 827/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.1897e-05 - mae: 0.0071\n",
      "Epoch 828/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 7.1290e-05 - mae: 0.0071\n",
      "Epoch 829/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.0701e-05 - mae: 0.0070\n",
      "Epoch 830/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 7.0108e-05 - mae: 0.0070\n",
      "Epoch 831/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.9512e-05 - mae: 0.0070\n",
      "Epoch 832/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.8934e-05 - mae: 0.0069\n",
      "Epoch 833/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.8359e-05 - mae: 0.0069\n",
      "Epoch 834/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.7782e-05 - mae: 0.0069\n",
      "Epoch 835/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.7214e-05 - mae: 0.0068\n",
      "Epoch 836/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.6650e-05 - mae: 0.0068\n",
      "Epoch 837/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.6093e-05 - mae: 0.0068\n",
      "Epoch 838/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.5536e-05 - mae: 0.0068\n",
      "Epoch 839/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.4991e-05 - mae: 0.0067\n",
      "Epoch 840/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.4444e-05 - mae: 0.0067\n",
      "Epoch 841/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.3904e-05 - mae: 0.0067\n",
      "Epoch 842/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.3372e-05 - mae: 0.0067\n",
      "Epoch 843/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.2835e-05 - mae: 0.0066\n",
      "Epoch 844/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.2311e-05 - mae: 0.0066\n",
      "Epoch 845/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.1794e-05 - mae: 0.0066\n",
      "Epoch 846/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 6.1272e-05 - mae: 0.0065\n",
      "Epoch 847/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 6.0758e-05 - mae: 0.0065\n",
      "Epoch 848/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 6.0248e-05 - mae: 0.0065\n",
      "Epoch 849/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.9744e-05 - mae: 0.0065\n",
      "Epoch 850/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.9241e-05 - mae: 0.0064\n",
      "Epoch 851/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.8751e-05 - mae: 0.0064\n",
      "Epoch 852/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.8254e-05 - mae: 0.0064\n",
      "Epoch 853/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.7764e-05 - mae: 0.0063\n",
      "Epoch 854/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.7279e-05 - mae: 0.0063\n",
      "Epoch 855/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.6803e-05 - mae: 0.0063\n",
      "Epoch 856/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.6325e-05 - mae: 0.0063\n",
      "Epoch 857/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5855e-05 - mae: 0.0062\n",
      "Epoch 858/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.5388e-05 - mae: 0.0062\n",
      "Epoch 859/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.4921e-05 - mae: 0.0062\n",
      "Epoch 860/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.4459e-05 - mae: 0.0062\n",
      "Epoch 861/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.4003e-05 - mae: 0.0061\n",
      "Epoch 862/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.3550e-05 - mae: 0.0061\n",
      "Epoch 863/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 5.3105e-05 - mae: 0.0061\n",
      "Epoch 864/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.2659e-05 - mae: 0.0061\n",
      "Epoch 865/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.2217e-05 - mae: 0.0060\n",
      "Epoch 866/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.1782e-05 - mae: 0.0060\n",
      "Epoch 867/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.1345e-05 - mae: 0.0060\n",
      "Epoch 868/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 5.0915e-05 - mae: 0.0060\n",
      "Epoch 869/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.0490e-05 - mae: 0.0059\n",
      "Epoch 870/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 5.0068e-05 - mae: 0.0059\n",
      "Epoch 871/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9642e-05 - mae: 0.0059\n",
      "Epoch 872/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.9230e-05 - mae: 0.0059\n",
      "Epoch 873/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.8816e-05 - mae: 0.0058\n",
      "Epoch 874/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.8406e-05 - mae: 0.0058\n",
      "Epoch 875/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.7998e-05 - mae: 0.0058\n",
      "Epoch 876/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 11ms/step - loss: 4.7597e-05 - mae: 0.0058\n",
      "Epoch 877/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.7200e-05 - mae: 0.0057\n",
      "Epoch 878/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.6804e-05 - mae: 0.0057\n",
      "Epoch 879/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6408e-05 - mae: 0.0057\n",
      "Epoch 880/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.6024e-05 - mae: 0.0057\n",
      "Epoch 881/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5639e-05 - mae: 0.0056\n",
      "Epoch 882/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.5256e-05 - mae: 0.0056\n",
      "Epoch 883/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.4877e-05 - mae: 0.0056\n",
      "Epoch 884/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.4499e-05 - mae: 0.0056\n",
      "Epoch 885/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.4127e-05 - mae: 0.0055\n",
      "Epoch 886/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3753e-05 - mae: 0.0055\n",
      "Epoch 887/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 4.3390e-05 - mae: 0.0055\n",
      "Epoch 888/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.3026e-05 - mae: 0.0055\n",
      "Epoch 889/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.2664e-05 - mae: 0.0055\n",
      "Epoch 890/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - loss: 4.2305e-05 - mae: 0.0054\n",
      "Epoch 891/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1953e-05 - mae: 0.0054\n",
      "Epoch 892/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1601e-05 - mae: 0.0054\n",
      "Epoch 893/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.1255e-05 - mae: 0.0054\n",
      "Epoch 894/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.0905e-05 - mae: 0.0053\n",
      "Epoch 895/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.0564e-05 - mae: 0.0053\n",
      "Epoch 896/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 4.0227e-05 - mae: 0.0053\n",
      "Epoch 897/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.9888e-05 - mae: 0.0053\n",
      "Epoch 898/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.9551e-05 - mae: 0.0053\n",
      "Epoch 899/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.9224e-05 - mae: 0.0052\n",
      "Epoch 900/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.8894e-05 - mae: 0.0052\n",
      "Epoch 901/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.8569e-05 - mae: 0.0052\n",
      "Epoch 902/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.8244e-05 - mae: 0.0052\n",
      "Epoch 903/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.7928e-05 - mae: 0.0051\n",
      "Epoch 904/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 3.7607e-05 - mae: 0.0051\n",
      "Epoch 905/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.7292e-05 - mae: 0.0051\n",
      "Epoch 906/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.6978e-05 - mae: 0.0051\n",
      "Epoch 907/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.6668e-05 - mae: 0.0051\n",
      "Epoch 908/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.6362e-05 - mae: 0.0050\n",
      "Epoch 909/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.6056e-05 - mae: 0.0050\n",
      "Epoch 910/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5756e-05 - mae: 0.0050\n",
      "Epoch 911/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.5453e-05 - mae: 0.0050\n",
      "Epoch 912/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.5159e-05 - mae: 0.0050\n",
      "Epoch 913/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4862e-05 - mae: 0.0049\n",
      "Epoch 914/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4571e-05 - mae: 0.0049\n",
      "Epoch 915/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.4281e-05 - mae: 0.0049\n",
      "Epoch 916/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3994e-05 - mae: 0.0049\n",
      "Epoch 917/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.3711e-05 - mae: 0.0049\n",
      "Epoch 918/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3425e-05 - mae: 0.0048\n",
      "Epoch 919/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.3148e-05 - mae: 0.0048\n",
      "Epoch 920/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.2869e-05 - mae: 0.0048\n",
      "Epoch 921/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.2593e-05 - mae: 0.0048\n",
      "Epoch 922/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.2320e-05 - mae: 0.0047\n",
      "Epoch 923/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.2052e-05 - mae: 0.0047\n",
      "Epoch 924/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1778e-05 - mae: 0.0047\n",
      "Epoch 925/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1513e-05 - mae: 0.0047\n",
      "Epoch 926/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.1250e-05 - mae: 0.0047\n",
      "Epoch 927/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 3.0990e-05 - mae: 0.0047\n",
      "Epoch 928/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.0730e-05 - mae: 0.0046\n",
      "Epoch 929/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.0468e-05 - mae: 0.0046\n",
      "Epoch 930/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 3.0217e-05 - mae: 0.0046\n",
      "Epoch 931/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9963e-05 - mae: 0.0046\n",
      "Epoch 932/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.9713e-05 - mae: 0.0046\n",
      "Epoch 933/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9464e-05 - mae: 0.0045\n",
      "Epoch 934/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.9214e-05 - mae: 0.0045\n",
      "Epoch 935/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.8970e-05 - mae: 0.0045\n",
      "Epoch 936/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8729e-05 - mae: 0.0045\n",
      "Epoch 937/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8485e-05 - mae: 0.0045\n",
      "Epoch 938/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8250e-05 - mae: 0.0044\n",
      "Epoch 939/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.8011e-05 - mae: 0.0044\n",
      "Epoch 940/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7778e-05 - mae: 0.0044\n",
      "Epoch 941/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7545e-05 - mae: 0.0044\n",
      "Epoch 942/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7313e-05 - mae: 0.0044\n",
      "Epoch 943/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.7084e-05 - mae: 0.0043\n",
      "Epoch 944/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6858e-05 - mae: 0.0043\n",
      "Epoch 945/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6631e-05 - mae: 0.0043\n",
      "Epoch 946/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.6409e-05 - mae: 0.0043\n",
      "Epoch 947/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.6185e-05 - mae: 0.0043\n",
      "Epoch 948/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5968e-05 - mae: 0.0043\n",
      "Epoch 949/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.5751e-05 - mae: 0.0042\n",
      "Epoch 950/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5535e-05 - mae: 0.0042\n",
      "Epoch 951/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5321e-05 - mae: 0.0042\n",
      "Epoch 952/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.5108e-05 - mae: 0.0042\n",
      "Epoch 953/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4899e-05 - mae: 0.0042\n",
      "Epoch 954/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.4690e-05 - mae: 0.0042\n",
      "Epoch 955/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.4482e-05 - mae: 0.0041\n",
      "Epoch 956/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4278e-05 - mae: 0.0041\n",
      "Epoch 957/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.4073e-05 - mae: 0.0041\n",
      "Epoch 958/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3875e-05 - mae: 0.0041\n",
      "Epoch 959/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3673e-05 - mae: 0.0041\n",
      "Epoch 960/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3473e-05 - mae: 0.0040\n",
      "Epoch 961/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.3278e-05 - mae: 0.0040\n",
      "Epoch 962/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.3082e-05 - mae: 0.0040\n",
      "Epoch 963/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2889e-05 - mae: 0.0040\n",
      "Epoch 964/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.2695e-05 - mae: 0.0040\n",
      "Epoch 965/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.2508e-05 - mae: 0.0040\n",
      "Epoch 966/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2319e-05 - mae: 0.0039\n",
      "Epoch 967/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.2130e-05 - mae: 0.0039\n",
      "Epoch 968/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1947e-05 - mae: 0.0039\n",
      "Epoch 969/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1763e-05 - mae: 0.0039\n",
      "Epoch 970/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.1579e-05 - mae: 0.0039\n",
      "Epoch 971/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.1398e-05 - mae: 0.0039\n",
      "Epoch 972/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.1220e-05 - mae: 0.0038\n",
      "Epoch 973/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 2.1041e-05 - mae: 0.0038\n",
      "Epoch 974/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0864e-05 - mae: 0.0038\n",
      "Epoch 975/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0692e-05 - mae: 0.0038\n",
      "Epoch 976/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0517e-05 - mae: 0.0038\n",
      "Epoch 977/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 2.0347e-05 - mae: 0.0038\n",
      "Epoch 978/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0174e-05 - mae: 0.0038\n",
      "Epoch 979/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 2.0005e-05 - mae: 0.0037\n",
      "Epoch 980/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9837e-05 - mae: 0.0037\n",
      "Epoch 981/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.9672e-05 - mae: 0.0037\n",
      "Epoch 982/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9506e-05 - mae: 0.0037\n",
      "Epoch 983/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9344e-05 - mae: 0.0037\n",
      "Epoch 984/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9180e-05 - mae: 0.0037\n",
      "Epoch 985/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.9021e-05 - mae: 0.0036\n",
      "Epoch 986/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8862e-05 - mae: 0.0036\n",
      "Epoch 987/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8703e-05 - mae: 0.0036\n",
      "Epoch 988/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.8547e-05 - mae: 0.0036\n",
      "Epoch 989/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.8390e-05 - mae: 0.0036\n",
      "Epoch 990/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.8239e-05 - mae: 0.0036\n",
      "Epoch 991/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.8084e-05 - mae: 0.0036\n",
      "Epoch 992/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7933e-05 - mae: 0.0035\n",
      "Epoch 993/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7781e-05 - mae: 0.0035\n",
      "Epoch 994/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7630e-05 - mae: 0.0035\n",
      "Epoch 995/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7483e-05 - mae: 0.0035\n",
      "Epoch 996/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - loss: 1.7338e-05 - mae: 0.0035\n",
      "Epoch 997/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.7193e-05 - mae: 0.0035\n",
      "Epoch 998/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.7050e-05 - mae: 0.0034\n",
      "Epoch 999/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 10ms/step - loss: 1.6905e-05 - mae: 0.0034\n",
      "Epoch 1000/1000\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - loss: 1.6764e-05 - mae: 0.0034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1627e3310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T04:42:38.873739Z",
     "start_time": "2024-08-19T04:42:38.872141Z"
    }
   },
   "source": [
    "# 모델 가중치 확인하기\n",
    "print(model.weights)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasVariable shape=(1, 1), dtype=float32, path=sequential_1/dense_1/kernel>, <KerasVariable shape=(1,), dtype=float32, path=sequential_1/dense_1/bias>]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T04:42:38.877387Z",
     "start_time": "2024-08-19T04:42:38.874416Z"
    }
   },
   "source": [
    "# 모델 레이어의 가중치 출력하기\n",
    "print(f'weight : {model.layers[0].weights[0].numpy()}')\n",
    "print(f'bias : {model.layers[0].bias.numpy()}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : [[2.001265]]\n",
      "bias : [0.99119264]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-08-19T05:54:43.390008Z",
     "start_time": "2024-08-19T05:54:43.346176Z"
    }
   },
   "source": [
    "# 학습 완료된 모델 사용하여 예측하기\n",
    "print(model.predict(np.array([[11],[12],[13]])))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step\n",
      "[[23.005108]\n",
      " [25.006372]\n",
      " [27.007637]]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T05:54:54.833552Z",
     "start_time": "2024-08-19T05:54:54.830256Z"
    }
   },
   "source": [
    "# 클래스와 메소드 사용법 확인하기\n",
    "help(model.fit)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module keras.src.backend.tensorflow.trainer:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1) method of keras.src.models.sequential.Sequential instance\n",
      "    Trains the model for a fixed number of epochs (dataset iterations).\n",
      "    \n",
      "    Args:\n",
      "        x: Input data. It could be:\n",
      "            - A NumPy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "            - A tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "            - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "            - A `tf.data.Dataset`. Should return a tuple\n",
      "            of either `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "            - A `keras.utils.PyDataset` returning `(inputs,\n",
      "            targets)` or `(inputs, targets, sample_weights)`.\n",
      "        y: Target data. Like the input data `x`,\n",
      "            it could be either NumPy array(s) or backend-native tensor(s).\n",
      "            If `x` is a dataset, generator,\n",
      "            or `keras.utils.PyDataset` instance, `y` should\n",
      "            not be specified (since targets will be obtained from `x`).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of datasets, generators, or `keras.utils.PyDataset`\n",
      "            instances (since they generate batches).\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided\n",
      "            (unless the `steps_per_epoch` flag is set to\n",
      "            something other than None).\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "            \"auto\" becomes 1 for most cases.\n",
      "            Note that the progress bar is not\n",
      "            particularly useful when logged to a file,\n",
      "            so `verbose=2` is recommended when not running interactively\n",
      "            (e.g., in a production environment). Defaults to `\"auto\"`.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training.\n",
      "            See `keras.callbacks`. Note\n",
      "            `keras.callbacks.ProgbarLogger` and\n",
      "            `keras.callbacks.History` callbacks are created\n",
      "            automatically and need not be passed to `model.fit()`.\n",
      "            `keras.callbacks.ProgbarLogger` is created\n",
      "            or not based on the `verbose` argument in `model.fit()`.\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate\n",
      "            the loss and any model metrics\n",
      "            on this data at the end of each epoch.\n",
      "            The validation data is selected from the last samples\n",
      "            in the `x` and `y` data provided, before shuffling. This\n",
      "            argument is not supported when `x` is a dataset, generator or\n",
      "            `keras.utils.PyDataset` instance.\n",
      "            If both `validation_data` and `validation_split` are provided,\n",
      "            `validation_data` will override `validation_split`.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data. Thus, note the fact\n",
      "            that the validation loss of data provided using\n",
      "            `validation_split` or `validation_data` is not affected by\n",
      "            regularization layers like noise and dropout.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            It could be:\n",
      "            - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
      "            - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
      "            arrays.\n",
      "            - A `tf.data.Dataset`.\n",
      "            - A Python generator or `keras.utils.PyDataset` returning\n",
      "            `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
      "        shuffle: Boolean, whether to shuffle the training data\n",
      "            before each epoch. This argument is\n",
      "            ignored when `x` is a generator or a `tf.data.Dataset`.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class. When `class_weight` is specified\n",
      "            and targets have a rank of 2 or greater, either `y` must be\n",
      "            one-hot encoded, or an explicit final dimension of `1` must\n",
      "            be included for sparse class labels.\n",
      "        sample_weight: Optional NumPy array of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            NumPy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample.\n",
      "            This argument is not supported when `x` is a dataset, generator,\n",
      "            or `keras.utils.PyDataset` instance, instead provide the\n",
      "            sample_weights as the third element of `x`.\n",
      "            Note that sample weighting does not apply to metrics specified\n",
      "            via the `metrics` argument in `compile()`. To apply sample\n",
      "            weighting to your metrics, you can specify them via the\n",
      "            `weighted_metrics` in `compile()` instead.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring one epoch finished and starting the\n",
      "            next epoch. When training with input tensors such as\n",
      "            backend-native tensors, the default `None` is equal to\n",
      "            the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined. If `x` is a\n",
      "            `tf.data.Dataset`, and `steps_per_epoch`\n",
      "            is `None`, the epoch will run until the input dataset is\n",
      "            exhausted.  When passing an infinitely repeating dataset, you\n",
      "            must specify the `steps_per_epoch` argument. If\n",
      "            `steps_per_epoch=-1` the training will run indefinitely with an\n",
      "            infinitely repeating dataset.\n",
      "        validation_steps: Only relevant if `validation_data` is provided.\n",
      "            Total number of steps (batches of\n",
      "            samples) to draw before stopping when performing validation\n",
      "            at the end of every epoch. If `validation_steps` is `None`,\n",
      "            validation will run until the `validation_data` dataset is\n",
      "            exhausted. In the case of an infinitely repeated dataset, it\n",
      "            will run into an infinite loop. If `validation_steps` is\n",
      "            specified and only part of the dataset will be consumed, the\n",
      "            evaluation will start from the beginning of the dataset at each\n",
      "            epoch. This ensures that the same validation samples are used\n",
      "            every time.\n",
      "        validation_batch_size: Integer or `None`.\n",
      "            Number of samples per validation batch.\n",
      "            If unspecified, will default to `batch_size`.\n",
      "            Do not specify the `validation_batch_size` if your data is in\n",
      "            the form of datasets or `keras.utils.PyDataset`\n",
      "            instances (since they generate batches).\n",
      "        validation_freq: Only relevant if validation data is provided.\n",
      "            Specifies how many training epochs to run\n",
      "            before a new validation run is performed,\n",
      "            e.g. `validation_freq=2` runs validation every 2 epochs.\n",
      "    \n",
      "    Unpacking behavior for iterator-like inputs:\n",
      "        A common pattern is to pass an iterator like object such as a\n",
      "        `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
      "        which will in fact yield not only features (`x`)\n",
      "        but optionally targets (`y`) and sample weights (`sample_weight`).\n",
      "        Keras requires that the output of such iterator-likes be\n",
      "        unambiguous. The iterator should return a tuple\n",
      "        of length 1, 2, or 3, where the optional second and third elements\n",
      "        will be used for `y` and `sample_weight` respectively.\n",
      "        Any other type provided will be wrapped in\n",
      "        a length-one tuple, effectively treating everything as `x`. When\n",
      "        yielding dicts, they should still adhere to the top-level tuple\n",
      "        structure,\n",
      "        e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      "        features, targets, and weights from the keys of a single dict.\n",
      "        A notable unsupported data type is the `namedtuple`. The reason is\n",
      "        that it behaves like both an ordered datatype (tuple) and a mapping\n",
      "        datatype (dict). So given a namedtuple of the form:\n",
      "        `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      "        it is ambiguous whether to reverse the order of the elements when\n",
      "        interpreting the value. Even worse is a tuple of the form:\n",
      "        `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      "        where it is unclear if the tuple was intended to be unpacked\n",
      "        into `x`, `y`, and `sample_weight` or passed through\n",
      "        as a single element to `x`.\n",
      "    \n",
      "    Returns:\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 심층신경망으로 항공사 고객 만족 분류 모델 구현 실습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터 로드 및 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T05:54:56.858621Z",
     "start_time": "2024-08-19T05:54:56.856264Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# 경고 메시지를 무시하도록 설정하기\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T05:54:58.798937Z",
     "start_time": "2024-08-19T05:54:58.661304Z"
    }
   },
   "source": [
    "# csv 파일에서 데이터를 로드해서 데이터프레임으로 저장하기\n",
    "df = pd.read_csv('./dataset/Invistico_Airline.csv')\n",
    "\n",
    "# 데이터프레임 정보 확인하기\n",
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129880 entries, 0 to 129879\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   satisfaction                       129880 non-null  object \n",
      " 1   Gender                             129880 non-null  object \n",
      " 2   Customer Type                      129880 non-null  object \n",
      " 3   Age                                129880 non-null  int64  \n",
      " 4   Type of Travel                     129880 non-null  object \n",
      " 5   Class                              129880 non-null  object \n",
      " 6   Flight Distance                    129880 non-null  int64  \n",
      " 7   Seat comfort                       129880 non-null  int64  \n",
      " 8   Departure/Arrival time convenient  129880 non-null  int64  \n",
      " 9   Food and drink                     129880 non-null  int64  \n",
      " 10  Gate location                      129880 non-null  int64  \n",
      " 11  Inflight wifi service              129880 non-null  int64  \n",
      " 12  Inflight entertainment             129880 non-null  int64  \n",
      " 13  Online support                     129880 non-null  int64  \n",
      " 14  Ease of Online booking             129880 non-null  int64  \n",
      " 15  On-board service                   129880 non-null  int64  \n",
      " 16  Leg room service                   129880 non-null  int64  \n",
      " 17  Baggage handling                   129880 non-null  int64  \n",
      " 18  Checkin service                    129880 non-null  int64  \n",
      " 19  Cleanliness                        129880 non-null  int64  \n",
      " 20  Online boarding                    129880 non-null  int64  \n",
      " 21  Departure Delay in Minutes         129880 non-null  int64  \n",
      " 22  Arrival Delay in Minutes           129487 non-null  float64\n",
      "dtypes: float64(1), int64(17), object(5)\n",
      "memory usage: 22.8+ MB\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T05:55:04.066839Z",
     "start_time": "2024-08-19T05:55:04.058048Z"
    }
   },
   "source": [
    "# 데이터프레임의 처음 5개 행의 데이터 출력하기\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  satisfaction  Gender   Customer Type  Age   Type of Travel     Class  \\\n",
       "0    satisfied  Female  Loyal Customer   65  Personal Travel       Eco   \n",
       "1    satisfied    Male  Loyal Customer   47  Personal Travel  Business   \n",
       "2    satisfied  Female  Loyal Customer   15  Personal Travel       Eco   \n",
       "3    satisfied  Female  Loyal Customer   60  Personal Travel       Eco   \n",
       "4    satisfied  Female  Loyal Customer   70  Personal Travel       Eco   \n",
       "\n",
       "   Flight Distance  Seat comfort  Departure/Arrival time convenient  \\\n",
       "0              265             0                                  0   \n",
       "1             2464             0                                  0   \n",
       "2             2138             0                                  0   \n",
       "3              623             0                                  0   \n",
       "4              354             0                                  0   \n",
       "\n",
       "   Food and drink  ...  Online support  Ease of Online booking  \\\n",
       "0               0  ...               2                       3   \n",
       "1               0  ...               2                       3   \n",
       "2               0  ...               2                       2   \n",
       "3               0  ...               3                       1   \n",
       "4               0  ...               4                       2   \n",
       "\n",
       "   On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
       "0                 3                 0                 3                5   \n",
       "1                 4                 4                 4                2   \n",
       "2                 3                 3                 4                4   \n",
       "3                 1                 0                 1                4   \n",
       "4                 2                 0                 2                4   \n",
       "\n",
       "   Cleanliness  Online boarding  Departure Delay in Minutes  \\\n",
       "0            3                2                           0   \n",
       "1            3                2                         310   \n",
       "2            4                2                           0   \n",
       "3            1                3                           0   \n",
       "4            2                5                           0   \n",
       "\n",
       "   Arrival Delay in Minutes  \n",
       "0                       0.0  \n",
       "1                     305.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>...</th>\n",
       "      <th>Online support</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>65</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>47</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>2464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>15</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>2138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>60</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>70</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T05:55:07.455074Z",
     "start_time": "2024-08-19T05:55:07.389574Z"
    }
   },
   "source": [
    "# 데이터프레임의 요약 통계량 확인하기\n",
    "df.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 Age  Flight Distance   Seat comfort  \\\n",
       "count  129880.000000    129880.000000  129880.000000   \n",
       "mean       39.427957      1981.409055       2.838597   \n",
       "std        15.119360      1027.115606       1.392983   \n",
       "min         7.000000        50.000000       0.000000   \n",
       "25%        27.000000      1359.000000       2.000000   \n",
       "50%        40.000000      1925.000000       3.000000   \n",
       "75%        51.000000      2544.000000       4.000000   \n",
       "max        85.000000      6951.000000       5.000000   \n",
       "\n",
       "       Departure/Arrival time convenient  Food and drink  Gate location  \\\n",
       "count                      129880.000000   129880.000000  129880.000000   \n",
       "mean                            2.990645        2.851994       2.990422   \n",
       "std                             1.527224        1.443729       1.305970   \n",
       "min                             0.000000        0.000000       0.000000   \n",
       "25%                             2.000000        2.000000       2.000000   \n",
       "50%                             3.000000        3.000000       3.000000   \n",
       "75%                             4.000000        4.000000       4.000000   \n",
       "max                             5.000000        5.000000       5.000000   \n",
       "\n",
       "       Inflight wifi service  Inflight entertainment  Online support  \\\n",
       "count          129880.000000           129880.000000   129880.000000   \n",
       "mean                3.249130                3.383477        3.519703   \n",
       "std                 1.318818                1.346059        1.306511   \n",
       "min                 0.000000                0.000000        0.000000   \n",
       "25%                 2.000000                2.000000        3.000000   \n",
       "50%                 3.000000                4.000000        4.000000   \n",
       "75%                 4.000000                4.000000        5.000000   \n",
       "max                 5.000000                5.000000        5.000000   \n",
       "\n",
       "       Ease of Online booking  On-board service  Leg room service  \\\n",
       "count           129880.000000     129880.000000     129880.000000   \n",
       "mean                 3.472105          3.465075          3.485902   \n",
       "std                  1.305560          1.270836          1.292226   \n",
       "min                  0.000000          0.000000          0.000000   \n",
       "25%                  2.000000          3.000000          2.000000   \n",
       "50%                  4.000000          4.000000          4.000000   \n",
       "75%                  5.000000          4.000000          5.000000   \n",
       "max                  5.000000          5.000000          5.000000   \n",
       "\n",
       "       Baggage handling  Checkin service    Cleanliness  Online boarding  \\\n",
       "count     129880.000000    129880.000000  129880.000000    129880.000000   \n",
       "mean           3.695673         3.340807       3.705759         3.352587   \n",
       "std            1.156483         1.260582       1.151774         1.298715   \n",
       "min            1.000000         0.000000       0.000000         0.000000   \n",
       "25%            3.000000         3.000000       3.000000         2.000000   \n",
       "50%            4.000000         3.000000       4.000000         4.000000   \n",
       "75%            5.000000         4.000000       5.000000         4.000000   \n",
       "max            5.000000         5.000000       5.000000         5.000000   \n",
       "\n",
       "       Departure Delay in Minutes  Arrival Delay in Minutes  \n",
       "count               129880.000000             129487.000000  \n",
       "mean                    14.713713                 15.091129  \n",
       "std                     38.071126                 38.465650  \n",
       "min                      0.000000                  0.000000  \n",
       "25%                      0.000000                  0.000000  \n",
       "50%                      0.000000                  0.000000  \n",
       "75%                     12.000000                 13.000000  \n",
       "max                   1592.000000               1584.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>Online support</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129880.000000</td>\n",
       "      <td>129487.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.427957</td>\n",
       "      <td>1981.409055</td>\n",
       "      <td>2.838597</td>\n",
       "      <td>2.990645</td>\n",
       "      <td>2.851994</td>\n",
       "      <td>2.990422</td>\n",
       "      <td>3.249130</td>\n",
       "      <td>3.383477</td>\n",
       "      <td>3.519703</td>\n",
       "      <td>3.472105</td>\n",
       "      <td>3.465075</td>\n",
       "      <td>3.485902</td>\n",
       "      <td>3.695673</td>\n",
       "      <td>3.340807</td>\n",
       "      <td>3.705759</td>\n",
       "      <td>3.352587</td>\n",
       "      <td>14.713713</td>\n",
       "      <td>15.091129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.119360</td>\n",
       "      <td>1027.115606</td>\n",
       "      <td>1.392983</td>\n",
       "      <td>1.527224</td>\n",
       "      <td>1.443729</td>\n",
       "      <td>1.305970</td>\n",
       "      <td>1.318818</td>\n",
       "      <td>1.346059</td>\n",
       "      <td>1.306511</td>\n",
       "      <td>1.305560</td>\n",
       "      <td>1.270836</td>\n",
       "      <td>1.292226</td>\n",
       "      <td>1.156483</td>\n",
       "      <td>1.260582</td>\n",
       "      <td>1.151774</td>\n",
       "      <td>1.298715</td>\n",
       "      <td>38.071126</td>\n",
       "      <td>38.465650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1359.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>1925.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>2544.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>6951.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1592.000000</td>\n",
       "      <td>1584.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T05:55:55.523454Z",
     "start_time": "2024-08-19T05:55:55.497012Z"
    }
   },
   "source": [
    "# 결측치 확인하기\n",
    "df.isnull().sum()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction                           0\n",
       "Gender                                 0\n",
       "Customer Type                          0\n",
       "Age                                    0\n",
       "Type of Travel                         0\n",
       "Class                                  0\n",
       "Flight Distance                        0\n",
       "Seat comfort                           0\n",
       "Departure/Arrival time convenient      0\n",
       "Food and drink                         0\n",
       "Gate location                          0\n",
       "Inflight wifi service                  0\n",
       "Inflight entertainment                 0\n",
       "Online support                         0\n",
       "Ease of Online booking                 0\n",
       "On-board service                       0\n",
       "Leg room service                       0\n",
       "Baggage handling                       0\n",
       "Checkin service                        0\n",
       "Cleanliness                            0\n",
       "Online boarding                        0\n",
       "Departure Delay in Minutes             0\n",
       "Arrival Delay in Minutes             393\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 데이터 전처리하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 결측치 처리하기 "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T05:56:46.593930Z",
     "start_time": "2024-08-19T05:56:45.949956Z"
    }
   },
   "source": [
    "# SimpleImputer 객체로 결측치 대체하기\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df[\"Arrival Delay in Minutes\"] = mean_imputer.fit_transform(df[[\"Arrival Delay in Minutes\"]])"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T05:58:29.255295Z",
     "start_time": "2024-08-19T05:58:29.251825Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"Arrival Delay in Minutes\"].isnull().sum()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 데이터 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:02:28.753920Z",
     "start_time": "2024-08-19T06:02:28.724805Z"
    }
   },
   "source": [
    "# object 칼럼 유형을 string 유형으로 변경하기\n",
    "cols = ['satisfaction', 'Gender', 'Customer Type', 'Type of Travel', 'Class']\n",
    "df[cols] = df[cols].astype(str)\n",
    "df[cols]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        satisfaction  Gender      Customer Type   Type of Travel     Class\n",
       "0          satisfied  Female     Loyal Customer  Personal Travel       Eco\n",
       "1          satisfied    Male     Loyal Customer  Personal Travel  Business\n",
       "2          satisfied  Female     Loyal Customer  Personal Travel       Eco\n",
       "3          satisfied  Female     Loyal Customer  Personal Travel       Eco\n",
       "4          satisfied  Female     Loyal Customer  Personal Travel       Eco\n",
       "...              ...     ...                ...              ...       ...\n",
       "129875     satisfied  Female  disloyal Customer  Personal Travel       Eco\n",
       "129876  dissatisfied    Male  disloyal Customer  Personal Travel  Business\n",
       "129877  dissatisfied    Male  disloyal Customer  Personal Travel       Eco\n",
       "129878  dissatisfied    Male  disloyal Customer  Personal Travel       Eco\n",
       "129879  dissatisfied  Female  disloyal Customer  Personal Travel       Eco\n",
       "\n",
       "[129880 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129875</th>\n",
       "      <td>satisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129876</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129877</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129878</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129879</th>\n",
       "      <td>dissatisfied</td>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129880 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:06:10.419497Z",
     "start_time": "2024-08-19T06:06:10.409640Z"
    }
   },
   "source": [
    "# 범주형 데이터를 수치값으로 변경하기\n",
    "df['satisfaction'].replace(['dissatisfied','satisfied'], [0,1], inplace=True)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58793"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:06:43.460950Z",
     "start_time": "2024-08-19T06:06:43.446508Z"
    }
   },
   "cell_type": "code",
   "source": "sum(df['satisfaction'] == 1), sum(df['satisfaction'] == 0)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71087, 58793)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:14:29.571418Z",
     "start_time": "2024-08-19T06:14:29.560269Z"
    }
   },
   "source": [
    "# 순서형 인코딩(Ordinal Encoding)하기\n",
    "categories = pd.Categorical(\n",
    "    df['Class'], \n",
    "    categories= ['Eco', 'Eco Plus', 'Business'], \n",
    "    ordered=True)\n",
    "\n",
    "# pd.factorize(categories, sort=True) 첫번째 파라미터로 df['Class'] 사용하지 않는 이유:\n",
    "# 카테고리의 특성에 따라 \"Eco:0, Eco Plus:1, Business:2\" 가 되어야 하는데 categories화 하여 순서를 지정하지 않으면 \"Business:1, Eco:2, Eco Plus: 1\" 과 같이 될 수 있다.\n",
    "labels, unique = pd.factorize(categories, sort=True)\n",
    "df['Class'] = labels"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:29:07.944345Z",
     "start_time": "2024-08-19T06:29:07.905451Z"
    }
   },
   "source": [
    "# 원핫 인코딩(One Hot Encoding)하기\n",
    "cat_cols = ['Gender','Customer Type','Type of Travel']\n",
    "df = pd.get_dummies(df, columns=cat_cols)"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:29:09.642746Z",
     "start_time": "2024-08-19T06:29:09.634295Z"
    }
   },
   "source": [
    "# 데이터 전처리 결과 확인하기\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   satisfaction  Age  Class  Flight Distance  Seat comfort  \\\n",
       "0             1   65      0              265             0   \n",
       "1             1   47      2             2464             0   \n",
       "2             1   15      0             2138             0   \n",
       "3             1   60      0              623             0   \n",
       "4             1   70      0              354             0   \n",
       "\n",
       "   Departure/Arrival time convenient  Food and drink  Gate location  \\\n",
       "0                                  0               0              2   \n",
       "1                                  0               0              3   \n",
       "2                                  0               0              3   \n",
       "3                                  0               0              3   \n",
       "4                                  0               0              3   \n",
       "\n",
       "   Inflight wifi service  Inflight entertainment  ...  Cleanliness  \\\n",
       "0                      2                       4  ...            3   \n",
       "1                      0                       2  ...            3   \n",
       "2                      2                       0  ...            4   \n",
       "3                      3                       4  ...            1   \n",
       "4                      4                       3  ...            2   \n",
       "\n",
       "   Online boarding  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0                2                           0                       0.0   \n",
       "1                2                         310                     305.0   \n",
       "2                2                           0                       0.0   \n",
       "3                3                           0                       0.0   \n",
       "4                5                           0                       0.0   \n",
       "\n",
       "   Gender_Female  Gender_Male  Customer Type_Loyal Customer  \\\n",
       "0           True        False                          True   \n",
       "1          False         True                          True   \n",
       "2           True        False                          True   \n",
       "3           True        False                          True   \n",
       "4           True        False                          True   \n",
       "\n",
       "   Customer Type_disloyal Customer  Type of Travel_Business travel  \\\n",
       "0                            False                           False   \n",
       "1                            False                           False   \n",
       "2                            False                           False   \n",
       "3                            False                           False   \n",
       "4                            False                           False   \n",
       "\n",
       "   Type of Travel_Personal Travel  \n",
       "0                            True  \n",
       "1                            True  \n",
       "2                            True  \n",
       "3                            True  \n",
       "4                            True  \n",
       "\n",
       "[5 rows x 26 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>...</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Customer Type_Loyal Customer</th>\n",
       "      <th>Customer Type_disloyal Customer</th>\n",
       "      <th>Type of Travel_Business travel</th>\n",
       "      <th>Type of Travel_Personal Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>2464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>305.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:29:47.802597Z",
     "start_time": "2024-08-19T06:29:47.796859Z"
    }
   },
   "source": [
    "# 데이터 유형 확인하기\n",
    "df.dtypes"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction                           int64\n",
       "Age                                    int64\n",
       "Class                                  int64\n",
       "Flight Distance                        int64\n",
       "Seat comfort                           int64\n",
       "Departure/Arrival time convenient      int64\n",
       "Food and drink                         int64\n",
       "Gate location                          int64\n",
       "Inflight wifi service                  int64\n",
       "Inflight entertainment                 int64\n",
       "Online support                         int64\n",
       "Ease of Online booking                 int64\n",
       "On-board service                       int64\n",
       "Leg room service                       int64\n",
       "Baggage handling                       int64\n",
       "Checkin service                        int64\n",
       "Cleanliness                            int64\n",
       "Online boarding                        int64\n",
       "Departure Delay in Minutes             int64\n",
       "Arrival Delay in Minutes             float64\n",
       "Gender_Female                           bool\n",
       "Gender_Male                             bool\n",
       "Customer Type_Loyal Customer            bool\n",
       "Customer Type_disloyal Customer         bool\n",
       "Type of Travel_Business travel          bool\n",
       "Type of Travel_Personal Travel          bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 데이터셋 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:30:01.530056Z",
     "start_time": "2024-08-19T06:30:01.485293Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋을 입력(X)과 레이블(y)로 분리하기\n",
    "X = df.drop(['satisfaction'], axis=1)\n",
    "y = df['satisfaction'].reset_index(drop=True)\n",
    "\n",
    "# 데이터셋을 훈련 데이터와 검증 데이터로 분리하기\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y)\n",
    "\n",
    "print(f'훈련 데이터셋 크기 : X_train {X_train.shape}, y_train {y_train.shape}')\n",
    "print(f'검증 데이터셋 크기 : X_val {X_val.shape}, y_val {y_val.shape}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋 크기 : X_train (103904, 25), y_train (103904,)\n",
      "검증 데이터셋 크기 : X_val (25976, 25), y_val (25976,)\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 데이터 스케일링하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:30:26.873039Z",
     "start_time": "2024-08-19T06:30:26.795756Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터 정규화하기\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "print(X_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15384615 0.         0.34502246 ... 1.         1.         0.        ]\n",
      " [0.33333333 0.         0.44051587 ... 1.         1.         0.        ]\n",
      " [0.48717949 0.         0.26546877 ... 0.         1.         0.        ]\n",
      " ...\n",
      " [0.35897436 1.         0.31459209 ... 0.         1.         0.        ]\n",
      " [0.17948718 0.         0.25010868 ... 0.         0.         1.        ]\n",
      " [0.19230769 1.         0.62860455 ... 0.         1.         0.        ]]\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 심층신경망 모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:30:43.779406Z",
     "start_time": "2024-08-19T06:30:43.740073Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import random\n",
    "\n",
    "# 모델 시드 고정하기\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Keras의 Sequential 객체로 딥러닝 모델 구성하기\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42) #모델 시드 고정하기\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_shape=(25,),kernel_initializer=initializer))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:30:52.598457Z",
     "start_time": "2024-08-19T06:30:52.587971Z"
    }
   },
   "source": [
    "# 모델 구조 및 파라미터 정보 확인하기\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │           \u001B[38;5;34m832\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m2,112\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │         \u001B[38;5;34m8,320\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m8,256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m2,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m33\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m21,633\u001B[0m (84.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,633</span> (84.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m21,633\u001B[0m (84.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,633</span> (84.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) 모델 컴파일하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:30:55.954215Z",
     "start_time": "2024-08-19T06:30:55.948089Z"
    }
   },
   "source": [
    "# 모델을 학습시킬 최적화 방법, loss 계산 방법, 평가 방법 설정하기\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy']) "
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:31:40.792916Z",
     "start_time": "2024-08-19T06:31:22.172091Z"
    }
   },
   "source": [
    "# 모델 학습하기\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=128,\n",
    "          verbose=1, validation_data=(X_val, y_val), callbacks=[es])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 974us/step - accuracy: 0.8300 - loss: 0.3657 - val_accuracy: 0.9199 - val_loss: 0.1915\n",
      "Epoch 2/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 913us/step - accuracy: 0.9217 - loss: 0.1909 - val_accuracy: 0.9341 - val_loss: 0.1562\n",
      "Epoch 3/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 889us/step - accuracy: 0.9331 - loss: 0.1572 - val_accuracy: 0.9415 - val_loss: 0.1348\n",
      "Epoch 4/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 876us/step - accuracy: 0.9395 - loss: 0.1418 - val_accuracy: 0.9431 - val_loss: 0.1296\n",
      "Epoch 5/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 872us/step - accuracy: 0.9433 - loss: 0.1328 - val_accuracy: 0.9440 - val_loss: 0.1265\n",
      "Epoch 6/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 920us/step - accuracy: 0.9454 - loss: 0.1276 - val_accuracy: 0.9460 - val_loss: 0.1234\n",
      "Epoch 7/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 889us/step - accuracy: 0.9469 - loss: 0.1230 - val_accuracy: 0.9483 - val_loss: 0.1202\n",
      "Epoch 8/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 872us/step - accuracy: 0.9481 - loss: 0.1200 - val_accuracy: 0.9481 - val_loss: 0.1195\n",
      "Epoch 9/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 891us/step - accuracy: 0.9487 - loss: 0.1174 - val_accuracy: 0.9483 - val_loss: 0.1192\n",
      "Epoch 10/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 896us/step - accuracy: 0.9502 - loss: 0.1138 - val_accuracy: 0.9503 - val_loss: 0.1143\n",
      "Epoch 11/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 923us/step - accuracy: 0.9509 - loss: 0.1121 - val_accuracy: 0.9519 - val_loss: 0.1101\n",
      "Epoch 12/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 947us/step - accuracy: 0.9519 - loss: 0.1101 - val_accuracy: 0.9521 - val_loss: 0.1093\n",
      "Epoch 13/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 903us/step - accuracy: 0.9521 - loss: 0.1090 - val_accuracy: 0.9516 - val_loss: 0.1100\n",
      "Epoch 14/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 921us/step - accuracy: 0.9523 - loss: 0.1073 - val_accuracy: 0.9535 - val_loss: 0.1053\n",
      "Epoch 15/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 914us/step - accuracy: 0.9539 - loss: 0.1051 - val_accuracy: 0.9515 - val_loss: 0.1120\n",
      "Epoch 16/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 918us/step - accuracy: 0.9543 - loss: 0.1033 - val_accuracy: 0.9512 - val_loss: 0.1107\n",
      "Epoch 17/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 915us/step - accuracy: 0.9550 - loss: 0.1027 - val_accuracy: 0.9528 - val_loss: 0.1062\n",
      "Epoch 18/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 921us/step - accuracy: 0.9546 - loss: 0.1018 - val_accuracy: 0.9532 - val_loss: 0.1072\n",
      "Epoch 19/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 918us/step - accuracy: 0.9556 - loss: 0.1002 - val_accuracy: 0.9507 - val_loss: 0.1153\n",
      "Epoch 20/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 922us/step - accuracy: 0.9562 - loss: 0.0998 - val_accuracy: 0.9531 - val_loss: 0.1086\n",
      "Epoch 21/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 932us/step - accuracy: 0.9559 - loss: 0.0990 - val_accuracy: 0.9533 - val_loss: 0.1069\n",
      "Epoch 22/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 922us/step - accuracy: 0.9569 - loss: 0.0979 - val_accuracy: 0.9514 - val_loss: 0.1094\n",
      "Epoch 23/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 915us/step - accuracy: 0.9578 - loss: 0.0964 - val_accuracy: 0.9541 - val_loss: 0.1058\n",
      "Epoch 24/100\n",
      "\u001B[1m812/812\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 923us/step - accuracy: 0.9577 - loss: 0.0961 - val_accuracy: 0.9527 - val_loss: 0.1095\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) 모델 훈련 과정 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T06:34:29.026314Z",
     "start_time": "2024-08-19T06:34:28.658387Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 훈련 과정 정확도(accuracy) 시각화하기\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# 훈련 과정 손실(loss) 시각화하기\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
